@article{Aamodt1994CaseBasedReasoningFoundational,
  title = {Case-{{Based Reasoning}} - {{Foundational Issues}}, {{Methodological Variations}}, and {{System Approaches}}.},
  author = {Aamodt, Agnar and Plaza, Enric},
  year = {1994},
  month = jan,
  journal = {AI Commun.},
  doi = {10.3233/AIC-1994-7104}
}

@article{Abels2021FocusingKnowledgebasedGraph,
  title = {Focusing {{Knowledge-based Graph Argument Mining}} via {{Topic Modeling}}},
  author = {Abels, Patrick and Ahmadi, Zahra and Burkhardt, Sophie and Schiller, Benjamin and Gurevych, Iryna and Kramer, Stefan},
  year = {2021},
  month = feb,
  journal = {arXiv:2102.02086 [cs]},
  eprint = {2102.02086},
  primaryclass = {cs},
  urldate = {2021-03-01},
  abstract = {Decision-making usually takes five steps: identifying the problem, collecting data, extracting evidence, identifying pro and con arguments, and making decisions. Focusing on extracting evidence, this paper presents a hybrid model that combines latent Dirichlet allocation and word embeddings to obtain external knowledge from structured and unstructured data. We study the task of sentence-level argument mining, as arguments mostly require some degree of world knowledge to be identified and understood. Given a topic and a sentence, the goal is to classify whether a sentence represents an argument in regard to the topic. We use a topic model to extract topic- and sentence-specific evidence from the structured knowledge base Wikidata, building a graph based on the cosine similarity between the entity word vectors of Wikidata and the vector of the given sentence. Also, we build a second graph based on topic-specific articles found via Google to tackle the general incompleteness of structured knowledge bases. Combining these graphs, we obtain a graph-based model which, as our evaluation shows, successfully capitalizes on both structured and unstructured data.},
  archiveprefix = {arXiv}
}

@inproceedings{Adda-Decker2000InvestigatingTextNormalization,
  title = {Investigating Text Normalization and Pronunciation Variants for {{German}} Broadcast Transcription},
  booktitle = {6th {{International Conference}} on {{Spoken Language Processing}} ({{ICSLP}} 2000)},
  author = {{Adda-Decker}, Martine and Adda, Gilles and Lamel, Lori},
  year = {2000-10-16/2000-10-20},
  pages = {4},
  address = {Beijing, China},
  urldate = {2018-09-05},
  abstract = {In this paper we describe our ongoing work concerning lexical modeling in the LIMSI broadcast transcription system for German. Lexical decomposition is investigated with a twofold goal: lexical coverage optimization and improved letter-to-sound conversion. A set of about 450 decompounding rules, developed using statistics from a 300M word corpus, reduces the OOV rate from 4.5\% to 4.0\% on a 30k development text set. Adding partial inflection stripping, the OOV rate drops to 2.9\%. For letterto-sound conversion, decompounding reduces cross-lexeme ambiguities and thus contributes to more consistent pronunciation dictionaries. Another point of interest concerns reduced pronunciation modeling. Word error rates, measured on 1.3 hours of ARTE TV broadcast, vary between 18 and 24\% depending on the show and the system configuration. Our experiments indicate that using reduced pronunciations slightly decreases word error rates.},
  langid = {english}
}

@article{Adewumi2016SystematicLiteratureReview,
  title = {A Systematic Literature Review of Open Source Software Quality Assessment Models},
  author = {Adewumi, Adewole and Misra, Sanjay and Omoregbe, Nicholas and Crawford, Broderick and Soto, Ricardo},
  year = {2016},
  month = nov,
  journal = {SpringerPlus},
  volume = {5},
  number = {1},
  pages = {1936},
  issn = {2193-1801},
  doi = {10.1186/s40064-016-3612-4},
  urldate = {2023-10-05},
  abstract = {Many open source software (OSS) quality assessment models are proposed and available in the literature. However, there is little or no adoption of these models in practice. In order to guide the formulation of newer models so they can be acceptable by practitioners, there is need for clear discrimination of the existing models based on their specific properties. Based on this, the aim of this study is to perform a systematic literature review to investigate the properties of the existing OSS quality assessment models by classifying them with respect to their quality characteristics, the methodology they use for assessment, and their domain of application so as to guide the formulation and development of newer models. Searches in IEEE Xplore, ACM, Science Direct, Springer and Google Search is performed so as to retrieve all relevant primary studies in this regard. Journal and conference papers between the year 2003 and 2015 were considered since the first known OSS quality model emerged in 2003.}
}

@article{Afantenos2018ComparingDecodingMechanisms,
  title = {Comparing Decoding Mechanisms for Parsing Argumentative Structures},
  author = {Afantenos, Stergos and Peldszus, Andreas and Stede, Manfred},
  year = {2018},
  month = nov,
  journal = {Argument \& Computation},
  volume = {9},
  number = {3},
  pages = {177--192},
  issn = {19462174, 19462166},
  doi = {10.3233/AAC-180033},
  urldate = {2023-10-26}
}

@inproceedings{Agarwal2022GraphNLIGraphbasedNatural,
  title = {{{GraphNLI}}: {{A Graph-based Natural Language Inference Model}} for {{Polarity Prediction}} in {{Online Debates}}},
  shorttitle = {{{GraphNLI}}},
  booktitle = {Proceedings of the {{ACM Web Conference}} 2022},
  author = {Agarwal, Vibhor and Joglekar, Sagar and Young, Anthony P. and Sastry, Nishanth},
  year = {2022},
  month = apr,
  series = {{{WWW}} '22},
  pages = {2729--2737},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3485447.3512144},
  urldate = {2023-07-26},
  abstract = {Online forums that allow participatory engagement between users have been transformative for public discussion of important issues. However, debates on such forums can sometimes escalate into full blown exchanges of hate or misinformation. An important tool in understanding and tackling such problems is to be able to infer the argumentative relation of whether a reply is supporting or attacking the post it is replying to. This so called polarity prediction task is difficult because replies may be based on external context beyond a post and the reply whose polarity is being predicted. We propose GraphNLI, a novel graph-based deep learning architecture that uses graph walk techniques to capture the wider context of a discussion thread in a principled fashion. Specifically, we propose methods to perform root-seeking graph walks that start from a post and captures its surrounding context to generate additional embeddings for the post. We then use these embeddings to predict the polarity relation between a reply and the post it is replying to. We evaluate the performance of our models on a curated debate dataset from Kialo, an online debating platform. Our model outperforms relevant baselines, including S-BERT, with an overall accuracy of 83\%.},
  isbn = {978-1-4503-9096-5}
}

@article{Agarwal2023GraphBasedContextAwareModel,
  title = {A {{Graph-Based Context-Aware Model}} to {{Understand Online Conversations}}},
  author = {Agarwal, Vibhor and Young, Anthony P. and Joglekar, Sagar and Sastry, Nishanth},
  year = {2023},
  month = nov,
  journal = {ACM Transactions on the Web},
  volume = {18},
  number = {1},
  pages = {10:1--10:27},
  issn = {1559-1131},
  doi = {10.1145/3624579},
  urldate = {2023-11-23},
  abstract = {Online forums that allow for participatory engagement between users have been transformative for the public discussion of many important issues. However, such conversations can sometimes escalate into full-blown exchanges of hate and misinformation. Existing approaches in natural language processing (NLP), such as deep learning models for classification tasks, use as inputs only a single comment or a pair of comments depending upon whether the task concerns the inference of properties of the individual comments or the replies between pairs of comments, respectively. However, in online conversations, comments and replies may be based on external context beyond the immediately relevant information that is input to the model. Therefore, being aware of the conversations' surrounding contexts should improve the model's performance for the inference task at hand. We propose GraphNLI,1 a novel graph-based deep learning architecture that uses graph walks to incorporate the wider context of a conversation in a principled manner. Specifically, a graph walk starts from a given comment and samples ``nearby'' comments in the same or parallel conversation threads, which results in additional embeddings that are aggregated together with the initial comment's embedding. We then use these enriched embeddings for downstream NLP prediction tasks that are important for online conversations. We evaluate GraphNLI on two such tasks - polarity prediction and misogynistic hate speech detection - and find that our model consistently outperforms all relevant baselines for both tasks. Specifically, GraphNLI with a biased root-seeking random walk performs with a macro-F1 score of 3 and 6 percentage points better than the best-performing BERT-based baselines for the polarity prediction and hate speech detection tasks, respectively. We also perform extensive ablative experiments and hyperparameter searches to understand the efficacy of GraphNLI. This demonstrates the potential of context-aware models to capture the global context along with the local context of online conversations for these two tasks.}
}

@inproceedings{Agater2025SLANGOInitialBlueprint,
  title = {{{SLANGO}} - {{The Initial Blueprint}} of~{{Privacy-Oriented Legal Query Assistance}}: {{Exploring}} the~{{Potential}} of~{{Retrieval-Augmented Generation}} for~{{German Law Using SPR}}},
  shorttitle = {{{SLANGO}} - {{The Initial Blueprint}} of~{{Privacy-Oriented Legal Query Assistance}}},
  booktitle = {Artificial {{Intelligence XLI}}},
  author = {Agater, J{\'e}r{\^o}me and Memari, Ammar},
  editor = {Bramer, Max and Stahl, Frederic},
  year = {2025},
  pages = {208--221},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-77918-3_15},
  abstract = {This paper introduces an application of Large Language Models (LLMs) in the context of Retrieval-Augmented Generation (RAG) to the problem of privacy-preserving question answering in a legal setting. As Germany's voluminous legal documents, including laws and court decisions, are not stored accurately in the inherent knowledge of LLMs, LLMs are prone to producing unreliable or non-existent references. By augmenting the inherent knowledge with ground truth facts retrieved from a Neo4J database, the answer-generating system can cite the facts directly. By using a locally run LLM, we mitigate the need for cloud-based data processing, preventing privacy-relevant data from leaving the system. Our preliminary results with selected legal questions show the system's ability to provide plausible legal answers. This research lays the foundation for further studies, opening the possibility for integrating more sophisticated RAG techniques and building a user interface with deterministic quoting for precise citation and ease of use. Our study presents a step towards deploying AI in sensitive legal settings, promising a future where legal questions can be answered correctly by LLMs without sacrificing data privacy.},
  isbn = {978-3-031-77918-3},
  langid = {english}
}

@inproceedings{Aicher2024BEABuildingEngaging,
  title = {{{BEA}}: {{Building Engaging Argumentation}}},
  shorttitle = {{{BEA}}},
  booktitle = {Robust {{Argumentation Machines}}},
  author = {Aicher, Annalena and Weber, Klaus and Andr{\'e}, Elisabeth and Minker, Wolfgang and Ultes, Stefan},
  editor = {Cimiano, Philipp and Frank, Anette and Kohlhase, Michael and Stein, Benno},
  year = {2024},
  pages = {279--295},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63536-6_17},
  abstract = {Exchanging arguments and knowledge in conversations is an intuitive way for humans to form opinions and reconcile opposing viewpoints. The vast amount of information available on the internet, often accessed through search engines, presents a considerable challenge. Managing and filtering this overwhelming wealth of data raises the potential for intellectual isolation. This can stem either from personalized searches that create ``filter bubbles'' by considering a user's history and preferences, or from the intrinsic, albeit unconscious, tendency of users to seek information that aligns with their existing beliefs, forming ``self-imposed filter bubbles''.},
  isbn = {978-3-031-63536-6},
  langid = {english}
}

@inproceedings{Ajjour2018VisualizationTopicSpace,
  title = {Visualization of the {{Topic Space}} of {{Argument Search Results}} in Args.Me},
  booktitle = {Proceedings of the 2018 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}: {{System Demonstrations}}},
  author = {Ajjour, Yamen and Wachsmuth, Henning and Kiesel, Dora and Riehmann, Patrick and Fan, Fan and Castiglia, Giuliano and Adejoh, Rosemary and Fr{\"o}hlich, Bernd and Stein, Benno},
  year = {2018},
  month = nov,
  pages = {60--65},
  publisher = {Association for Computational Linguistics},
  address = {Brussels, Belgium},
  doi = {10.18653/v1/D18-2011},
  urldate = {2020-09-28},
  abstract = {In times of fake news and alternative facts, pro and con arguments on controversial topics are of increasing importance. Recently, we presented args.me as the first search engine for arguments on the web. In its initial version, args.me ranked arguments solely by their relevance to a topic queried for, making it hard to learn about the diverse topical aspects covered by the search results. To tackle this shortcoming, we integrated a visualization interface for result exploration in args.me that provides an instant overview of the main aspects in a barycentric coordinate system. This topic space is generated ad-hoc from controversial issues on Wikipedia and argument-specific LDA models. In two case studies, we demonstrate how individual arguments can be found easily through interactions with the visualization, such as highlighting and filtering.}
}

@inproceedings{Ajjour2019DataAcquisitionArgument,
  title = {Data {{Acquisition}} for {{Argument Search}}: {{The}} Args.Me {{Corpus}}},
  shorttitle = {Data {{Acquisition}} for {{Argument Search}}},
  booktitle = {{{KI}} 2019: {{Advances}} in {{Artificial Intelligence}}},
  author = {Ajjour, Yamen and Wachsmuth, Henning and Kiesel, Johannes and Potthast, Martin and Hagen, Matthias and Stein, Benno},
  editor = {Benzm{\"u}ller, Christoph and Stuckenschmidt, Heiner},
  year = {2019},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {48--59},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-30179-8_4},
  abstract = {Argument search is the study of search engine technology that can retrieve arguments for potentially controversial topics or claims upon user request. The design of an argument search engine is tied to its underlying argument acquisition paradigm. More specifically, the employed paradigm controls the trade-off between retrieval precision and recall and thus determines basic search characteristics: Compiling an exhaustive argument corpus offline benefits precision at the expense of recall, whereas retrieving arguments from the web on-the-fly benefits recall at the expense of precision. This paper presents the new corpus of our argument search engine args.me, which follows the former paradigm. We freely provide the corpus to the community. With 387 606 arguments it is one of the largest argument resources available so far. In a qualitative analysis, we compare the args.me corpus acquisition paradigm to that of two other argument search engines, and we report first empirical insights into how people search with args.me.},
  isbn = {978-3-030-30179-8},
  langid = {english}
}

@inproceedings{Akbik2018ContextualStringEmbeddings,
  title = {Contextual {{String Embeddings}} for {{Sequence Labeling}}},
  booktitle = {Proceedings of the 27th {{International Conference}} on {{Computational Linguistics}}},
  author = {Akbik, Alan and Blythe, Duncan and Vollgraf, Roland},
  year = {2018},
  month = aug,
  pages = {1638--1649},
  publisher = {Association for Computational Linguistics},
  address = {Santa Fe, New Mexico, USA},
  urldate = {2021-02-09},
  abstract = {Recent advances in language modeling using recurrent neural networks have made it viable to model language as distributions over characters. By learning to predict the next character on the basis of previous characters, such models have been shown to automatically internalize linguistic concepts such as words, sentences, subclauses and even sentiment. In this paper, we propose to leverage the internal states of a trained character language model to produce a novel type of word embedding which we refer to as contextual string embeddings. Our proposed embeddings have the distinct properties that they (a) are trained without any explicit notion of words and thus fundamentally model words as sequences of characters, and (b) are contextualized by their surrounding text, meaning that the same word will have different embeddings depending on its contextual use. We conduct a comparative evaluation against previous embeddings and find that our embeddings are highly useful for downstream tasks: across four classic sequence labeling tasks we consistently outperform the previous state-of-the-art. In particular, we significantly outperform previous work on English and German named entity recognition (NER), allowing us to report new state-of-the-art F1-scores on the CoNLL03 shared task. We release all code and pre-trained language models in a simple-to-use framework to the research community, to enable reproduction of these experiments and application of our proposed embeddings to other tasks: https://github.com/zalandoresearch/flair}
}

@inproceedings{Aker2017ExtensibleMultilingualOpen,
  title = {An {{Extensible Multilingual Open Source Lemmatizer}}},
  booktitle = {{{RANLP}} 2017 - {{Recent Advances}} in {{Natural Language Processing Meet Deep Learning}}},
  author = {Aker, Ahmet and Petrak, Johann and Sabbah, Firas},
  year = {2017},
  month = nov,
  pages = {40--45},
  publisher = {Incoma Ltd. Shoumen, Bulgaria},
  doi = {10.26615/978-954-452-049-6_006},
  urldate = {2021-03-08},
  abstract = {We present GATE DictLemmatizer, a multilingual open source lemmatizer for the GATE NLP framework that currently supports English, German, Italian, French, Dutch, and Spanish, and is easily extensible to other languages. The software is freely available under the LGPL license. The lemmatization is based on the Helsinki Finite-State Transducer Technology (HFST) and lemma dictionaries automatically created from Wiktionary. We evaluate the performance of the lemmatizers against TreeTagger, which is only freely available for research purposes. Our evaluation shows that DictLemmatizer achieves similar or even better results than TreeTagger for languages where there is support from HFST. The performance drops when there is no support from HFST and the entire lemmatization process is based on lemma dictionaries. However, the results are still satisfactory given the fact that DictLemmatizer isopen-source and can be easily extended to other languages. The software for extending the lemmatizer by creating word lists from Wiktionary dictionaries is also freely available as open-source software.},
  isbn = {978-954-452-049-6}
}

@inproceedings{Al-Debagy2018ComparativeReviewMicroservices,
  title = {A {{Comparative Review}} of {{Microservices}} and {{Monolithic Architectures}}},
  booktitle = {2018 {{IEEE}} 18th {{International Symposium}} on {{Computational Intelligence}} and {{Informatics}} ({{CINTI}})},
  author = {{Al-Debagy}, Omar and Martinek, Peter},
  year = {2018},
  month = nov,
  pages = {000149--000154},
  issn = {2471-9269},
  doi = {10.1109/CINTI.2018.8928192},
  urldate = {2023-11-21},
  abstract = {Microservices' architecture is getting attention in the academic community and the industry, and mostly is compared with monolithic architecture. Plenty of the results of these research papers contradict each other regarding the performance of these architectures. Therefore, these two architectures are compared in this paper, and some specific configurations of microservices' applications are evaluated as well in the term of service discovery. Monolithic architecture in concurrency testing showed better performance in throughput by 6\% when compared to microservices architecture. The load testing scenario did not present significant difference between the two architectures. Furthermore, a third test comparing microservices applications built with different service discovery technologies such as Consul and Eureka showed that applications with Consul presented better results in terms of throughput.}
}

@inproceedings{Al-Khatib2020EndtoEndArgumentationKnowledge,
  title = {End-to-{{End Argumentation Knowledge Graph Construction}}},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {{Al-Khatib}, Khalid and Hou, Yufang and Wachsmuth, Henning and Jochim, Charles and Bonin, Francesca and Stein, Benno},
  year = {2020},
  month = apr,
  volume = {34},
  pages = {7367--7374},
  doi = {10.1609/aaai.v34i05.6231},
  urldate = {2020-09-28},
  abstract = {This paper studies the end-to-end construction of an argumentation knowledge graph that is intended to support argument synthesis, argumentative question answering, or fake news detection, among others. The study is motivated by the proven effectiveness of knowledge graphs for interpretable and controllable text generation and exploratory search. Original in our work is that we propose a model of the knowledge encapsulated in arguments. Based on this model, we build a new corpus that comprises about 16k manual annotations of 4740 claims with instances of the model's elements, and we develop an end-to-end framework that automatically identifies all modeled types of instances. The results of experiments show the potential of the framework for building a web-based argumentation graph that is of high quality and large scale.}
}

@inproceedings{Aleksovski2008UsingMultipleOntologies,
  title = {Using Multiple Ontologies as Background Knowledge in Ontology Matching},
  author = {Aleksovski, Zharko and ten Kate, Warner and van Harmelen, Frank},
  year = {2008},
  abstract = {Using ontology as a background knowledge in ontology matching is being actively investigated. Recently the idea attracted attention because of the growing number of available ontologies, which in turn opens up new opportunities, and reduces the problem of finding candidate background knowledge. Particularly interesting is the approach of using multiple ontologies as background knowledge, which we explore in this paper. We report on an experimental study conducted using real-life ontologies published online. The first contribution of this paper is an exploration about how the matching performance behaves when multiple background ontologies are used cumulatively. As a second contribution, we analyze the impact that different types of background ontologies have to the matching performance. With respect to the precision and recall, more background knowledge monotonically increases the recall, while the precision depends on the quality of the added background ontology, with high quality tending to increase, and the low quality tending to decrease the precision.}
}

@article{Aleven2003UsingBackgroundKnowledge,
  title = {Using Background Knowledge in Case-Based Legal Reasoning: {{A}} Computational Model and an Intelligent Learning Environment},
  shorttitle = {Using Background Knowledge in Case-Based Legal Reasoning},
  author = {Aleven, Vincent},
  year = {2003},
  month = nov,
  journal = {Artificial Intelligence},
  volume = {150},
  number = {1-2},
  pages = {183--237},
  issn = {00043702},
  doi = {10.1016/S0004-3702(03)00105-X},
  urldate = {2019-08-20},
  abstract = {Researchers in the field of AI and Law have developed a number of computational models of the arguments that skilled attorneys make based on past cases. However, these models have not accounted for the ways that attorneys use middle-level normative background knowledge (1) to organize multi-case arguments, (2) to reason about the significance of differences between cases, and (3) to assess the relevance of precedent cases to a given problem situation. We present a novel model, that accounts for these argumentation phenomena. An evaluation study showed that arguments about the significance of distinctions based on this model help predict the outcome of cases in the area of trade secrets law, confirming the quality of these arguments. The model forms the basis of an intelligent learning environment called CATO, which was designed to help beginning law students acquire basic argumentation skills. CATO uses the model for a number of purposes, including the dynamic generation of argumentation examples. In a second evaluation study, carried out in the context of an actual legal writing course, we compared instruction with CATO against the best traditional legal writing instruction. The results indicate that CATO's example-based instructional approach is effective in teaching basic argumentation skills. However, a more ``integrated'' approach appears to be needed if students are to achieve better transfer of these skills to more complex contexts. CATO's argumentation model and instructional environment are a contribution to the research fields of AI and Law, Case-Based Reasoning, and AI and Education.},
  langid = {english}
}

@inproceedings{Alhamzeh2022ItTimeReason,
  title = {It's {{Time}} to {{Reason}}: {{Annotating Argumentation Structures}} in {{Financial Earnings Calls}}: {{The FinArg Dataset}}},
  shorttitle = {It's {{Time}} to {{Reason}}},
  booktitle = {Proceedings of the {{Fourth Workshop}} on {{Financial Technology}} and {{Natural Language Processing}} ({{FinNLP}})},
  author = {Alhamzeh, Alaa and Fonck, Romain and Versm{\'e}e, Erwan and {Egyed-Zsigmond}, El{\"o}d and Kosch, Harald and Brunie, Lionel},
  year = {2022},
  month = dec,
  pages = {163--169},
  publisher = {Association for Computational Linguistics},
  address = {Abu Dhabi, United Arab Emirates (Hybrid)},
  urldate = {2023-07-26},
  abstract = {With the goal of reasoning on the financial textual data, we present in this paper, a novel approach for annotating arguments, their components and relations in the transcripts of earnings conference calls (ECCs). The proposed scheme is driven from the argumentation theory at the micro-structure level of discourse. We further conduct a manual annotation study with four annotators on 136 documents. We obtained inter-annotator agreement of lphaU = 0.70 for argument components and lpha = 0.81 for argument relations. The final created corpus, with the size of 804 documents, as well as the annotation guidelines are publicly available for researchers in the domains of computational argumentation, finance and FinNLP.}
}

@misc{Allen-Zhu2024PhysicsLanguageModels,
  title = {Physics of {{Language Models}}: {{Part}} 3.3, {{Knowledge Capacity Scaling Laws}}},
  shorttitle = {Physics of {{Language Models}}},
  author = {{Allen-Zhu}, Zeyuan and Li, Yuanzhi},
  year = {2024},
  month = apr,
  number = {arXiv:2404.05405},
  eprint = {2404.05405},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-04-09},
  abstract = {Scaling laws describe the relationship between the size of language models and their capabilities. Unlike prior studies that evaluate a model's capability via loss or benchmarks, we estimate the number of knowledge bits a model stores. We focus on factual knowledge represented as tuples, such as (USA, capital, Washington D.C.) from a Wikipedia page. Through multiple controlled datasets, we establish that language models can and only can store 2 bits of knowledge per parameter, even when quantized to int8, and such knowledge can be flexibly extracted for downstream applications. Consequently, a 7B model can store 14B bits of knowledge, surpassing the English Wikipedia and textbooks combined based on our estimation. More broadly, we present 12 results on how (1) training duration, (2) model architecture, (3) quantization, (4) sparsity constraints such as MoE, and (5) data signal-to-noise ratio affect a model's knowledge storage capacity. Notable insights include: * The GPT-2 architecture, with rotary embedding, matches or even surpasses LLaMA/Mistral architectures in knowledge storage, particularly over shorter training durations. This arises because LLaMA/Mistral uses GatedMLP, which is less stable and harder to train. * Prepending training data with domain names (e.g., wikipedia.org) significantly increases a model's knowledge capacity. Language models can autonomously identify and prioritize domains rich in knowledge, optimizing their storage capacity.},
  archiveprefix = {arXiv}
}

@incollection{Allen2003NaturalLanguageProcessing,
  title = {Natural Language Processing},
  booktitle = {Encyclopedia of {{Computer Science}}},
  author = {Allen, James F.},
  year = {2003},
  month = jan,
  pages = {1218--1222},
  publisher = {{John Wiley and Sons Ltd.}},
  address = {GBR},
  urldate = {2021-02-06},
  abstract = {Natural language processing (NLP) refers to computer systems that analyze, attempt to understand, or produce one or more human languages, such as English, Japanese, Italian, or Russian. The input might be text, spoken language, or keyboard input. The task might be to translate to another language, to comprehend and represent the content of text, to build a database or generate summaries, or to maintain a dialogue with a user as part of an interface for database/information retrieval (q.v.). This article addresses issues in natural language comprehension and generation from text or keyboard input. Similar techniques can be used for spoken language by adding a system for speech recognition (see SPEECH RECOGNITION AND SYNTHESIS).},
  isbn = {978-0-470-86412-8}
}

@inproceedings{Alshomary2020ExtractiveSnippetGeneration,
  title = {Extractive {{Snippet Generation}} for {{Arguments}}},
  booktitle = {Proceedings of the 43rd {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Alshomary, Milad and D{\"u}sterhus, Nick and Wachsmuth, Henning},
  year = {2020},
  month = jul,
  series = {{{SIGIR}} '20},
  pages = {1969--1972},
  publisher = {Association for Computing Machinery},
  address = {Virtual Event, China},
  doi = {10.1145/3397271.3401186},
  urldate = {2020-09-02},
  abstract = {Snippets are used in web search to help users assess the relevance of retrieved results to their query. Recently, specialized search engines have arisen that retrieve pro and con arguments on controversial issues. We argue that standard snippet generation is insufficient to represent the core reasoning of an argument. In this paper, we introduce the task of generating a snippet that represents the main claim and reason of an argument. We propose a query-independent extractive summarization approach to this task that uses a variant of PageRank to assess the importance of sentences based on their context and argumentativeness. In both automatic and manual evaluation, our approach outperforms strong baselines.},
  isbn = {978-1-4503-8016-4}
}

@inproceedings{Alshomary2022GeneratingContrastiveSnippets,
  title = {Generating {{Contrastive Snippets}} for {{Argument Search}}},
  booktitle = {Computational {{Models}} of {{Argument}}},
  author = {Alshomary, Milad and Rieskamp, Jonas and Wachsmuth, Henning},
  year = {2022},
  series = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  volume = {353},
  pages = {21--31},
  publisher = {IOS Press},
  address = {Cardiff, Wales},
  doi = {10.3233/FAIA220138},
  urldate = {2022-09-15},
  abstract = {In argument search, snippets provide an overview of the aspects discussed by the arguments retrieved for a queried controversial topic. Existing work has focused on generating snippets that are representative of an argument's content while remaining argumentative. In this work, we argue that the snippets should also be contrastive, that is, they should highlight the aspects that make an argument unique in the context of others. Thereby, aspect diversity is increased and redundancy is reduced. We present and compare two snippet generation approaches that jointly optimize representativeness and contrastiveness. According to our experiments, both approaches have advantages, and one is able to generate representative yet sufficiently contrastive snippets.}
}

@inproceedings{Alsinet2018ProbabilisticAuthorCenteredModel,
  title = {A {{Probabilistic Author-Centered Model}} for {{Twitter Discussions}}},
  booktitle = {Information {{Processing}} and {{Management}} of {{Uncertainty}} in {{Knowledge-Based Systems}}. {{Theory}} and {{Foundations}}},
  author = {Alsinet, Teresa and Argelich, Josep and B{\'e}jar, Ram{\'o}n and Esteva, Francesc and Godo, Lluis},
  editor = {Medina, Jes{\'u}s and {Ojeda-Aciego}, Manuel and Verdegay, Jos{\'e} Luis and Pelta, David A. and Cabrera, Inma P. and {Bouchon-Meunier}, Bernadette and Yager, Ronald R.},
  year = {2018},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {683--695},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-91476-3_56},
  abstract = {In a recent work some of the authors have developed an argumentative approach for discovering relevant opinions in Twitter discussions with probabilistic valued relationships. Given a Twitter discussion, the system builds an argument graph where each node denotes a tweet and each edge denotes a criticism relationship between a pair of tweets of the discussion. Relationships between tweets are associated with a probability value, indicating the uncertainty on whether they actually hold. In this work we introduce and investigate a natural extension of the representation model, referred as probabilistic author-centered model. In this model, tweets by a same author are grouped, describing his/her opinion in the discussion, and are represented with a single node in the graph, while edges stand for criticism relationships between author's opinions. In this new model, interactions between authors can give rise to circular criticism relationships, and the probability of one opinion criticizing another is evaluated from the criticism probabilities among the individual tweets in both opinions.},
  isbn = {978-3-319-91476-3},
  langid = {english}
}

@article{Alvez2019CommonsenseReasoningUsing,
  title = {Commonsense {{Reasoning Using WordNet}} and {{SUMO}}: A {{Detailed Analysis}}},
  shorttitle = {Commonsense {{Reasoning Using WordNet}} and {{SUMO}}},
  author = {{\'A}lvez, Javier and {Gonzalez-Dios}, Itziar and Rigau, German},
  year = {2019},
  month = sep,
  journal = {arXiv:1909.02314 [cs]},
  eprint = {1909.02314},
  primaryclass = {cs},
  urldate = {2021-02-01},
  abstract = {We describe a detailed analysis of a sample of large benchmark of commonsense reasoning problems that has been automatically obtained from WordNet, SUMO and their mapping. The objective is to provide a better assessment of the quality of both the benchmark and the involved knowledge resources for advanced commonsense reasoning tasks. By means of this analysis, we are able to detect some knowledge misalignments, mapping errors and lack of knowledge and resources. Our final objective is the extraction of some guidelines towards a better exploitation of this commonsense knowledge framework by the improvement of the included resources.},
  archiveprefix = {arXiv}
}

@article{AlZubaer2023PerformanceAnalysisLarge,
  title = {Performance Analysis of Large Language Models in the Domain of Legal Argument Mining},
  author = {Al Zubaer, Abdullah and Granitzer, Michael and Mitrovi{\'c}, Jelena},
  year = {2023},
  journal = {Frontiers in Artificial Intelligence},
  volume = {6},
  issn = {2624-8212},
  urldate = {2024-02-10},
  abstract = {Generative pre-trained transformers (GPT) have recently demonstrated excellent performance in various natural language tasks. The development of ChatGPT and the recently released GPT-4 model has shown competence in solving complex and higher-order reasoning tasks without further training or fine-tuning. However, the applicability and strength of these models in classifying legal texts in the context of argument mining are yet to be realized and have not been tested thoroughly. In this study, we investigate the effectiveness of GPT-like models, specifically GPT-3.5 and GPT-4, for argument mining via prompting. We closely study the model's performance considering diverse prompt formulation and example selection in the prompt via semantic search using state-of-the-art embedding models from OpenAI and sentence transformers. We primarily concentrate on the argument component classification task on the legal corpus from the European Court of Human Rights. To address these models' inherent non-deterministic nature and make our result statistically sound, we conducted 5-fold cross-validation on the test set. Our experiments demonstrate, quite surprisingly, that relatively small domain-specific models outperform GPT 3.5 and GPT-4 in the F1-score for premise and conclusion classes, with 1.9\% and 12\% improvements, respectively. We hypothesize that the performance drop indirectly reflects the complexity of the structure in the dataset, which we verify through prompt and data analysis. Nevertheless, our results demonstrate a noteworthy variation in the performance of GPT models based on prompt formulation. We observe comparable performance between the two embedding models, with a slight improvement in the local model's ability for prompt selection. This suggests that local models are as semantically rich as the embeddings from the OpenAI model. Our results indicate that the structure of prompts significantly impacts the performance of GPT models and should be considered when designing them.}
}

@article{Amgoud2006FinalReviewReport,
  title = {Final {{Review}} and {{Report}} on {{Formal Argumentation System}}},
  author = {Amgoud, Leila and Bodenstaff, L. and Caminada, M. and McBurney, P. and Parsons, Simon and Prakken, Henry and Veenen, J. and Vreeswijk, Gerard},
  year = {2006},
  month = jan
}

@inproceedings{Amin2018CasebasedReasoningNatural,
  title = {Case-Based {{Reasoning}} in {{Natural Language Processing}}: {{Word2vec VS fastText}}},
  booktitle = {Proceedings of the 23rd {{UK Workshop}} on {{Case-Based Reasoning}}},
  author = {Amin, Kareem and Lancaster, George and Kapetanakis, Stelios and Althoff, Klaus-Dieter and Dengel, Andreas and Petridis, Miltos},
  year = {2018},
  month = dec,
  publisher = {{School of Computing, Engineering and Mathematics, University of Brighton, UK}},
  address = {Cambridge, United Kingdom},
  abstract = {Businesses can benefi t greatly from analysing their document assets. These can vary greatly from plain text messages across customer support tickets to complex message exchanges and workflow logs within countless business transactions. Decoding text-based domain knowledge can be a challenging task due to the need for a comprehensive representation and evaluation of the business process ontology, activities, rules and paths. To provide an adequate process coverage, significant time and monetary resources should be invested as well as a high maintenance portfolio, especially for large processes and environments that change dynamically. This work investigates a novel natural language processing path which combines Case-based Reasoning and Deep Neural Networks. Our aim is to minimize the effort from domain experts while extracting domain knowledge from rich text, containing domain abbreviations, grammatically incorrect text and mixed language. Our proposed approach seems promising and a possible future direction in the industry.}
}

@inproceedings{Amorim2022ConnectingNonFunctionalRequirements,
  title = {Connecting {{Non-Functional Requirements}} to {{Open Source Ecosystems Health}}},
  booktitle = {Proceedings of the 16th {{Brazilian Symposium}} on {{Software Components}}, {{Architectures}}, and {{Reuse}}},
  author = {Amorim, Simone da Silva and Mcgregor, John D. and de Almeida, Eduardo Santana and Garcia Chavez, Christina von Flach},
  year = {2022},
  month = oct,
  series = {{{SBCARS}} '22},
  pages = {76--80},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3559712.3559719},
  urldate = {2023-10-05},
  abstract = {One efficient way to perceive the effects of design decisions is by analyzing and evaluating Non-Functional Requirements (NFRs). A design decison can contribute positively or negatively toward specific NFRs. In their turn, NFRs describe how the software operates, representing essential quality characteristics of the software systems. In addition, the typical way of perceiving the ``quality'' of a software ecosystem is through the concept of ecosystem health and its health indicators. Considering the descriptive nature of NFRs representing a quality characteristic of the system, they could be a feasible way to know ecosystem health. Through their connection with the health indicators, it is possible to sketch paths to understand the influence of the NFRs on the health indicators and realize how the ecosystem health perceives the design decisions. This study aims to understand and map influences from NFRs to health indicators based on evidence found in KDE, a real-world ecosystem. We conducted mixed-methods research, including a survey with ecosystem experts and an adapted practitioner-evidence framework. Findings present a high-level descriptive mapping with connections between NFRs and health indicators, besides explaining evidence found in the KDE ecosystem.},
  isbn = {978-1-4503-9745-2}
}

@inproceedings{Angeli2014NaturalLINaturalLogic,
  title = {{{NaturalLI}}: {{Natural Logic Inference}} for {{Common Sense Reasoning}}},
  shorttitle = {{{NaturalLI}}},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Angeli, Gabor and Manning, Christopher D.},
  year = {2014},
  month = oct,
  pages = {534--545},
  publisher = {Association for Computational Linguistics},
  address = {Doha, Qatar},
  doi = {10.3115/v1/D14-1059},
  urldate = {2020-06-04}
}

@article{Anonymous2019ArgumentationbasedApproachExplainable,
  title = {Towards an Argumentation-Based Approach to Explainable Planning},
  author = {Anonymous},
  year = {2019},
  month = apr,
  urldate = {2019-09-12},
  abstract = {Providing transparency of AI planning systems is crucial for their success in practical applications. In order to create a transparent system, a user must be able to query it for explanations about...}
}

@misc{Anthony2017ThinkingFastSlow,
  title = {Thinking {{Fast}} and {{Slow}} with {{Deep Learning}} and {{Tree Search}}},
  author = {Anthony, Thomas and Tian, Zheng and Barber, David},
  year = {2017},
  month = dec,
  number = {arXiv:1705.08439},
  eprint = {1705.08439},
  primaryclass = {cs},
  doi = {10.48550/arXiv.1705.08439},
  urldate = {2024-03-28},
  abstract = {Sequential decision making problems, such as structured prediction, robotic control, and game playing, require a combination of planning policies and generalisation of those plans. In this paper, we present Expert Iteration (ExIt), a novel reinforcement learning algorithm which decomposes the problem into separate planning and generalisation tasks. Planning new policies is performed by tree search, while a deep neural network generalises those plans. Subsequently, tree search is improved by using the neural network policy to guide search, increasing the strength of new plans. In contrast, standard deep Reinforcement Learning algorithms rely on a neural network not only to generalise plans, but to discover them too. We show that ExIt outperforms REINFORCE for training a neural network to play the board game Hex, and our final tree search agent, trained tabula rasa, defeats MoHex 1.0, the most recent Olympiad Champion player to be publicly released.},
  archiveprefix = {arXiv}
}

@article{Artstein2008InterCoderAgreementComputational,
  title = {Inter-{{Coder Agreement}} for {{Computational Linguistics}}},
  author = {Artstein, Ron and Poesio, Massimo},
  year = {2008},
  month = sep,
  journal = {Computational Linguistics},
  volume = {34},
  number = {4},
  pages = {555--596},
  publisher = {MIT Press},
  issn = {0891-2017},
  doi = {10.1162/coli.07-034-R2},
  urldate = {2021-02-23},
  abstract = {This article is a survey of methods for measuring agreement among corpus annotators. It exposes the mathematics and underlying assumptions of agreement coefficients, covering Krippendorff's alpha as well as Scott's pi and Cohen's kappa; discusses the use of coefficients in several annotation tasks; and argues that weighted, alpha-like coefficients, traditionally less used than kappa-like measures in computational linguistics, may be more appropriate for many corpus annotation tasks---but that their use makes the interpretation of the value of the coefficient even harder.}
}

@incollection{Artstein2017InterannotatorAgreement,
  title = {Inter-Annotator {{Agreement}}},
  booktitle = {Handbook of {{Linguistic Annotation}}},
  author = {Artstein, Ron},
  editor = {Ide, Nancy and Pustejovsky, James},
  year = {2017},
  pages = {297--313},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-024-0881-2_11},
  urldate = {2021-02-23},
  abstract = {This chapter touches upon several issues in the calculation and assessment of inter-annotator agreement. It gives an introduction to the theory behind agreement coefficients and examples of their application to linguistic annotation tasks. Specific examples explore variation in annotator performance due to heterogeneous data, complex labels, item difficulty, and annotator differences, showing how global agreement coefficients may mask these sources of variation, and how detailed agreement studies can give insight into both the annotation process and the nature of the underlying data. The chapter also reviews recent work on using machine learning to exploit the variation among annotators and learn detailed models from which accurate labels can be inferred. I therefore advocate an approach where agreement studies are not used merely as a means to accept or reject a particular annotation scheme, but as a tool for exploring patterns in the data that are being annotated.},
  isbn = {978-94-024-0881-2},
  langid = {english}
}

@inproceedings{Arumae2019AnnotatingCreatingSummary,
  title = {Towards {{Annotating}} and {{Creating Summary Highlights}} at {{Sub-sentence Level}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{New Frontiers}} in {{Summarization}}},
  author = {Arumae, Kristjan and Bhatia, Parminder and Liu, Fei},
  year = {2019},
  month = nov,
  pages = {64--69},
  publisher = {Association for Computational Linguistics},
  address = {Hong Kong, China},
  doi = {10.18653/v1/D19-5408},
  urldate = {2023-10-26},
  abstract = {Highlighting is a powerful tool to pick out important content and emphasize. Creating summary highlights at the sub-sentence level is particularly desirable, because sub-sentences are more concise than whole sentences. They are also better suited than individual words and phrases that can potentially lead to disfluent, fragmented summaries. In this paper we seek to generate summary highlights by annotating summary-worthy sub-sentences and teaching classifiers to do the same. We frame the task as jointly selecting important sentences and identifying a single most informative textual unit from each sentence. This formulation dramatically reduces the task complexity involved in sentence compression. Our study provides new benchmarks and baselines for generating highlights at the sub-sentence level.}
}

@article{Arumugam2022DevelopmentArgumentBased,
  title = {Development of Argument Based Opinion Mining Model with Sentimental Data Analysis from Twitter Content},
  author = {Arumugam, S. S.},
  year = {2022},
  journal = {Concurrency and Computation: Practice and Experience},
  volume = {34},
  number = {15},
  pages = {e6956},
  issn = {1532-0634},
  doi = {10.1002/cpe.6956},
  urldate = {2023-10-20},
  abstract = {In present scenario, social networks have developed massive in practice and society impact. Specifically, micro-blogging is on trend in various platforms, such as Twitter, Instagram to evaluate public opinions for various issues. In recent times, some methods are developed for evaluating Twitter messages, based on the sentiment and opinions presented in tweets, corresponding to the hash-tags and keywords. However, these models have some issues in handling the contradictory content and inconsistent data. Considering with this, this article presents an argument based opinion mining model with sentimental data analysis, for extracting specific argument, which is assessed in bottom-up manner from the content from society emotion's reflects on the messages. Moreover, this model makes the user to pull out the arguments from a document set, which contains content from commercial sites, to extract the mostly argued positive and negative content. This model use natural language processing techniques, extraction of argument words for defining the decisions. The classification Naive Bayes classification is used for categorizing the results widely under agreed or disagreed. The experimental results prove that the proposed model provides feasible and appropriate results in argument analysis from Twitter content.},
  copyright = {{\copyright} 2022 John Wiley \& Sons, Ltd.},
  langid = {english}
}

@phdthesis{Ashley1988ModellingLegalArgument,
  title = {Modelling Legal Argument: Reasoning with Cases and Hypotheticals},
  shorttitle = {Modelling Legal Argument},
  author = {Ashley, Kevin D.},
  year = {1988},
  address = {USA},
  abstract = {This dissertation is about adversarial, case-based reasoning and the HYPO program that performs adversarial reasoning with cases and hypotheticals in the legal domain. The dissertation identifies and describes basic case-based operations, an adversarial, case-based reasoning process, a schematic structure for case-based arguments, the kinds of counter-examples that arise and the knowledge sources necessary to support adversarial, case-based reasoning. The HYPO program embodies the methodology. It comprises: (1) a structured Case Knowledge Base ("CKB") of actual legal cases; (2) an indexing scheme ("dimensions") for retrieval of relevant cases from the CKB; (3) methods for analyzing problem situations and retrieving relevant cases; (4) methods for interpreting and assessing the relevancy of past cases by "positioning" the problem situation with respect to relevant existing cases in the CKB as seen from the viewpoint of the problem at hand and finding the most-on-point cases; (5) methods for comparing/contrasting cases (e.g., citing, distinguishing, finding counter-examples); (6) methods for posing hypotheticals that test the sensitivity of the problem situation to changes, particularly with regard to potentially adverse effects of new damaging facts coming to light and existing favorable ones being discredited; (7) methods for generating "3-ply" argument outlines to play out realistic legal arguments citing cases in a manner familiar to attorneys; and (8) methods for explaining alternative decisions of the problem situation by posing hypotheticals, comparing arguments and summarizing the precedents. HYPO's performance compares favorably to that of judges and attorneys in actual legal cases. The law is an excellent domain to study case-based reasoning since by its very nature it: (1) espouses a doctrine of precedent in which prior cases are the primary tools for justifying legal conclusions; and (2) employs precedential reasoning to make up for the lack of strong domain models with which to reason deductively about problem situations. The law is also a paradigm for adversarial case-based reasoning; there are "no right answers", only arguments pitting interpretations of cases and facts against each other. The dissertation addresses issues of central concern to Artificial Intelligence including: relevance and credit assignment, indexing and inference control, argumentation, analogical reasoning and explanation.},
  school = {University of Massachusetts},
  annotation = {Order No: GAX88-13198}
}

@inproceedings{Ashley1997ReasoningSymbolicallyPartially,
  title = {Reasoning {{Symbolically About Partially Matched Cases}}},
  booktitle = {Proceedings of the 15th {{International Joint Conference}} on {{Artifical Intelligence}} - {{Volume}} 1},
  author = {Ashley, Kevin D. and Aleven, Vincent},
  year = {1997},
  series = {{{IJCAI}}'97},
  pages = {335--341},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco, CA, USA},
  urldate = {2019-08-20},
  abstract = {In teaching case-based argumentation skills, the CATO program, an intelligent learning environment, guides students' assessments of partial matches between problems and cases by generating alternative interpretations of the similarities and differences. CATO's Factor Hierarchy captures information about the significance of similarities and differences given the normative purposes of the domain classification. Its algorithms for emphasizing or downplaying significance tailor interpretations to the comparison context, block interpretations strongly contradicted by other factors and strategically determine how and how abstractly to characterize a difference. An empirical evaluation confirmed CATO's effectiveness in teaching basic argumentation skills.}
}

@inproceedings{Asowo2025EnsembleModellingFeature,
  title = {An {{Ensemble Modelling}} of~{{Feature Engineering}} and~{{Predictions}} for~{{Enhanced Fake News Detection}}},
  booktitle = {Artificial {{Intelligence XLI}}},
  author = {Asowo, Patricia and Lal, Sangeeta and Ani, Uchenna Daniel},
  editor = {Bramer, Max and Stahl, Frederic},
  year = {2025},
  pages = {225--231},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-77918-3_16},
  abstract = {The threat of fake news jeopardizing the credibility of online news platforms, particularly on social media, underscores the need for innovative solutions. This paper proposes a creative engine for detecting fake news, leveraging advanced machine learning techniques, specifically Bidirectional En-coder Representations by Transformers (BERT). Our approach involves feature selection from news content and social contexts, combining predictions from multiple models, including Random Forest, BERT, GRU, LSTM, and a voting ensemble model. Through extensive evaluation of the WELFake dataset, our method highlights an impressive accuracy of 99\%, surpassing baselines and existing systems. Our study highlights the crucial role of hyperparameter tuning, improving the performance of the BERT model to 100\%.},
  isbn = {978-3-031-77918-3},
  langid = {english}
}

@misc{AssociationForComputationalLinguistics2019POSTaggingState,
  title = {{{POS Tagging}} ({{State}} of the Art)},
  author = {{Association for Computational Linguistics}},
  year = {2019},
  month = mar,
  urldate = {2021-02-09},
  howpublished = {https://aclweb.org/aclwiki/POS\_Tagging\_(State\_of\_the\_art)}
}

@inproceedings{Auer2007DBpediaNucleusWeb,
  title = {{{DBpedia}}: {{A Nucleus}} for a {{Web}} of {{Open Data}}},
  shorttitle = {{{DBpedia}}},
  booktitle = {The {{Semantic Web}}},
  author = {Auer, S{\"o}ren and Bizer, Christian and Kobilarov, Georgi and Lehmann, Jens and Cyganiak, Richard and Ives, Zachary},
  editor = {Aberer, Karl and Choi, Key-Sun and Noy, Natasha and Allemang, Dean and Lee, Kyung-Il and Nixon, Lyndon and Golbeck, Jennifer and Mika, Peter and Maynard, Diana and Mizoguchi, Riichiro and Schreiber, Guus and {Cudr{\'e}-Mauroux}, Philippe},
  year = {2007},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {722--735},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-76298-0_52},
  abstract = {DBpedia is a community effort to extract structured information from Wikipedia and to make this information available on the Web. DBpedia allows you to ask sophisticated queries against datasets derived from Wikipedia and to link other datasets on the Web to Wikipedia data. We describe the extraction of the DBpedia datasets, and how the resulting information is published on the Web for human- and machine-consumption. We describe some emerging applications from the DBpedia community and show how website authors can facilitate DBpedia content within their sites. Finally, we present the current status of interlinking DBpedia with other open datasets on the Web and outline how DBpedia could serve as a nucleus for an emerging Web of open data.},
  isbn = {978-3-540-76298-0},
  langid = {english}
}

@misc{Ayoobi2024ProtoArgNetInterpretableImage,
  title = {{{ProtoArgNet}}: {{Interpretable Image Classification}} with {{Super-Prototypes}} and {{Argumentation}} [{{Technical Report}}]},
  shorttitle = {{{ProtoArgNet}}},
  author = {Ayoobi, Hamed and Potyka, Nico and Toni, Francesca},
  year = {2024},
  month = aug,
  number = {arXiv:2311.15438},
  eprint = {2311.15438},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.15438},
  urldate = {2024-12-19},
  abstract = {We propose ProtoArgNet, a novel interpretable deep neural architecture for image classification in the spirit of prototypical-part-learning as found, e.g., in ProtoPNet. While earlier approaches associate every class with multiple prototypical-parts, ProtoArgNet uses super-prototypes that combine prototypical-parts into a unified class representation. This is done by combining local activations of prototypes in an MLP-like manner, enabling the localization of prototypes and learning (non-linear) spatial relationships among them. By leveraging a form of argumentation, ProtoArgNet is capable of providing both supporting (i.e. `this looks like that') and attacking (i.e. `this differs from that') explanations. We demonstrate on several datasets that ProtoArgNet outperforms state-of-the-art prototypical-part-learning approaches. Moreover, the argumentation component in ProtoArgNet is customisable to the user's cognitive requirements by a process of sparsification, which leads to more compact explanations compared to state-of-the-art approaches.},
  archiveprefix = {arXiv}
}

@misc{Baek2024ResearchAgentIterativeResearch,
  title = {{{ResearchAgent}}: {{Iterative Research Idea Generation}} over {{Scientific Literature}} with {{Large Language Models}}},
  shorttitle = {{{ResearchAgent}}},
  author = {Baek, Jinheon and Jauhar, Sujay Kumar and Cucerzan, Silviu and Hwang, Sung Ju},
  year = {2024},
  month = apr,
  number = {arXiv:2404.07738},
  eprint = {2404.07738},
  primaryclass = {cs},
  doi = {10.48550/arXiv.2404.07738},
  urldate = {2024-04-16},
  abstract = {Scientific Research, vital for improving human life, is hindered by its inherent complexity, slow pace, and the need for specialized experts. To enhance its productivity, we propose a ResearchAgent, a large language model-powered research idea writing agent, which automatically generates problems, methods, and experiment designs while iteratively refining them based on scientific literature. Specifically, starting with a core paper as the primary focus to generate ideas, our ResearchAgent is augmented not only with relevant publications through connecting information over an academic graph but also entities retrieved from an entity-centric knowledge store based on their underlying concepts, mined and shared across numerous papers. In addition, mirroring the human approach to iteratively improving ideas with peer discussions, we leverage multiple ReviewingAgents that provide reviews and feedback iteratively. Further, they are instantiated with human preference-aligned large language models whose criteria for evaluation are derived from actual human judgments. We experimentally validate our ResearchAgent on scientific publications across multiple disciplines, showcasing its effectiveness in generating novel, clear, and valid research ideas based on human and model-based evaluation results.},
  archiveprefix = {arXiv}
}

@misc{Balaguer2024RAGVsFinetuning,
  title = {{{RAG}} vs {{Fine-tuning}}: {{Pipelines}}, {{Tradeoffs}}, and a {{Case Study}} on {{Agriculture}}},
  shorttitle = {{{RAG}} vs {{Fine-tuning}}},
  author = {Balaguer, Angels and Benara, Vinamra and Cunha, Renato Luiz de Freitas and Filho, Roberto de M. Estev{\~a}o and Hendry, Todd and Holstein, Daniel and Marsman, Jennifer and Mecklenburg, Nick and Malvar, Sara and Nunes, Leonardo O. and Padilha, Rafael and Sharp, Morris and Silva, Bruno and Sharma, Swati and Aski, Vijay and Chandra, Ranveer},
  year = {2024},
  month = jan,
  number = {arXiv:2401.08406},
  eprint = {2401.08406},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.08406},
  urldate = {2024-09-03},
  abstract = {There are two common ways in which developers are incorporating proprietary and domain-specific data when building applications of Large Language Models (LLMs): Retrieval-Augmented Generation (RAG) and Fine-Tuning. RAG augments the prompt with the external data, while fine-Tuning incorporates the additional knowledge into the model itself. However, the pros and cons of both approaches are not well understood. In this paper, we propose a pipeline for fine-tuning and RAG, and present the tradeoffs of both for multiple popular LLMs, including Llama2-13B, GPT-3.5, and GPT-4. Our pipeline consists of multiple stages, including extracting information from PDFs, generating questions and answers, using them for fine-tuning, and leveraging GPT-4 for evaluating the results. We propose metrics to assess the performance of different stages of the RAG and fine-Tuning pipeline. We conduct an in-depth study on an agricultural dataset. Agriculture as an industry has not seen much penetration of AI, and we study a potentially disruptive application - what if we could provide location-specific insights to a farmer? Our results show the effectiveness of our dataset generation pipeline in capturing geographic-specific knowledge, and the quantitative and qualitative benefits of RAG and fine-tuning. We see an accuracy increase of over 6 p.p. when fine-tuning the model and this is cumulative with RAG, which increases accuracy by 5 p.p. further. In one particular experiment, we also demonstrate that the fine-tuned model leverages information from across geographies to answer specific questions, increasing answer similarity from 47\% to 72\%. Overall, the results point to how systems built using LLMs can be adapted to respond and incorporate knowledge across a dimension that is critical for a specific industry, paving the way for further applications of LLMs in other industrial domains.},
  archiveprefix = {arXiv}
}

@article{Balakrishnan2014StemmingLemmatizationComparison,
  title = {Stemming and {{Lemmatization}}: {{A Comparison}} of {{Retrieval Performances}}},
  shorttitle = {Stemming and {{Lemmatization}}},
  author = {Balakrishnan, Vimala and Ethel, Lloyd-Yemoh},
  year = {2014},
  journal = {Lecture Notes on Software Engineering},
  volume = {2},
  number = {3},
  pages = {262--267},
  issn = {23013559},
  doi = {10.7763/LNSE.2014.V2.134},
  urldate = {2021-03-08},
  abstract = {The current study proposes to compare document retrieval precision performances based on language modeling techniques, particularly stemming and lemmatization. Stemming is a procedure to reduce all words with the same stem to a common form whereas lemmatization removes inflectional endings and returns the base or dictionary form of a word. Comparisons were also made between these two techniques with a baseline ranking algorithm (i.e. with no language processing). A search engine was developed and the algorithms were tested based on a test collection. Both mean average precisions and histograms indicate stemming and lemmatization to outperform the baseline algorithm. As for the language modeling techniques, lemmatization produced better precision compared to stemming, however the differences are insignificant. Overall the findings suggest that language modeling techniques improves document retrieval, with lemmatization technique producing the best result.}
}

@inproceedings{Baltes2018SOTorrentReconstructingAnalyzing,
  title = {{{SOTorrent}}: Reconstructing and Analyzing the Evolution of Stack Overflow Posts},
  shorttitle = {{{SOTorrent}}},
  booktitle = {Proceedings of the 15th {{International Conference}} on {{Mining Software Repositories}}},
  author = {Baltes, Sebastian and Dumani, Lorik and Treude, Christoph and Diehl, Stephan},
  year = {2018},
  month = may,
  series = {{{MSR}} '18},
  pages = {319--330},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3196398.3196430},
  urldate = {2021-03-18},
  abstract = {Stack Overflow (SO) is the most popular question-and-answer website for software developers, providing a large amount of code snippets and free-form text on a wide variety of topics. Like other software artifacts, questions and answers on SO evolve over time, for example when bugs in code snippets are fixed, code is updated to work with a more recent library version, or text surrounding a code snippet is edited for clarity. To be able to analyze how content on SO evolves, we built SOTorrent, an open dataset based on the official SO data dump. SOTorrent provides access to the version history of SO content at the level of whole posts and individual text or code blocks. It connects SO posts to other platforms by aggregating URLs from text blocks and by collecting references from GitHub files to SO posts. In this paper, we describe how we built SOTorrent, and in particular how we evaluated 134 different string similarity metrics regarding their applicability for reconstructing the version history of text and code blocks. Based on a first analysis using the dataset, we present insights into the evolution of SO posts, e.g., that post edits are usually small, happen soon after the initial creation of the post, and that code is rarely changed without also updating the surrounding text. Further, our analysis revealed a close relationship between post edits and comments. Our vision is that researchers will use SOTorrent to investigate and understand the evolution of SO posts and their relation to other platforms such as GitHub.},
  isbn = {978-1-4503-5716-6}
}

@inproceedings{Banarescu2013AbstractMeaningRepresentation,
  title = {Abstract {{Meaning Representation}} for {{Sembanking}}},
  booktitle = {Proceedings of the 7th {{Linguistic Annotation Workshop}} and {{Interoperability}} with {{Discourse}}},
  author = {Banarescu, Laura and Bonial, Claire and Cai, Shu and Georgescu, Madalina and Griffitt, Kira and Hermjakob, Ulf and Knight, Kevin and Koehn, Philipp and Palmer, Martha and Schneider, Nathan},
  year = {2013},
  month = aug,
  pages = {178--186},
  publisher = {Association for Computational Linguistics},
  address = {Sofia, Bulgaria},
  urldate = {2020-10-16}
}

@inproceedings{Bao2022GenerativeModelEndtoEnd,
  title = {A {{Generative Model}} for {{End-to-End Argument Mining}} with {{Reconstructed Positional Encoding}} and {{Constrained Pointer Mechanism}}},
  booktitle = {Proceedings of the 2022 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Bao, Jianzhu and He, Yuhang and Sun, Yang and Liang, Bin and Du, Jiachen and Qin, Bing and Yang, Min and Xu, Ruifeng},
  editor = {Goldberg, Yoav and Kozareva, Zornitsa and Zhang, Yue},
  year = {2022},
  month = dec,
  pages = {10437--10449},
  publisher = {Association for Computational Linguistics},
  address = {Abu Dhabi, United Arab Emirates},
  doi = {10.18653/v1/2022.emnlp-main.713},
  urldate = {2024-02-10},
  abstract = {Argument mining (AM) is a challenging task as it requires recognizing the complex argumentation structures involving multiple subtasks. To handle all subtasks of AM in an end-to-end fashion, previous works generally transform AM into a dependency parsing task. However, such methods largely require complex pre- and post-processing to realize the task transformation. In this paper, we investigate the end-to-end AM task from a novel perspective by proposing a generative framework, in which the expected outputs of AM are framed as a simple target sequence. Then, we employ a pre-trained sequence-to-sequence language model with a constrained pointer mechanism (CPM) to model the clues for all the subtasks of AM in the light of the target sequence. Furthermore, we devise a reconstructed positional encoding (RPE) to alleviate the order biases induced by the autoregressive generation paradigm. Experimental results show that our proposed framework achieves new state-of-the-art performance on two AM benchmarks.}
}

@misc{Bargnesi2014Jsongraphspecification,
  title = {Json-Graph-Specification},
  author = {Bargnesi, Tony and Hayes, William},
  year = {2014},
  month = may,
  urldate = {2022-04-22},
  abstract = {A proposal for representing graph structure (nodes / edges) in JSON.},
  howpublished = {JSON Graph}
}

@inproceedings{Baroni2014DonCountPredict,
  title = {Don't Count, Predict! {{A}} Systematic Comparison of Context-Counting vs. Context-Predicting Semantic Vectors},
  booktitle = {Proceedings of the 52nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Baroni, Marco and Dinu, Georgiana and Kruszewski, Germ{\'a}n},
  year = {2014},
  month = jun,
  pages = {238--247},
  publisher = {Association for Computational Linguistics},
  address = {Baltimore, Maryland},
  doi = {10.3115/v1/P14-1023},
  urldate = {2021-02-07}
}

@phdthesis{Bartz2024VisionBasedSimilarityComputation,
  type = {Bachelor's {{Thesis}}},
  title = {Vision-{{Based Similarity Computation}} for {{Case-Based Retrieval}} of {{Argument Graphs}}},
  author = {Bartz, Kilian},
  year = {2024},
  month = apr,
  address = {Trier, Germany},
  abstract = {Over the last few years, there has been a surge of interest in Artificial Intelligence (AI) vision models, however, using them for automatic processing of drawn natural visual representations like graphs has not yet been evaluated. This could enable many new applications, especially the implementation of a fast and scalable retrieval for argumentation machines. In this thesis, I propose a new approach to implement structural retrieval in the context of a case-based argumentation machine using a Swin Transformer v2 model to trans- form visualized Argument Graphs (AGs) into dense embeddings on which similarities can be calculated very efficiently. In an experimental, iterative approach, I conceptualize multiple suitable visualization designs based on node-link graph drawings and treemaps, which aim to capture an AG's structure. These visualizations are used to train corresponding vision models for the embedding process. I demonstrate that even though treemap-based designs show more promising training behavior, more comprehensive node-link drawings exhibit better retrieval performance for complex queries. The A* search from previous works outperforms vision-based argument retrieval for simple queries; however, a higher query complexity noticeably increases the quality of vision-based argument retrieval. Furthermore, vision-based similarity computation can improve computation times by several orders of magnitude and also exhibits promising scaling of retrieval quality with larger training data sets and longer training durations. However, due to the complex and opaque information processing of Transformer models, the structural similarity values produced by the vision-based approach can be unpredictable and counterintuitive. Additionally, vision-based argument retrieval does not represent a complete replacement for A* search as it does not provide mappings from the query to the case base arguments.},
  langid = {english},
  school = {Trier University}
}

@inproceedings{Baydin2011CBRCommonsenseReasoning,
  title = {{{CBR}} with {{Commonsense Reasoning}} and {{Structure Mapping}}: {{An Application}} to {{Mediation}}},
  shorttitle = {{{CBR}} with {{Commonsense Reasoning}} and {{Structure Mapping}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Baydin, At{\i}l{\i}m G{\"u}ne{\c s} and {L{\'o}pez de M{\'a}ntaras}, Ramon and Simoff, Simeon and Sierra, Carles},
  editor = {Ram, Ashwin and Wiratunga, Nirmalie},
  year = {2011},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {378--392},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-23291-6_28},
  abstract = {Mediation is an important method in dispute resolution. We implement a case based reasoning approach to mediation integrating analogical and commonsense reasoning components that allow an artificial mediation agent to satisfy requirements expected from a human mediator, in particular: utilizing experience with cases in different domains; and structurally transforming the set of issues for a better solution. We utilize a case structure based on ontologies reflecting the perceptions of the parties in dispute. The analogical reasoning component, employing the Structure Mapping Theory from psychology, provides a flexibility to respond innovatively in unusual circumstances, in contrast with conventional approaches confined into specialized problem domains. We aim to build a mediation case base incorporating real world instances ranging from interpersonal or intergroup disputes to international conflicts.},
  isbn = {978-3-642-23291-6},
  langid = {english}
}

@inproceedings{Becker2017EnrichingArgumentativeTexts,
  title = {Enriching {{Argumentative Texts}} with {{Implicit Knowledge}}},
  booktitle = {Natural {{Language Processing}} and {{Information Systems}}},
  author = {Becker, Maria and Staniek, Michael and Nastase, Vivi and Frank, Anette},
  editor = {Frasincar, Flavius and Ittoo, Ashwin and Nguyen, Le Minh and M{\'e}tais, Elisabeth},
  year = {2017},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {84--96},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-59569-6_9},
  abstract = {Retrieving information that is implicit in a text is difficult. For argument analysis, revealing implied knowledge could be useful to judge how solid an argument is and to construct concise arguments. We design a process for obtaining high-quality implied knowledge annotations for German argumentative microtexts, in the form of simple natural language statements. This process involves several steps to promote agreement and monitors its evolution using textual similarity computation. To further characterize the implied knowledge, we annotate the added sentences with semantic clause types and common sense knowledge relations. To test whether the knowledge could be retrieved automatically, we compare the inserted sentences to Wikipedia articles on similar topics. Analysis of the added knowledge shows that (i) it is characterized by a high proportion of generic sentences, (ii) a majority of it can be mapped to common sense knowledge relations, and (iii) it is similar to sentences found in Wikipedia.},
  isbn = {978-3-319-59569-6},
  langid = {english}
}

@inproceedings{Becker2019AssessingDifficultyClassifying,
  title = {Assessing the {{Difficulty}} of {{Classifying ConceptNet Relations}} in a {{Multi-Label Classification Setting}}},
  booktitle = {{{RELATIONS}} - {{Workshop}} on Meaning Relations between Phrases and Sentences},
  author = {Becker, Maria and Staniek, Michael and Nastase, Vivi and Frank, Anette},
  year = {2019},
  month = may,
  publisher = {Association for Computational Linguistics},
  address = {Gothenburg, Sweden},
  doi = {10.18653/v1/W19-0801},
  urldate = {2020-09-09},
  abstract = {Commonsense knowledge relations are crucial for advanced NLU tasks. We examine the learnability of such relations as represented in ConceptNet, taking into account their specific properties, which can make relation classification difficult: a given concept pair can be linked by multiple relation types, and relations can have multi-word arguments of diverse semantic types. We explore a neural open world multi-label classification approach that focuses on the evaluation of classification accuracy for individual relations. Based on an in-depth study of the specific properties of the ConceptNet resource, we investigate the impact of different relation representations and model variations. Our analysis reveals that the complexity of argument types and relation ambiguity are the most important challenges to address. We design a customized evaluation method to address the incompleteness of the resource that can be expanded in future work.}
}

@article{Becker2020ExplainingArgumentsBackground,
  title = {Explaining {{Arguments}} with {{Background Knowledge}}},
  author = {Becker, Maria and Hulpu{\c s}, Ioana and Opitz, Juri and Paul, Debjit and Kobbe, Jonathan and Stuckenschmidt, Heiner and Frank, Anette},
  year = {2020},
  month = jul,
  journal = {Datenbank-Spektrum},
  volume = {20},
  number = {2},
  pages = {131--141},
  issn = {1610-1995},
  doi = {10.1007/s13222-020-00348-6},
  urldate = {2020-09-09},
  abstract = {Most information we consume as a~society is obtained over the Web. News -- often from questionable sources -- are spread online, as are election campaigns; calls for (collective) action spread with unforeseen speed and intensity. All such actions have argumentation at their core, and the conveyed content is often strategically selected or rhetorically framed. The responsibility of critical analysis of arguments is thus tacitly transferred to the content consumer who is often not prepared for the task, nor aware of the responsibility.},
  langid = {english}
}

@phdthesis{Becker2023InstructiveArgumentMining,
  title = {Instructive {{Argument Mining}} with {{Large Language Models}}},
  author = {Becker, Michael and Nanyan, Karine},
  year = {2023},
  month = sep,
  address = {Trier, Germany},
  abstract = {Understanding the argumentative structure of texts is important for decision-making, problem-solving, and knowledge exchange across various fields. While manual argument extraction has been the traditional approach, computers have enabled argument mining: the automatic extraction of arguments. In our research, we focus on solving argument mining tasks using Large Language Models (LLMs) which are artificial intelligence algorithms trained on large amounts of data and can produce human-like responses to natural language queries. Specifically, we conduct a comparative analysis of state-of-the-art closed-source LLMs, OpenAI's GPT-3.5 and GPT-4 and an open-source LLM, Meta's Llama 2, which is fine-tuned on the task of argument mining, i.e., trained on specific argumentative datasets to enhance its performance in this task. Our evaluation involves the comparison of the performance of these LLMs against each other and against an existing end-to-end argument mining pipeline. Our findings reveal that LLMs perform impressively well and outperform the argument mining pipeline. This suggests that they can play a major role in advancing accurate argument mining and understanding of complex argumentative structures.},
  langid = {english},
  school = {Trier University}
}

@incollection{Beckwith1998DesignImplementationWordNet,
  title = {Design and {{Implementation}} of the {{WordNet Lexical Database}} and {{Searching Software}}},
  booktitle = {{{WordNet}}},
  author = {Beckwith, Richard and Miller, George A. and Tengi, Randee},
  editor = {Fellbaum, Christiane},
  year = {1998},
  publisher = {The MIT Press},
  doi = {10.7551/mitpress/7287.003.0009},
  urldate = {2021-02-12},
  isbn = {978-0-262-27255-1},
  langid = {english}
}

@article{Bench-Capon2020DungArgumentationAI,
  title = {Before and after {{Dung}}: {{Argumentation}} in {{AI}} and {{Law}}},
  shorttitle = {Before and after {{Dung}}},
  author = {{Bench-Capon}, T. J. M.},
  year = {2020},
  month = jan,
  journal = {Argument \& Computation},
  volume = {11},
  number = {1-2},
  pages = {221--238},
  publisher = {IOS Press},
  issn = {1946-2166},
  doi = {10.3233/AAC-190477},
  urldate = {2021-01-17},
  abstract = {Dung's abstract argumentation frameworks have had a very significant role in the rise in interest in argumentation throughout this century. In this paper we will explore the impact of this seminal idea on a specific application domain, AI and Law. Ar},
  langid = {english}
}

@article{Benett1954CommunicationsLimitedResponseQuestioning,
  title = {Communications {{Through Limited-Response Questioning}}*},
  author = {Benett, E. M. and Alpert, R. and Goldstein, A. C.},
  year = {1954},
  month = jan,
  journal = {Public Opinion Quarterly},
  volume = {18},
  number = {3},
  pages = {303--308},
  issn = {0033-362X},
  doi = {10.1086/266520},
  urldate = {2021-03-07},
  abstract = {The extent of consistency between information from two methods of communication, the interview and the limited-response question, was investigated. Thirty questions showed consistencies greater than could be expected on the basis of chance. The questions were classified into four general categories, and the mean coefficients of consistency for these categories ranged from 0.46 to 1.00.}
}

@book{Bergmann2002ExperienceManagement,
  title = {Experience {{Management}}},
  editor = {Bergmann, Ralph and Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan and Carbonell, Jaime G. and Siekmann, J{\"o}rg},
  year = {2002},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {2432},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-45759-3},
  urldate = {2024-04-01},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-540-44191-5 978-3-540-45759-6}
}

@article{Bergmann2009CaseBasedReasoningIntroduction,
  title = {Case-{{Based Reasoning}} - {{Introduction}} and {{Recent Developments}}},
  author = {Bergmann, Ralph and Minor, Mirjam and Althoff, Klaus-Dieter and Reichle, Meike and Bach, Kerstin},
  year = {2009},
  month = jan,
  journal = {KI - K{\"u}nstliche Intelligenz, German Journal on Artificial Intelligence - Organ des Fachbereiches K{\"u}nstliche Intelligenz der Gesellschaft f{\"u}r Informatik e.V. KI},
  volume = {1/2009},
  number = {Case-Based Reasoning},
  pages = {5--11},
  urldate = {2018-09-02},
  abstract = {Case-based reasoning (CBR) is a sub-field of Artificial Intelligence that deals with experience-based problem solving. CBR has its roots in different disciplines such as cognitive science, machine learning, and knowledge-based systems. Today, it is a well established research field of its own, which produced a rich variety of specific methods, as well as applications implementing those methods for particular tasks and domains. This paper gives a compact overview of CBR in general and further discusses recent advancements in selected topics.}
}

@article{Bergmann2014SimilarityAssessmentEfficient,
  title = {Similarity Assessment and Efficient Retrieval of Semantic Workflows},
  author = {Bergmann, Ralph and Gil, Yolanda},
  year = {2014},
  month = mar,
  journal = {Information Systems},
  volume = {40},
  pages = {115--127},
  issn = {0306-4379},
  doi = {10.1016/j.is.2012.07.005},
  urldate = {2018-09-01},
  abstract = {In the recent years, the use of workflows has significantly expanded from its orig- inal domain of business processes towards new areas. The increasing demand for individual and more flexible workflows asks for new methods that support domain experts to create, monitor, and adapt workflows. The emergent field of process-oriented case-based reasoning addresses this problem by proposing methods for reasoning with workflows based on experience. New workflows can be constructed by reuse of already available similar workflows from a repository. Hence, methods for the similarity assessment of workflows and for the efficient retrieval of similar workflows from a repository are of core importance. To this end, we describe a new generic model for representing workflows as semantically labeled graphs, together with a related model for knowledge intensive similarity measures. Further, new algorithms for workflow similarity computation, based on A* search are described. A new retrieval algorithm is introduced that goes beyond traditional sequential retrieval for graphs, interweaving similarity com- putation with case selection. We describe the application of this model and several experimental evaluations of the algorithms in the domain of scientific workflows and in the domain of business workflows, thereby showing its broad applicability.}
}

@inproceedings{Bergmann2018ReCAPInformationRetrieval,
  title = {{{ReCAP}} - {{Information Retrieval}} and {{Case-Based Reasoning}} for {{Robust Deliberation}} and {{Synthesis}} of {{Arguments}} in the {{Political Discourse}}},
  booktitle = {Proceedings of the {{Conference}} "{{Lernen}}, {{Wissen}}, {{Daten}}, {{Analysen}}"},
  author = {Bergmann, Ralph and Schenkel, Ralf and Dumani, Lorik and Ollinger, Stefan},
  editor = {Gemulla, Rainer and Ponzetto, Simone Paolo and Bizer, Christian and Keuper, Margret and Stuckenschmidt, Heiner},
  year = {2018},
  month = aug,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {2191},
  pages = {49--60},
  publisher = {CEUR},
  address = {Mannheim, Germany},
  issn = {1613-0073},
  urldate = {2024-12-11},
  langid = {english}
}

@incollection{Bergmann2018SimilarityBasedRetrievalAutomatic,
  title = {Similarity-{{Based Retrieval}} and {{Automatic Adaptation}} of {{Semantic Workflows}}},
  booktitle = {Synergies {{Between Knowledge Engineering}} and {{Software Engineering}}},
  author = {Bergmann, Ralph and M{\"u}ller, Gilbert},
  editor = {Nalepa, Grzegorz J. and Baumeister, Joachim},
  year = {2018},
  volume = {626},
  pages = {31--54},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-64161-4_2},
  urldate = {2019-08-20},
  abstract = {The increasing demand for individual and more flexible process models and workflows asks for new intelligent process-oriented information systems. Such systems should, among other things, support domain experts in the creation and adaptation of process models or workflows. For this purpose, repositories of best practice workflows are an important means as they collect valuable experiential knowledge that can be reused in various ways. In this chapter we present process-oriented case-based reasoning (POCBR) as a method to support the creation and adaptation of workflows based on such knowledge. We provide a general introduction to process-oriented case-based reasoning and present a concise view of the POCBR methods we developed during the past ten years. This includes graph-based representation of semantic workflows, semantic workflow similarity, similarity-based retrieval, and workflow adaptation based on automatically learned adaptation knowledge. Finally, we sketch several application domains such as traditional business processes, social workflows, and cooking workflows.},
  isbn = {978-3-319-64160-7 978-3-319-64161-4},
  langid = {english}
}

@inproceedings{Bergmann2019ProCAKEProcessOrientedCaseBased,
  title = {{{ProCAKE}}: {{A Process-Oriented Case-Based Reasoning Framework}}},
  shorttitle = {{{ProCAKE}}},
  booktitle = {Workshops {{Proceedings}} for the {{Twenty-seventh International Conference}} on {{Case-Based Reasoning}}},
  author = {Bergmann, Ralph and Grumbach, Lisa and Malburg, Lukas and Zeyen, Christian},
  editor = {Kapetanakis, Stelios and Borck, Hayley},
  year = {2019},
  month = sep,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {2567},
  pages = {156--161},
  publisher = {CEUR},
  address = {Otzenhausen, Germany},
  issn = {1613-0073},
  urldate = {2024-04-01},
  langid = {english}
}

@inproceedings{Bergmann2019SimilarityMeasuresCaseBased,
  title = {Similarity {{Measures}} for {{Case-Based Retrieval}} of {{Natural Language Argument Graphs}} in {{Argumentation Machines}}},
  booktitle = {Proceedings of the {{Thirty-Second International Florida Artificial Intelligence Research Society Conference}}},
  author = {Bergmann, Ralph and Lenz, Mirko and Ollinger, Stefan and Pfister, Maximilian},
  editor = {Bart{\'a}k, Roman and Brawner, Keith W.},
  year = {2019-05-19/2019-05-22},
  pages = {329--334},
  publisher = {AAAI Press},
  address = {Sarasota, Florida, USA},
  abstract = {In the field of argumentation, the vision of robust argumentation machines is investigated. They explore natural language arguments from information sources on the web and reason with them on the knowledge level to actively support the deliberation and synthesis of arguments for a particular user query. We aim at combining methods from case-based reasoning (CBR), information retrieval, and computational argumentation to contribute to the foundations of argumentation machines. In this paper, we focus on the retrieval phase of a CBR approach for an argumentation machine and propose similarity measures for arguments represented as argument graphs. We evaluate the similarity measures on a corpus of annotated micro texts and demonstrate the benefit of semantic similarity measures and the relevance of structural aspects.}
}

@article{Bergmann2020ReCAPProject,
  title = {The {{ReCAP Project}}},
  author = {Bergmann, Ralph and Biertz, Manuel and Dumani, Lorik and Lenz, Mirko and Ludwig, Anna-Katharina and Neumann, Patrick J. and Ollinger, Stefan and Sahitaj, Premtim and Schenkel, Ralf and Witry, Alex},
  year = {2020},
  month = jun,
  journal = {Datenbank-Spektrum},
  volume = {20},
  pages = {93--98},
  issn = {1610-1995},
  doi = {10.1007/s13222-020-00340-0},
  urldate = {2020-06-10},
  abstract = {Argumentation Machines search for arguments in natural language from information sources on the Web and reason with them on the knowledge level to actively support the deliberation and synthesis of arguments for a~particular user query. The recap project is part of the Priority Program ratio and aims at novel contributions to and confluence of methods from information retrieval, knowledge representation, as well as case-based reasoning for the development of future argumentation machines. In this paper we summarise recent research results from the project. In particular, a~new German corpus of 100 semantically annotated argument graphs from the domain of education politics has been created and is made available to the argumentation research community. Further, we discuss a~comprehensive investigation in finding arguments and argument graphs. We introduce a~probabilistic ranking framework for argument retrieval, i.e. for finding good premises for a~designated claim. For finding argument graphs, we developed methods for case-based argument retrieval considering the graph structure of an argument together with textual and ontology-based similarity measures applied to claims, premises, and argument schemes.},
  langid = {english}
}

@article{Besnard2014ConstructingArgumentGraphs,
  title = {Constructing Argument Graphs with Deductive Arguments: A Tutorial},
  shorttitle = {Constructing Argument Graphs with Deductive Arguments},
  author = {Besnard, Philippe and Hunter, Anthony},
  year = {2014},
  month = jan,
  journal = {Argument \& Computation},
  volume = {5},
  number = {1},
  pages = {5--30},
  publisher = {IOS Press},
  issn = {1946-2166},
  doi = {10.1080/19462166.2013.869765},
  urldate = {2020-04-27},
  abstract = {A deductive argument is a pair where the first item is a set of premises, the second item is a claim, and the premises entail the claim. This can be formalised by assuming a logical language for the premises and the claim, and logical entailment (or},
  langid = {english}
}

@article{Besnard2014IntroductionStructuredArgumentation,
  title = {Introduction to Structured Argumentation},
  author = {Besnard, Philippe and Garcia, Alejandro and Hunter, Anthony and Modgil, Sanjay and Prakken, Henry and Simari, Guillermo and Toni, Francesca},
  year = {2014},
  month = jan,
  journal = {Argument \& Computation},
  volume = {5},
  number = {1},
  pages = {1--4},
  publisher = {IOS Press},
  issn = {1946-2166},
  doi = {10.1080/19462166.2013.869764},
  urldate = {2020-05-19},
  abstract = {In abstract argumentation, each argument is regarded as atomic. There is no internal structure to an argument. Also, there is no specification of what is an argument or an attack. They are assumed to be given. This abstract perspective provides many},
  langid = {english}
}

@inproceedings{Bex2010FormalAnalysisAIF,
  title = {A Formal Analysis of the {{AIF}} in Terms of the {{ASPIC}} Framework.},
  booktitle = {{{COMMA}}},
  author = {Bex, Floris and Prakken, Henry and Reed, Chris},
  year = {2010},
  month = jan,
  pages = {99--110},
  doi = {10.3233/978-1-60750-619-5-99}
}

@article{Bex2013ImplementingArgumentWeb,
  title = {Implementing the Argument Web},
  author = {Bex, Floris and Lawrence, John and Snaith, Mark and Reed, Chris},
  year = {2013},
  month = oct,
  journal = {Communications of the ACM},
  volume = {56},
  number = {10},
  pages = {66--73},
  issn = {0001-0782},
  doi = {10.1145/2500891},
  urldate = {2022-04-21},
  abstract = {Improve online public discourse by connecting opinions across blogs, editorials, and social media.}
}

@article{Bex2013LogicalSpecificationsArgument,
  title = {On Logical Specifications of the {{Argument Interchange Format}}},
  author = {Bex, Floris and Modgil, Sanjay and Prakken, Henry and Reed, C},
  year = {2013},
  month = sep,
  journal = {Journal of Logic and Computation},
  volume = {23},
  number = {5},
  pages = {951--989},
  doi = {10.1093/logcom/exs033},
  urldate = {2018-09-01},
  abstract = {The Argument Interchange Format (AIF) has been devised in order to support the interchange of ideas and data between different projects and applications in the area of computational argumentation. In order to support such interchange, an abstract ontology for argumentation is presented, which serves as an interlingua between various more concrete argumentation languages. In this article, we aim to give what is essentially a logical specification of the AIF ontology by mapping the ontology onto the logical ASPIC+~{\dots}}
}

@article{Bex2014ArguBloggingApplicationArgument,
  title = {{{ArguBlogging}}: {{An}} Application for the {{Argument Web}}},
  shorttitle = {{{ArguBlogging}}},
  author = {Bex, Floris and Snaith, Mark and Lawrence, John and Reed, Chris},
  year = {2014},
  month = mar,
  journal = {Journal of Web Semantics},
  volume = {25},
  pages = {9--15},
  issn = {1570-8268},
  doi = {10.1016/j.websem.2014.02.002},
  urldate = {2023-11-24},
  abstract = {In this paper, we present a software tool for `ArguBlogging', which allows users to construct debate and discussions across blogs, linking existing and new online resources to form distributed, structured conversations. Arguments and counterarguments can be posed by giving opinions on one's own blog and replying to other bloggers' posts. The resulting argument structure is connected to the Argument Web, in which argumentative structures are made semantically explicit and machine-processable. We discuss the ArguBlogging tool and the underlying infrastructure and ontology of the Argument Web.}
}

@article{Bhagavatula2020AbductiveCommonsenseReasoning,
  title = {Abductive {{Commonsense Reasoning}}},
  author = {Bhagavatula, Chandra and Bras, Ronan Le and Malaviya, Chaitanya and Sakaguchi, Keisuke and Holtzman, Ari and Rashkin, Hannah and Downey, Doug and Yih, Scott Wen-tau and Choi, Yejin},
  year = {2020},
  month = feb,
  journal = {arXiv:1908.05739 [cs]},
  eprint = {1908.05739},
  primaryclass = {cs},
  urldate = {2020-06-10},
  abstract = {Abductive reasoning is inference to the most plausible explanation. For example, if Jenny finds her house in a mess when she returns from work, and remembers that she left a window open, she can hypothesize that a thief broke into her house and caused the mess, as the most plausible explanation. While abduction has long been considered to be at the core of how people interpret and read between the lines in natural language (Hobbs et al., 1988), there has been relatively little research in support of abductive natural language inference and generation. We present the first study that investigates the viability of language-based abductive reasoning. We introduce a challenge dataset, ART, that consists of over 20k commonsense narrative contexts and 200k explanations. Based on this dataset, we conceptualize two new tasks -- (i) Abductive NLI: a multiple-choice question answering task for choosing the more likely explanation, and (ii) Abductive NLG: a conditional generation task for explaining given observations in natural language. On Abductive NLI, the best model achieves 68.9\% accuracy, well below human performance of 91.4\%. On Abductive NLG, the current best language generators struggle even more, as they lack reasoning capabilities that are trivial for humans. Our analysis leads to new insights into the types of reasoning that deep pre-trained language models fail to perform--despite their strong performance on the related but more narrowly defined task of entailment NLI--pointing to interesting avenues for future research.},
  archiveprefix = {arXiv}
}

@misc{Bharti2017AutomaticKeywordExtraction,
  title = {Automatic {{Keyword Extraction}} for {{Text Summarization}}: {{A Survey}}},
  shorttitle = {Automatic {{Keyword Extraction}} for {{Text Summarization}}},
  author = {Bharti, Santosh Kumar and Babu, Korra Sathya},
  year = {2017},
  month = apr,
  number = {arXiv:1704.03242},
  eprint = {1704.03242},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1704.03242},
  urldate = {2023-10-26},
  abstract = {In recent times, data is growing rapidly in every domain such as news, social media, banking, education, etc. Due to the excessiveness of data, there is a need of automatic summarizer which will be capable to summarize the data especially textual data in original document without losing any critical purposes. Text summarization is emerged as an important research area in recent past. In this regard, review of existing work on text summarization process is useful for carrying out further research. In this paper, recent literature on automatic keyword extraction and text summarization are presented since text summarization process is highly depend on keyword extraction. This literature includes the discussion about different methodology used for keyword extraction and text summarization. It also discusses about different databases used for text summarization in several domains along with evaluation matrices. Finally, it discusses briefly about issues and research challenges faced by researchers along with future direction.},
  archiveprefix = {arXiv}
}

@inproceedings{Biertz2022QualiAssistantExtractingQualia,
  title = {{{QualiAssistant}}: {{Extracting Qualia Structures}} from {{Texts}}},
  shorttitle = {{{QualiAssistant}}},
  booktitle = {Proceedings of the 9th {{Workshop}} on {{Argument Mining}}},
  author = {Biertz, Manuel and Dumani, Lorik and Nilles, Markus and Metzler, Bj{\"o}rn and Schenkel, Ralf},
  year = {2022},
  month = oct,
  pages = {199--208},
  publisher = {International Conference on Computational Linguistics},
  address = {Gyeongju, Republic of Korea},
  urldate = {2022-11-16},
  abstract = {In this paper, we present QualiAssistant, a free and open-source system written in Java for identification and extraction of Qualia structures from any natural language texts having many application scenarios such as argument mining or creating dictionaries. It answers the call for a Qualia bootstrapping tool with a ready-to-use system that can be gradually filled by the community with patterns in multiple languages. Qualia structures express the meaning of lexical items. They describe, e.g., of what kind the item is (formal role), what it includes (constitutive role), how it is brought about (agentive role), and what it is used for (telic role). They are also valuable for various Information Retrieval and NLP tasks. Our application requires search patterns for Qualia structures consisting of POS tag sequences as well as the dataset the user wants to search for Qualias. Samples for both are provided alongside this paper. While samples are in German, QualiAssistant can process all languages for which constituency trees can be generated and patterns are available. Our provided patterns follow a high-precision low-recall design aiming to generate automatic annotations for text mining but can be exchanged easily for other purposes. Our evaluation shows that QualiAssistant is a valuable and reliable tool for finding Qualia structures in unstructured texts.}
}

@inproceedings{Bilu2016ClaimSynthesisPredicate,
  title = {Claim {{Synthesis}} via {{Predicate Recycling}}},
  booktitle = {Proceedings of the 54th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 2: {{Short Papers}})},
  author = {Bilu, Yonatan and Slonim, Noam},
  year = {2016},
  pages = {525--530},
  publisher = {Association for Computational Linguistics},
  address = {Berlin, Germany},
  doi = {10.18653/v1/P16-2085},
  urldate = {2019-08-20},
  abstract = {Computational Argumentation has two main goals - the detection and analysis of arguments on the one hand, and the synthesis of arguments on the other. Much attention has been given to the former, but considerably less to the latter.},
  langid = {english}
}

@inproceedings{BinShiha2025UniversityNewsNew,
  title = {University {{News}}: {{A New Data Source}} for {{NLP Bias Research}}},
  shorttitle = {University {{News}}},
  booktitle = {Artificial {{Intelligence XLI}}},
  author = {Bin Shiha, Rawan and Atwell, Eric and Abbas, Noorhan},
  editor = {Bramer, Max and Stahl, Frederic},
  year = {2025},
  pages = {307--312},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-77915-2_22},
  abstract = {This research explores the use of university news articles for Natural Language Processing (NLP) and gender bias detection. It emphasises the importance of ethical considerations in NLP, advocating for transparency and diversity in dataset selection to ensure fairness. Using techniques such as Sentiment Analysis (SA) and gender-specific language classification, the study reveals a bias towards male possessive terms, indicating gender imbalance in the content. While the Facebook BART-Large-Mnli model demonstrated strong accuracy, it struggled with neutral sentiment, suggesting areas for improvement. The study highlights university news as a valuable dataset for promoting equity and inclusivity in NLP tools, laying the foundation for fairer methodologies.},
  isbn = {978-3-031-77915-2},
  langid = {english}
}

@book{Bird2009NaturalLanguageProcessing,
  title = {Natural {{Language Processing}} with {{Python}}: {{Analyzing Text}} with the {{Natural Language Toolkit}}},
  shorttitle = {Natural {{Language Processing}} with {{Python}}},
  author = {Bird, Steven and Klein, Ewan and Loper, Edward},
  year = {2009},
  month = jun,
  publisher = {O'Reilly Media, Inc.},
  abstract = {This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation. With it, you'll learn how to write Python programs that work with large collections of unstructured text. You'll access richly annotated datasets using a comprehensive range of linguistic data structures, and you'll understand the main algorithms for analyzing the content and structure of written communication.Packed with examples and exercises, Natural Language Processing with Python will help you:Extract information from unstructured text, either to guess the topic or identify "named entities"Analyze linguistic structure in text, including parsing and semantic analysisAccess popular linguistic databases, including WordNet and treebanksIntegrate techniques drawn from fields as diverse as linguistics and artificial intelligenceThis book will help you gain practical skills in natural language processing using the Python programming language and the Natural Language Toolkit (NLTK) open source library. If you're interested in developing web applications, analyzing multilingual news sources, or documenting endangered languages -- or if you're simply curious to have a programmer's perspective on how human language works -- you'll find Natural Language Processing with Python both fascinating and immensely useful.},
  googlebooks = {KGIbfiiP1i4C},
  isbn = {978-0-596-55571-9},
  langid = {english}
}

@article{Bizer2009DBpediaCrystallizationPoint,
  title = {{{DBpedia}} - {{A}} Crystallization Point for the {{Web}} of {{Data}}},
  author = {Bizer, Christian and Lehmann, Jens and Kobilarov, Georgi and Auer, S{\"o}ren and Becker, Christian and Cyganiak, Richard and Hellmann, Sebastian},
  year = {2009},
  month = sep,
  journal = {Journal of Web Semantics},
  series = {The {{Web}} of {{Data}}},
  volume = {7},
  number = {3},
  pages = {154--165},
  issn = {1570-8268},
  doi = {10.1016/j.websem.2009.07.002},
  urldate = {2024-06-15},
  abstract = {The DBpedia project is a community effort to extract structured information from Wikipedia and to make this information accessible on the Web. The resulting DBpedia knowledge base currently describes over 2.6 million entities. For each of these entities, DBpedia defines a globally unique identifier that can be dereferenced over the Web into a rich RDF description of the entity, including human-readable definitions in 30 languages, relationships to other resources, classifications in four concept hierarchies, various facts as well as data-level links to other Web data sources describing the entity. Over the last year, an increasing number of data publishers have begun to set data-level links to DBpedia resources, making DBpedia a central interlinking hub for the emerging Web of Data. Currently, the Web of interlinked data sources around DBpedia provides approximately 4.7 billion pieces of information and covers domains such as geographic information, people, companies, films, music, genes, drugs, books, and scientific publications. This article describes the extraction of the DBpedia knowledge base, the current status of interlinking DBpedia with other data sources on the Web, and gives an overview of applications that facilitate the Web of Data around DBpedia.}
}

@article{Blei2003LatentDirichletAllocation,
  title = {Latent Dirichlet Allocation},
  author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
  year = {2003},
  month = mar,
  journal = {The Journal of Machine Learning Research},
  volume = {3},
  number = {null},
  pages = {993--1022},
  issn = {1532-4435},
  abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.}
}

@article{Blevins2006WordbasedMorphology,
  title = {Word-Based Morphology},
  author = {Blevins, James P.},
  year = {2006},
  month = nov,
  journal = {Journal of Linguistics},
  volume = {42},
  number = {3},
  pages = {531--573},
  publisher = {Cambridge University Press},
  issn = {1469-7742, 0022-2267},
  doi = {10.1017/S0022226706004191},
  urldate = {2021-03-08},
  abstract = {This paper examines two contrasting perspectives on morphological analysis, and considers inflectional patterns that bear on the choice between these alternatives. On what is termed an ABSTRACTIVE perspective, surface word forms are regarded as basic morphotactic units of a grammatical system, with roots, stems and exponents treated as abstractions over a lexicon of word forms. This traditional standpoint is contrasted with the more CONSTRUCTIVE perspective of post-Bloomfieldian models, in which surface word forms are `built' from sub-word units. Part of the interest of this contrast is that it cuts across conventional divisions of morphological models. Thus, realization-based models are morphosyntactically `word-based' in the sense that they regard words as the minimal meaningful units of a grammatical system. Yet morphotactically, these models tend to adopt a constructive `root-based' or `stem-based' perspective. An examination of some form-class patterns in Saami, Estonian and Georgian highlights advantages of an abstractive model, and suggests that these advantages derive from the fact that sets of words often predict other word forms and determine a morphotactic analysis of their parts, whereas sets of sub-word units are of limited predictive value and typically do not provide enough information to recover word forms.},
  langid = {english}
}

@article{Blinowski2022MonolithicVsMicroservice,
  title = {Monolithic vs. {{Microservice Architecture}}: {{A Performance}} and {{Scalability Evaluation}}},
  shorttitle = {Monolithic vs. {{Microservice Architecture}}},
  author = {Blinowski, Grzegorz and Ojdowska, Anna and Przyby{\l}ek, Adam},
  year = {2022},
  journal = {IEEE Access},
  volume = {10},
  pages = {20357--20374},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3152803},
  urldate = {2023-11-21},
  abstract = {Context. Since its proclamation in 2012, microservices-based architecture has gained widespread popularity due to its advantages, such as improved availability, fault tolerance, and horizontal scalability, as well as greater software development agility. Motivation. Yet, refactoring a monolith to microservices by smaller businesses and expecting that the migration will bring benefits similar to those reported by top global companies, such as Netflix, Amazon, eBay, and Uber, might be an illusion. Indeed, for systems that do not have thousands of concurrent users and can be scaled vertically, the benefits of such migration have not been sufficiently investigated, while the existing evidence is inconsistent. Objective. The purpose of this paper is to compare the performance and scalability of monolithic and microservice architectures on a reference web application. Method. The application was implemented in four different versions, covering not only two different architectural styles (monolith vs. microservices) but also two different implementation technologies (Java vs. C\#.NET). Next, we conducted a series of controlled experiments in three different deployment environments (local, Azure Spring Cloud, and Azure App Service). Findings. The key lessons learned are as follows: (1) on a single machine, a monolith performs better than its microservice-based counterpart; (2) The Java platform makes better use of powerful machines in case of computation-intensive services when compared to.NET; the technology platform effect is reversed when non-computationally intensive services are run on machines with low computational capacity; (3) vertical scaling is more cost-effective than horizontal scaling in the Azure cloud; (4) scaling out beyond a certain number of instances degrades the application performance; (5) implementation technology (either Java or C\#.NET) does not have a noticeable impact on the scalability performance.}
}

@incollection{Block2019ClusteringArgumentGraphs,
  title = {Clustering of {{Argument Graphs Using Semantic Similarity Measures}}},
  booktitle = {{{KI}} 2019: {{Advances}} in {{Artificial Intelligence}}},
  author = {Block, Karsten and Trumm, Simon and Sahitaj, Premtim and Ollinger, Stefan and Bergmann, Ralph},
  editor = {Benzm{\"u}ller, Christoph and Stuckenschmidt, Heiner},
  year = {2019},
  volume = {11793},
  pages = {101--114},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-30179-8_8},
  urldate = {2022-01-03},
  abstract = {Research on argumentation in Artificial Intelligence recently investigates new methods that contribute to the vision of developing robust argumentation machines. One line of research explores ways of reasoning with natural language arguments coming from information sources on the web as a foundation for the deliberation and synthesis of arguments in specific domains. This paper builds upon arguments represented as argument graphs in the standardized Argument Interchange Format. While previous work was focused on the development of semantic similarity measures used for the case-based retrieval of argument graphs, this paper addresses the problem of clustering argument graphs to explore structures that facilitate argumentation interpretation. We propose a k-medoid and an agglomerative clustering approach based on semantic similarity measures. We compare the clustering results based on a graph-based semantic measure that takes the structure of the argument into account with a semantic word2vec measure on the pure textual argument representation. Experiments based on the Microtext corpus show that the graph-based similarity is best on internal evaluation measures, while the pure textual measure performs very well for identifying topic-specific clusters.},
  isbn = {978-3-030-30178-1 978-3-030-30179-8},
  langid = {english}
}

@article{Bogner2022TypeNotType,
  title = {To {{Type}} or {{Not}} to {{Type}}? {{A Systematic Comparison}} of the {{Software Quality}} of {{JavaScript}} and {{TypeScript Applications}} on {{GitHub}}},
  shorttitle = {To {{Type}} or {{Not}} to {{Type}}?},
  author = {Bogner, Justus and Merkel, Manuel},
  year = {2022},
  month = mar,
  journal = {arXiv:2203.11115 [cs]},
  eprint = {2203.11115},
  primaryclass = {cs},
  urldate = {2022-05-03},
  abstract = {JavaScript (JS) is one of the most popular programming languages, and widely used for web apps and even backend development. Due to its dynamic nature, however, JS applications often have a reputation for poor software quality. As a type-safe superset of JavaScript, TypeScript (TS) offers features to address this. However, there is currently insufficient empirical evidence to broadly support the claim that TS apps exhibit better software quality than JS apps. We therefore conducted a repository mining study based on 604 GitHub projects (299 for JS, 305 for TS) with over 16M LoC and collected four facets of software quality: a) code quality (\# of code smells per LoC), b) code understandability (cognitive complexity per LoC), c) bug proneness (bug fix commit ratio), and d) bug resolution time (mean time a bug issue is open). For TS, we also collected how frequently the type-safety ignoring `any` type was used. The analysis indicates that TS apps exhibit significantly better code quality and understandability than JS apps. Contrary to expectations, however, bug proneness and bug resolution time of our TS sample were not significantly lower than for JS: mean bug fix commit ratio was more than 60\% larger (0.126 vs. 0.206), and TS projects needed on average more than an additional day to fix bugs (31.86 vs. 33.04 days). Furthermore, reducing the usage of the `any` type in TS apps was significantly correlated with all metrics except bug proneness (Spearman's rho between 0.17 and 0.26). Our results indicate that the perceived positive influence of TypeScript for avoiding bugs in comparison to JavaScript may be more complicated than assumed. While using TS seems to have benefits, it does not automatically lead to less and easier to fix bugs. However, more research is needed in this area, especially concerning the potential influence of project complexity and developer experience.},
  archiveprefix = {arXiv}
}

@article{Bojanowski2016EnrichingWordVectors,
  title = {Enriching {{Word Vectors}} with {{Subword Information}}},
  author = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  year = {2016},
  month = jul,
  journal = {arXiv:1607.04606 [cs]},
  eprint = {1607.04606},
  primaryclass = {cs},
  abstract = {Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character \$n\$-grams. A vector representation is associated to each character \$n\$-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.},
  archiveprefix = {arXiv}
}

@article{Boller1990ConceptualizingArgumentQuality,
  title = {Conceptualizing {{Argument Quality Via Argument Structure}}},
  author = {Boller, Gregory W. and Swasy, John L. and Munch, James M.},
  year = {1990},
  journal = {ACR North American Advances},
  volume = {NA-17},
  urldate = {2019-09-04},
  langid = {english}
}

@inproceedings{Boltuzic2015IdentifyingProminentArguments,
  title = {Identifying {{Prominent Arguments}} in {{Online Debates Using Semantic Textual Similarity}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  author = {Boltu{\v z}i{\'c}, Filip and {\v S}najder, Jan},
  year = {2015},
  month = jun,
  pages = {110--115},
  publisher = {Association for Computational Linguistics},
  address = {Denver, CO},
  doi = {10.3115/v1/W15-0514},
  urldate = {2019-11-18}
}

@book{Bonami2018LexemeDescriptiveTheoretical,
  title = {The Lexeme in Descriptive and Theoretical Morphology},
  author = {Bonami, Olivier},
  year = {2018},
  month = feb,
  series = {Empirically {{Oriented Theoretical Morphology}} and {{Syntax}}},
  publisher = {Language Science Press},
  address = {Berlin},
  langid = {english}
}

@inproceedings{Bond2013LinkingExtendingOpen,
  title = {Linking and {{Extending}} an {{Open Multilingual Wordnet}}},
  booktitle = {Proceedings of the 51st {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Bond, Francis and Foster, Ryan},
  year = {2013},
  month = aug,
  pages = {1352--1362},
  publisher = {Association for Computational Linguistics},
  address = {Sofia, Bulgaria},
  urldate = {2021-02-13}
}

@inproceedings{Bondarenko2020ComparativeWebSearch,
  title = {Comparative {{Web Search Questions}}},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Bondarenko, Alexander and Braslavski, Pavel and V{\"o}lske, Michael and Aly, Rami and Fr{\"o}be, Maik and Panchenko, Alexander and Biemann, Chris and Stein, Benno and Hagen, Matthias},
  year = {2020},
  month = jan,
  series = {{{WSDM}} '20},
  pages = {52--60},
  publisher = {Association for Computing Machinery},
  address = {Houston, TX, USA},
  doi = {10.1145/3336191.3371848},
  urldate = {2020-09-02},
  abstract = {{\textbackslash}beginabstract We analyze comparative questions, i.e., questions asking to compare different items, that were submitted to Yandex in 2012. Responses to such questions might be quite different from the simple "ten blue links'' and could, for example, aggregate pros and cons of the different options as direct answers. However, changing the result presentation is an intricate decision such that the classification of comparative questions forms a highly precision-oriented task. From a year-long Yandex log, we annotate a random sample of 50,000{\textasciitilde}questions; 2.8\%{\textasciitilde}of which are comparative. For these annotated questions, we develop a precision-oriented classifier by combining carefully hand-crafted lexico-syntactic rules with feature-based and neural approaches---achieving a recall of{\textasciitilde}0.6 at a perfect precision of{\textasciitilde}1.0. After running the classifier on the full year log (on average, there is at least one comparative question per second), we analyze 6,250{\textasciitilde}comparative questions using more fine-grained subclasses (e.g., should the answer be a "simple'' fact or rather a more verbose argument) for which individual classifiers are trained. An important insight is that more than 65\%{\textasciitilde}of the comparative questions demand argumentation and opinions, i.e., reliable direct answers to comparative questions require more than the facts from a search engine's knowledge graph. In addition, we present a qualitative analysis of the underlying comparative information needs (separated into 14{\textasciitilde}categories likeconsumer electronics orhealth ), their seasonal dynamics, and possible answers from community question answering platforms. {\textbackslash}endabstract},
  isbn = {978-1-4503-6822-3}
}

@inproceedings{Bondarenko2020ToucheFirstShared,
  title = {Touch{\'e}: {{First Shared Task}} on {{Argument Retrieval}}},
  shorttitle = {Touch{\'e}},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {Bondarenko, Alexander and Hagen, Matthias and Potthast, Martin and Wachsmuth, Henning and Beloucif, Meriem and Biemann, Chris and Panchenko, Alexander and Stein, Benno},
  editor = {Jose, Joemon M. and Yilmaz, Emine and Magalh{\~a}es, Jo{\~a}o and Castells, Pablo and Ferro, Nicola and Silva, M{\'a}rio J. and Martins, Fl{\'a}vio},
  year = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {517--523},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-45442-5_67},
  abstract = {Technologies for argument mining and argumentation processing are maturing continuously, giving rise to the idea of retrieving arguments in search scenarios. We introduce Touch{\'e}, the first lab on Argument Retrieval featuring two subtasks: (1) the retrieval of arguments from a focused debate collection to support argumentative conversations, and (2) the retrieval of arguments from a generic web crawl to answer comparative questions with argumentative results. The goal of this lab is to perform an evaluation of various strategies to retrieve argumentative information from the web content. In this paper, we describe the setting of each subtask: the motivation, the data, and the evaluation methodology.},
  isbn = {978-3-030-45442-5},
  langid = {english}
}

@inproceedings{Bondarenko2023OverviewTouche2023,
  title = {Overview of~{{Touch{\'e}}} 2023: {{Argument}} and~{{Causal Retrieval}}},
  shorttitle = {Overview of~{{Touch{\'e}}} 2023},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {Bondarenko, Alexander and Fr{\"o}be, Maik and Kiesel, Johannes and Schlatt, Ferdinand and Barriere, Valentin and Ravenet, Brian and Hemamou, L{\'e}o and Luck, Simon and Reimer, Jan Heinrich and Stein, Benno and Potthast, Martin and Hagen, Matthias},
  editor = {Kamps, Jaap and Goeuriot, Lorraine and Crestani, Fabio and Maistro, Maria and Joho, Hideo and Davis, Brian and Gurrin, Cathal and Kruschwitz, Udo and Caputo, Annalina},
  year = {2023},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {527--535},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-28241-6_61},
  abstract = {The goal of Touch{\'e} is to foster and support the development of technologies for argument and causal retrieval and analysis. For the fourth time, we organize the Touch{\'e} lab featuring four shared tasks: (a)~argument retrieval for controversial topics, where participants retrieve web documents that contain high-quality argumentation and detect the argument stance, (b)~causal retrieval, where participants retrieve documents that contain causal statements from a generic web crawl and detect the causal stance, (c)~image retrieval for arguments, where participants retrieve images showing support or opposition to some stance from a focused web crawl, and (d)~intra-multilingual multi-target stance classification, where participants detect the stance of comments on proposals from the multilingual participatory democracy platform~CoFE. In this paper, we briefly summarize the results of Touch{\'e}~2022 and describe the planned setup for the fourth lab edition at CLEF~2023.},
  isbn = {978-3-031-28241-6},
  langid = {english}
}

@article{Bonnici2013SubgraphIsomorphismAlgorithm,
  title = {A Subgraph Isomorphism Algorithm and Its Application to Biochemical Data},
  author = {Bonnici, Vincenzo and Giugno, Rosalba and Pulvirenti, Alfredo and Shasha, Dennis and Ferro, Alfredo},
  year = {2013},
  month = apr,
  journal = {BMC Bioinformatics},
  volume = {14},
  number = {7},
  pages = {S13},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-14-S7-S13},
  urldate = {2019-01-07},
  abstract = {Graphs can represent biological networks at the molecular, protein, or species level. An important query is to find all matches of a pattern graph to a target graph. Accomplishing this is inherently difficult (NP-complete) and the efficiency of heuristic algorithms for the problem may depend upon the input graphs. The common aim of existing algorithms is to eliminate unsuccessful mappings as early as and as inexpensively as possible.}
}

@inproceedings{Bosc2016DARTDatasetArguments,
  title = {{{DART}}: A {{Dataset}} of {{Arguments}} and Their {{Relations}} on {{Twitter}}},
  shorttitle = {{{DART}}},
  booktitle = {Proceedings of the {{Tenth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'16)},
  author = {Bosc, Tom and Cabrio, Elena and Villata, Serena},
  year = {2016},
  month = may,
  pages = {1258--1263},
  publisher = {European Language Resources Association (ELRA)},
  address = {Portoro{\v z}, Slovenia},
  urldate = {2022-01-13},
  abstract = {The problem of understanding the stream of messages exchanged on social media such as Facebook and Twitter is becoming a major challenge for automated systems. The tremendous amount of data exchanged on these platforms as well as the specific form of language adopted by social media users constitute a new challenging context for existing argument mining techniques. In this paper, we describe a resource of natural language arguments called DART (Dataset of Arguments and their Relations on Twitter) where the complete argument mining pipeline over Twitter messages is considered: (i) we identify which tweets can be considered as arguments and which cannot, and (ii) we identify what is the relation, i.e., support or attack, linking such tweets to each other.}
}

@inproceedings{Bosc2016TweetiesSquabblingPositive,
  title = {Tweeties {{Squabbling}}: {{Positive}} and {{Negative Results}} in {{Applying Argument Mining}} on {{Social Media}}},
  shorttitle = {Tweeties {{Squabbling}}},
  booktitle = {Computational {{Models}} of {{Argument}}},
  author = {Bosc, Tom and Cabrio, Elena and Villata, Serena},
  year = {2016},
  pages = {21--32},
  publisher = {IOS Press},
  doi = {10.3233/978-1-61499-686-6-21},
  urldate = {2023-10-20}
}

@inproceedings{Bosselut2019COMETCommonsenseTransformers,
  title = {{{COMET}}: {{Commonsense Transformers}} for {{Automatic Knowledge Graph Construction}}},
  shorttitle = {{{COMET}}},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Bosselut, Antoine and Rashkin, Hannah and Sap, Maarten and Malaviya, Chaitanya and Celikyilmaz, Asli and Choi, Yejin},
  year = {2019},
  month = jul,
  pages = {4762--4779},
  publisher = {Association for Computational Linguistics},
  address = {Florence, Italy},
  doi = {10.18653/v1/P19-1470},
  urldate = {2020-05-02},
  abstract = {We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5\% (ATOMIC) and 91.7\% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.}
}

@inproceedings{Boteanu2015SolvingExplainingAnalogy,
  title = {Solving and {{Explaining Analogy Questions Using Semantic Networks}}},
  booktitle = {Twenty-{{Ninth AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Boteanu, Adrian and Chernova, Sonia},
  year = {2015},
  month = feb,
  urldate = {2020-05-30},
  abstract = {Analogies are a fundamental human reasoning pattern that relies on relational similarity. Understanding how analogies are formed facilitates the transfer of knowledge between contexts. The approach presented in this work focuses on obtaining precise interpretations of analogies. We leverage noisy semantic networks to answer and explain a wide spectrum of analogy questions. The core of our contribution, the Semantic Similarity Engine, consists of methods for extracting and comparing graph-contexts that reveal the relational parallelism that analogies are based on, while mitigating uncertainty in the semantic network.We demonstrate these methods in two tasks: answering multiple choice analogy questions and generating human readable analogy explanations. We evaluate our approach on two datasets totaling 600 analogy questions. Our results show reliable performance and low false-positive rate in question answering; human evaluators agreed with 96\% of our analogy explanations.},
  copyright = {Authors who publish a paper in this conference agree to the following terms:   Author(s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.  The author(s) warrants that they are the sole author and owner of the copyright in the above article/paper, except for those portions shown to be in quotations; that the article/paper is original throughout; and that the undersigned right to make the grants set forth above is complete and unencumbered.  The author(s) agree that if anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, the author(s) will hold harmless and indemnify AAAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense AAAI may make to such claim or action. Moreover, the undersigned agrees to cooperate in any claim or other action seeking to protect or enforce any right the undersigned has granted to AAAI in the article/paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, the undersigned agrees to reimburse whomever brings such claim or action for expenses and attorneys' fees incurred therein.  Author(s) retain all proprietary rights other than copyright (such as patent rights).  Author(s) may make personal reuse of all or portions of the above article/paper in other works of their own authorship.  Author(s) may reproduce, or have reproduced, their article/paper for the author's personal use, or for company use provided that AAAI copyright and the source are indicated, and that the copies are not used in a way that implies AAAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the article/paper in electronic or digital form on any computer network, except by the author or the author's employer, and then only on the author's or the employer's own web page or ftp site. Such web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the AAAI electronic server, and shall not post other AAAI copyrighted materials not of the author's or the employer's creation (including tables of contents with links to other papers) without AAAI's written permission.  Author(s) may make limited distribution of all or portions of their article/paper prior to publication.  In the case of work performed under U.S. Government contract, AAAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above article/paper, and to authorize others to do so, for U.S. Government purposes.  In the event the above article/paper is not accepted and published by AAAI, or is withdrawn by the author(s) before acceptance by AAAI, this agreement becomes null and void.},
  langid = {english}
}

@inproceedings{Bowman2015LargeAnnotatedCorpus,
  title = {A Large Annotated Corpus for Learning Natural Language Inference},
  booktitle = {Proceedings of the 2015 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher and Manning, Christopher D.},
  year = {2015},
  month = sep,
  pages = {632--642},
  publisher = {Association for Computational Linguistics},
  address = {Lisbon, Portugal},
  doi = {10.18653/v1/D15-1075},
  urldate = {2021-02-07}
}

@inproceedings{Boylan2024KGValidatorFrameworkAutomatic,
  title = {{{KGValidator}}: {{A Framework}} for {{Automatic Validation}} of {{Knowledge Graph Construction}}},
  shorttitle = {{{KGValidator}}},
  booktitle = {Joint Proceedings of the 3rd {{International}} Workshop One Knowledge Graph Generation from Text ({{TEXT2KG}}) and {{Data Quality}} Meets {{Machine Learning}} and {{Knowledge Graphs}} ({{DQMLKG}})},
  author = {Boylan, Jack and {Gholipour-Ghalandari}, Demian and Hokamp, Chris and Thorn, Dominic and Ghaffari, Parsa and Mangla, Shashank},
  editor = {Tiwari, Sanju and Mihindukulasooriya, Nandana and Osborne, Francesco and Kontokostas, Dimitris and D'Souza, Jennifer and Kejriwal, Mayank and Pellegrino, Maria Angela and Rula, Anisa and Gayo, Jose Emilio Labra and Cochez, Michael and Alam, Mehwish},
  year = {2024},
  month = may,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3747},
  pages = {23},
  publisher = {CEUR},
  address = {Hersonissos, Greece},
  issn = {1613-0073},
  urldate = {2024-10-31},
  langid = {english}
}

@book{Bramer2025ArtificialIntelligenceXLI,
  title = {Artificial {{Intelligence XLI}}: 44th {{SGAI International Conference}} on {{Artificial Intelligence}}, {{AI}} 2024, {{Cambridge}}, {{UK}}, {{December}} 17--19, 2024, {{Proceedings}}, {{Part I}}},
  shorttitle = {Artificial {{Intelligence XLI}}},
  editor = {Bramer, Max and Stahl, Frederic},
  year = {2025},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {15446},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-77915-2},
  urldate = {2024-12-03},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-031-77914-5 978-3-031-77915-2},
  langid = {english}
}

@book{Bramer2025ArtificialIntelligenceXLIa,
  title = {Artificial {{Intelligence XLI}}: 44th {{SGAI International Conference}} on {{Artificial Intelligence}}, {{AI}} 2024, {{Cambridge}}, {{UK}}, {{December}} 17--19, 2024, {{Proceedings}}, {{Part II}}},
  shorttitle = {Artificial {{Intelligence XLI}}},
  editor = {Bramer, Max and Stahl, Frederic},
  year = {2025},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {15447},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-77918-3},
  urldate = {2024-12-18},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-031-77917-6 978-3-031-77918-3},
  langid = {english}
}

@mastersthesis{Brand2024ModelingAcquiringKnowledge,
  title = {Modeling and {{Acquiring Knowledge}} with {{Large Language Models}}: {{A Study}} in the {{Cyber-Physical Domain}}},
  shorttitle = {Modeling and {{Acquiring Knowledge}} with {{Large Language Models}}},
  author = {Brand, Florian},
  year = {2024},
  month = feb,
  address = {Trier},
  abstract = {Many Artificial Intelligence (AI) systems rely on human-engineered knowledge to solve new problems with the provided knowledge. These systems are deployed in a range of domains, from medicine over finance to the cyber-physical domain. However, the engineering and acquisition of knowledge for these systems is a cumbersome task, even for domain experts. There are various tools and methods proposed to lessen the burden on those experts. The recent advancements in Large Language Models (LLMs) show a promising way to utilize them in the knowledge creation process. This thesis applies LLMs as a tool for the engineering and acquisition of formal knowledge in the cyber-physical domain. It analyzes the characteristics and differences of LLMs and determines their suitability for this task. Additionally, the knowledge representations of the systems in the cyber-physical domain are researched and compared. Furthermore, a method is developed to use LLMs for the generation of formal knowledge in the cyber-physical domain. This method is implemented and evaluated, showing promising results across different setups. However, a domain expert is still needed in the process to guide the LLM and provide useful inputs.},
  langid = {english},
  school = {Trier University}
}

@article{Branting2003ReductiongraphModelPrecedent,
  title = {A Reduction-Graph Model of Precedent in Legal Analysis},
  author = {Branting, L. Karl},
  year = {2003},
  month = nov,
  journal = {Artificial Intelligence},
  volume = {150},
  number = {1-2},
  pages = {59--95},
  issn = {00043702},
  doi = {10.1016/S0004-3702(03)00102-4},
  urldate = {2019-08-20},
  abstract = {Legal analysis is a task underlying many forms of legal problem solving. In the Anglo-American legal system, legal analysis is based in part on legal precedents, previously decided cases. This paper describes a reduction-graph model of legal precedents that accounts for a key characteristic of legal precedents: a precedent's relevance to subsequent cases is determined by the theory under which the precedent is decided. This paper identifies the implementation requirements for legal analysis using the reduction-graph model of legal precedents and describes GREBE, a program that satisfies these requirements.},
  langid = {english}
}

@inproceedings{Breen2004JMdictJapaneseMultilingualDictionary,
  title = {{{JMdict}}: A {{Japanese-Multilingual Dictionary}}},
  shorttitle = {{{JMdict}}},
  booktitle = {Proceedings of the {{Workshop}} on {{Multilingual Linguistic Resources}}},
  author = {Breen, Jim},
  year = {2004},
  month = aug,
  pages = {65--72},
  publisher = {COLING},
  address = {Geneva, Switzerland},
  urldate = {2021-02-13}
}

@inproceedings{Brinner2024WeaklySupervisedClaim,
  title = {Weakly {{Supervised Claim Localization}} in~{{Scientific Abstracts}}},
  booktitle = {Robust {{Argumentation Machines}}},
  author = {Brinner, Marc and Zarrie{\ss}, Sina and Heger, Tina},
  editor = {Cimiano, Philipp and Frank, Anette and Kohlhase, Michael and Stein, Benno},
  year = {2024},
  pages = {20--38},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63536-6_2},
  abstract = {We explore the possibility of leveraging model explainability methods for weakly supervised claim localization in scientific abstracts. The resulting approaches require only abstract-level supervision, i.e., information about the general presence of a claim in a given abstract, to extract spans of text that indicate this specific claim. We evaluate our methods on the SciFact claim verification dataset, as well as on a newly created dataset that contains expert-annotated evidence for scientific hypotheses in paper abstracts from the field of invasion biology. Our results suggest that significant performance in the claim localization task can be achieved without any explicit supervision, which increases the transferability to new domains with limited data availability. In the course of our experiments, we additionally find that injecting information from human evidence annotations into the training of a neural network classifier can lead to a significant increase in classification performance.},
  isbn = {978-3-031-63536-6},
  langid = {english}
}

@inproceedings{Britner2023AQUAPLANEArgumentQuality,
  title = {{{AQUAPLANE}}: {{The Argument Quality Explainer App}}},
  shorttitle = {{{AQUAPLANE}}},
  booktitle = {Proceedings of the 32nd {{ACM International Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Britner, Sebastian and Dumani, Lorik and Schenkel, Ralf},
  year = {2023},
  month = oct,
  series = {{{CIKM}} '23},
  pages = {5015--5020},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3583780.3614733},
  urldate = {2023-11-24},
  abstract = {In computational argumentation, so-called quality dimensions such as coherence or rhetoric are often used for ranking arguments. However, the literature often only predicts which argument is more persuasive, but not why this is the case. In this paper, we introduce AQUAPLANE, a transparent and easy-to-extend application that not only decides for a pair of arguments which one is more convincing with respect to a statement, but also provides an explanation.},
  isbn = {979-8-4007-0124-5}
}

@inproceedings{Brown2020LanguageModelsAre,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  year = {2020},
  volume = {33},
  pages = {1877--1901},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-06-21},
  abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.  For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model.  GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.}
}

@inproceedings{Bryant2018LanguageModelBased,
  title = {Language {{Model Based Grammatical Error Correction}} without {{Annotated Training Data}}},
  booktitle = {Proceedings of the {{Thirteenth Workshop}} on {{Innovative Use}} of {{NLP}} for {{Building Educational Applications}}},
  author = {Bryant, Christopher and Briscoe, Ted},
  year = {2018},
  month = jun,
  pages = {247--253},
  publisher = {Association for Computational Linguistics},
  address = {New Orleans, Louisiana},
  doi = {10.18653/v1/W18-0529},
  urldate = {2020-05-20},
  abstract = {Since the end of the CoNLL-2014 shared task on grammatical error correction (GEC), research into language model (LM) based approaches to GEC has largely stagnated. In this paper, we re-examine LMs in GEC and show that it is entirely possible to build a simple system that not only requires minimal annotated data ({$\sim$}1000 sentences), but is also fairly competitive with several state-of-the-art systems. This approach should be of particular interest for languages where very little annotated training data exists, although we also hope to use it as a baseline to motivate future research.}
}

@article{Budan2017ApproachCharacterizeGraded,
  title = {An Approach to Characterize Graded Entailment of Arguments through a Label-Based Framework},
  author = {Bud{\'a}n, Maximiliano C. D. and Simari, Gerardo I. and Viglizzo, Ignacio and Simari, Guillermo R.},
  year = {2017},
  month = mar,
  journal = {International Journal of Approximate Reasoning},
  volume = {82},
  pages = {242--269},
  issn = {0888-613X},
  doi = {10.1016/j.ijar.2016.12.016},
  urldate = {2023-10-20},
  abstract = {Argumentation theory is a powerful paradigm that formalizes a type of commonsense reasoning that aims to simulate the human ability to resolve a specific problem in an intelligent manner. A classical argumentation process takes into account only the properties related to the intrinsic logical soundness of an argument in order to determine its acceptability status. However, these properties are not always the only ones that matter to establish the argument's acceptability---there exist other qualities, such as strength, weight, social votes, trust degree, relevance level, and certainty degree, among others. In this work, we redefine the argumentative process to improve the analysis of arguments by considering their special features in order to obtain more refined results. Towards this end, we propose adding meta-level information to the arguments in the form of labels representing quantifiable data ranking over a range of fuzzy valuations. These labels are propagated through an argumentative graph according to the relations of support, conflict, and aggregation between arguments. Through this process we obtain final labels that are useful in determining argument acceptability.}
}

@inproceedings{Budzynska2019AdvancesArgumentMining,
  title = {Advances in {{Argument Mining}}},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}: {{Tutorial Abstracts}}},
  author = {Budzynska, Katarzyna and Reed, Chris},
  year = {2019},
  month = jul,
  pages = {39--42},
  urldate = {2019-08-25},
  langid = {american}
}

@phdthesis{Burkert2023MultitaskTransformerModel,
  title = {A Multi-Task Transformer Model for Argument Graph Construction},
  author = {Burkert, Nico},
  year = {2023},
  month = mar,
  address = {Wiesbaden, Germany},
  school = {Hochschule RheinMain}
}

@incollection{Burkhard2001NotionSimilarityCase,
  title = {On the {{Notion}} of {{Similarity}} in {{Case Based Reasoning}} and {{Fuzzy Theory}}},
  booktitle = {Soft {{Computing}} in {{Case Based Reasoning}}},
  author = {Burkhard, Hans-Dieter and Richter, Michael M.},
  editor = {Pal, Sankar K. and Dillon, Tharam S. and Yeung, Daniel S.},
  year = {2001},
  pages = {29--45},
  publisher = {Springer London},
  address = {London},
  doi = {10.1007/978-1-4471-0687-6_2},
  abstract = {Notions of similarity and neighborhood play an important role in informatics. Different disciplines have developed their own treatment of related measures. We consider this problem under the viewpoint of case based reasoning and fuzzy theory. While distance and similarity can be considered to be formally equivalent, there exist some differences concerning their intuitive use which have impact on the composition of global measures from local ones.},
  isbn = {978-1-4471-0687-6},
  langid = {english}
}

@article{Busse2015ActuallyWhatDoes,
  title = {Actually, {{What Does}} "{{Ontology}}" {{Mean}}? {{A Term Coined}} by {{Philosophy}} in the {{Light}} of {{Different Scientific Disciplines}}},
  author = {Busse, Johannes and Humm, Bernhard and L{\"u}bbert, Christoph and Moelter, Frank and Reibold, Anatol and Rewald, Matthias and Schl{\"u}ter, Veronika and Seiler, Bernhard and Tegtmeier, Erwin and Zeh, Thomas},
  year = {2015},
  month = mar,
  journal = {Journal of Computing and Information Technology},
  volume = {23},
  number = {1},
  pages = {29--41},
  doi = {10.2498/cit.1002508},
  urldate = {2018-09-01},
  abstract = {This article is a fictitious, moderated dialogue between an information scientist, a philosopher, and a psychologist. They explore the term ``ontology'' from the point of view of their own discipline, with the object of learning from each other. The target audience of this article are laypersons with respect to the specific disciplines -- but who have a scientific background. The authors work in the fields of computer science, knowledge engineering, electrical engineering, mathematics, neurobiology, philosophy, and psychology.}
}

@inproceedings{Cabrio2012CombiningTextualEntailment,
  title = {Combining {{Textual Entailment}} and {{Argumentation Theory}} for {{Supporting Online Debates Interactions}}},
  booktitle = {Proceedings of the 50th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 2: {{Short Papers}})},
  author = {Cabrio, Elena and Villata, Serena},
  year = {2012},
  month = jul,
  pages = {208--212},
  publisher = {Association for Computational Linguistics},
  address = {Jeju Island, Korea},
  urldate = {2019-11-18}
}

@inproceedings{Cabrio2013DetectingBipolarSemantic,
  title = {Detecting {{Bipolar Semantic Relations}} among {{Natural Language Arguments}} with {{Textual Entailment}}: A {{Study}}.},
  shorttitle = {Detecting {{Bipolar Semantic Relations}} among {{Natural Language Arguments}} with {{Textual Entailment}}},
  booktitle = {Proceedings of the {{Joint Symposium}} on {{Semantic Processing}}. {{Textual Inference}} and {{Structures}} in {{Corpora}}},
  author = {Cabrio, Elena and Villata, Serena},
  year = {2013},
  month = nov,
  pages = {24--32},
  address = {Trento, Italy},
  urldate = {2023-10-20}
}

@article{Cabrio2013NaturalLanguageBipolar,
  title = {A Natural Language Bipolar Argumentation Approach to Support Users in Online Debate Interactions{\dag}},
  author = {Cabrio, Elena and Villata, Serena},
  year = {2013},
  month = sep,
  journal = {Argument \& Computation},
  volume = {4},
  number = {3},
  pages = {209--230},
  issn = {1946-2166, 1946-2174},
  doi = {10.1080/19462166.2013.862303},
  urldate = {2023-10-20},
  langid = {english}
}

@inproceedings{Cabrio2018FiveYearsArgument,
  title = {Five Years of Argument Mining: A Data-Driven Analysis},
  shorttitle = {Five Years of Argument Mining},
  booktitle = {Proceedings of the 27th {{International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Cabrio, Elena and Villata, Serena},
  year = {2018},
  month = jul,
  series = {{{IJCAI}}'18},
  pages = {5427--5433},
  publisher = {AAAI Press},
  address = {Stockholm, Sweden},
  doi = {10.24963/ijcai.2018/766},
  urldate = {2020-09-02},
  abstract = {Argument mining is the research area aiming at extracting natural language arguments and their relations from text, with the final goal of providing machine-processable structured data for computational models of argument. This research topic has started to attract the attention of a small community of researchers around 2014, and it is nowadays counted as one of the most promising research areas in Artificial Intelligence in terms of growing of the community, funded projects, and involvement of companies. In this paper, we present the argument mining tasks, and we discuss the obtained results in the area from a data-driven perspective. An open discussion highlights the main weaknesses suffered by the existing work in the literature, and proposes open challenges to be faced in the future.},
  isbn = {978-0-9992411-2-7}
}

@inproceedings{Campello2013DensityBasedClusteringBased,
  title = {Density-{{Based Clustering Based}} on {{Hierarchical Density Estimates}}},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Campello, Ricardo J. G. B. and Moulavi, Davoud and Sander, Joerg},
  editor = {Pei, Jian and Tseng, Vincent S. and Cao, Longbing and Motoda, Hiroshi and Xu, Guandong},
  year = {2013},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {160--172},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-37456-2_14},
  abstract = {We propose a theoretically and practically improved density-based, hierarchical clustering method, providing a clustering hierarchy from which a simplified tree of significant clusters can be constructed. For obtaining a ``flat'' partition consisting of only the most significant clusters (possibly corresponding to different density thresholds), we propose a novel cluster stability measure, formalize the problem of maximizing the overall stability of selected clusters, and formulate an algorithm that computes an optimal solution to this problem. We demonstrate that our approach outperforms the current, state-of-the-art, density-based clustering methods on a wide variety of real world data.},
  isbn = {978-3-642-37456-2},
  langid = {english}
}

@inproceedings{Campos2018TextFeatureBased,
  title = {A {{Text Feature Based Automatic Keyword Extraction Method}} for {{Single Documents}}},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {Campos, Ricardo and Mangaravite, V{\'i}tor and Pasquali, Arian and Jorge, Al{\'i}pio M{\'a}rio and Nunes, C{\'e}lia and Jatowt, Adam},
  editor = {Pasi, Gabriella and Piwowarski, Benjamin and Azzopardi, Leif and Hanbury, Allan},
  year = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {684--691},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-76941-7_63},
  abstract = {In this work, we propose a lightweight approach for keyword extraction and ranking based on an unsupervised methodology to select the most important keywords of a single document. To understand the merits of our proposal, we compare it against RAKE, TextRank and SingleRank methods (three well-known unsupervised approaches) and the baseline TF.IDF, over four different collections to illustrate the generality of our approach. The experimental results suggest that extracting keywords from documents using our method results in a superior effectiveness when compared to similar approaches.},
  isbn = {978-3-319-76941-7},
  langid = {english}
}

@inproceedings{Campos2018YAKECollectionIndependentAutomatic,
  title = {{{YAKE}}! {{Collection-Independent Automatic Keyword Extractor}}},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {Campos, Ricardo and Mangaravite, V{\'i}tor and Pasquali, Arian and Jorge, Al{\'i}pio M{\'a}rio and Nunes, C{\'e}lia and Jatowt, Adam},
  editor = {Pasi, Gabriella and Piwowarski, Benjamin and Azzopardi, Leif and Hanbury, Allan},
  year = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {806--810},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-76941-7_80},
  abstract = {In this paper, we present YAKE!, a novel feature-based system for multi-lingual keyword extraction from single documents, which supports texts of different sizes, domains or languages. Unlike most systems, YAKE! does not rely on dictionaries or thesauri, neither it is trained against any corpora. Instead, we follow an unsupervised approach which builds upon features extracted from the text, making it thus applicable to documents written in many different languages without the need for external knowledge. This can be beneficial for a large number of tasks and a plethora of situations where the access to training corpora is either limited or restricted. In this demo, we offer an easy to use, interactive session, where users from both academia and industry can try our system, either by using a sample document or by introducing their own text. As an add-on, we compare our extracted keywords against the output produced by the IBM Natural Language Understanding (IBM NLU) and Rake system. YAKE! demo is available at http://bit.ly/YakeDemoECIR2018. A python implementation of YAKE! is also available at PyPi repository (https://pypi.python.org/pypi/yake/).},
  isbn = {978-3-319-76941-7},
  langid = {english}
}

@article{Campos2020YAKEKeywordExtraction,
  title = {{{YAKE}}! {{Keyword}} Extraction from Single Documents Using Multiple Local Features},
  author = {Campos, Ricardo and Mangaravite, V{\'i}tor and Pasquali, Arian and Jorge, Al{\'i}pio and Nunes, C{\'e}lia and Jatowt, Adam},
  year = {2020},
  month = jan,
  journal = {Information Sciences},
  volume = {509},
  pages = {257--289},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2019.09.013},
  urldate = {2020-04-27},
  abstract = {As the amount of generated information grows, reading and summarizing texts of large collections turns into a challenging task. Many documents do not come with descriptive terms, thus requiring humans to generate keywords on-the-fly. The need to automate this kind of task demands the development of keyword extraction systems with the ability to automatically identify keywords within the text. One approach is to resort to machine-learning algorithms. These, however, depend on large annotated text corpora, which are not always available. An alternative solution is to consider an unsupervised approach. In this article, we describe YAKE!, a light-weight unsupervised automatic keyword extraction method which rests on statistical text features extracted from single documents to select the most relevant keywords of a text. Our system does not need to be trained on a particular set of documents, nor does it depend on dictionaries, external corpora, text size, language, or domain. To demonstrate the merits and significance of YAKE!, we compare it against ten state-of-the-art unsupervised approaches and one supervised method. Experimental results carried out on top of twenty datasets show that YAKE! significantly outperforms other unsupervised methods on texts of different sizes, languages, and domains.},
  langid = {english}
}

@misc{CanonicalDebateLab2020ArgumentTechnologies,
  title = {Argument {{Technologies}}},
  author = {{Canonical Debate Lab}},
  year = {2020},
  urldate = {2023-10-18}
}

@inproceedings{Cao2023AutoAMEndToEndNeural,
  title = {{{AutoAM}}: {{An End-To-End Neural Model}} for~{{Automatic}} and~{{Universal Argument Mining}}},
  shorttitle = {{{AutoAM}}},
  booktitle = {Advanced {{Data Mining}} and {{Applications}}},
  author = {Cao, Lang},
  editor = {Yang, Xiaochun and Suhartanto, Heru and Wang, Guoren and Wang, Bin and Jiang, Jing and Li, Bing and Zhu, Huaijie and Cui, Ningning},
  year = {2023},
  pages = {517--531},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-46674-8_36},
  abstract = {Argument mining is to analyze argument structure and extract important argument information from unstructured text. An argument mining system can help people automatically gain causal and logical information behind the text. As argumentative corpus gradually increases, like more people begin to argue and debate on social media, argument mining from them is becoming increasingly critical. However, argument mining is still a big challenge in natural language tasks due to its difficulty, and relative techniques are not mature. For example, research on non-tree argument mining needs to be done more. Most works just focus on extracting tree structure argument information. Moreover, current methods cannot accurately describe and capture argument relations and do not predict their types. In this paper, we propose a novel neural model called AutoAM to solve these problems. We first introduce the argument component attention mechanism in our model. It can capture the relevant information between argument components, so our model can better perform argument mining. Our model is a universal end-to-end framework, which can analyze argument structure without constraints like tree structure and complete three subtasks of argument mining in one model. The experiment results show that our model outperforms the existing works on several metrics in two public datasets.},
  isbn = {978-3-031-46674-8},
  langid = {english}
}

@inproceedings{Carbonell1983DerivationalAnalogyIts,
  title = {Derivational Analogy and Its Role in Problem Solving},
  booktitle = {Proceedings of the {{Third AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Carbonell, Jaime G.},
  year = {1983},
  month = aug,
  series = {{{AAAI}}'83},
  pages = {64--69},
  publisher = {AAAI Press},
  address = {Washington, D.C.},
  urldate = {2020-05-26},
  abstract = {Derivational analogy, a method of solving problems based upon the transfer of past experience to new problem situations, is discussed in the context of other general approaches to problem solving. The experience transfer process consists of recreating lines of reasoning, including decision sequences and accompanying justifications, that proved effective in solving particular problems requiring similar initial analysis. The derivational analogy approach is advocated as a means of implementing reasoning from individual cases in expert systems.}
}

@incollection{Carbonell1983LearningAnalogyFormulating,
  title = {Learning by {{Analogy}}: {{Formulating}} and {{Generalizing Plans}} from {{Past Experience}}},
  shorttitle = {Learning by {{Analogy}}},
  booktitle = {Machine {{Learning}}: {{An Artificial Intelligence Approach}}},
  author = {Carbonell, Jaime G.},
  editor = {Michalski, Ryszard S. and Carbonell, Jaime G. and Mitchell, Tom M.},
  year = {1983},
  series = {Symbolic {{Computation}}},
  volume = {1},
  pages = {137--161},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-12405-5_5},
  urldate = {2020-05-26},
  abstract = {Analogical reasoning is a powerful mechanism for exploiting past experience in planning and problem solving. This chapter outlines a theory of analogical problem solving based on an extension to means-ends analysis. An analogical transformation process is developed to extract knowledge from past successful problem-solving situations that bear a strong similarity to the current problem. Then, the investigation focuses on exploiting and extending the analogical reasoning model to generate useful exemplary solutions to related problems from which more general plans can be induced and refined. Starting with a general analogical inference engine, problem-solving experience is, in essence, compiled incrementally into effective procedures that solve various classes of problems in an increasingly reliable and direct manner.},
  isbn = {978-3-662-12405-5},
  langid = {english}
}

@incollection{Carbonell1986DerivationalAnalogyTheory,
  title = {Derivational {{Analogy}}: {{A}} Theory of Reconstructive Problem Solving and Expertise Acquisition},
  shorttitle = {Derivational {{Analogy}}},
  booktitle = {Machine {{Learning}}: {{An Artificial Intelligence Approach}}},
  author = {Carbonell, Jaime G.},
  editor = {Michalski, Ryszard S. and Carbonell, Jaime G. and Mitchell, Tom M.},
  year = {1986},
  series = {Symbolic {{Computation}}},
  volume = {2},
  pages = {26},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  abstract = {Derivational analogy, a method of solving problems based on the transfer of past experience to new probiem situations, is discussed in the context of other general approaches to problem solving. The experience transfer process consists of recreating lines of reasoning, including decision sequences and accompanying justifications, that proved effective in solving particular problems requiring similar initial analysis. The role of derivational analogy in case-based reasoning and in automated expertise acquisition is discussed.},
  langid = {english}
}

@inproceedings{Caro-Martinez2024UseCaseSpecificReuse,
  title = {Use {{Case-Specific Reuse}} of~{{XAI Strategies}}: {{Design}} and~{{Analysis Through}} an~{{Evaluation Metrics Library}}},
  shorttitle = {Use {{Case-Specific Reuse}} of~{{XAI Strategies}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {{Caro-Mart{\'i}nez}, Marta and Darias, Jes{\'u}s M. and {D{\'i}az-Agudo}, Bel{\'e}n and {Recio-Garc{\'i}a}, Juan A.},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {81--95},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_6},
  abstract = {Nowadays, we have access to a good number of eXplainable Artificial Intelligence libraries and techniques aimed at providing explanations for users to comprehend black-box intelligent systems. However, this presents a double-edged sword: while we can access a wide catalogue of explanation possibilities, determining the most suitable explanation method for a specific situation remains a challenging decision-making task. The iSee project was conceived with the primary goal of constructing a platform where users can share their own experiences with explanations and their successful explanation strategies. Through this CBR platform, other users can leverage these solutions for their own explanation needs, obtaining the most suitable explanation solutions regarding their requirements. In this paper, our focus lies on the reuse step of the CBR cycle. We have developed and implemented constructive reuse approaches, consisting of various methods to assist design users in adapting their solutions to specific use cases and end users. We have validated the applicability of the resulting solutions and introduced an evaluation metrics library designed to assess explanation strategies. Using this library, we have evaluated system solutions based on various key features including computational complexity, popularity, uniformity, diversity, serendipity, and granularity.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@inproceedings{Carvallo2019UseNontechnicalRequirements,
  title = {On the {{Use}} of {{Non-technical Requirements}} for the {{Evaluation}} of {{FOSS Software Components}}},
  booktitle = {Quality of {{Information}} and {{Communications Technology}}},
  author = {Carvallo, Juan Pablo and Carvajal, Fabi{\'a}n and Crespo, Esteban and Mendez, Lucia and Torres, Mar{\'i}a Jos{\'e} and Vintimilla, Rosalva},
  editor = {Piattini, Mario and {Rupino da Cunha}, Paulo and {Garc{\'i}a Rodr{\'i}guez de Guzm{\'a}n}, Ignacio and {P{\'e}rez-Castillo}, Ricardo},
  year = {2019},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {64--78},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-29238-6_5},
  abstract = {Modern enterprises rely on Information Systems specifically designed to manage the increasing complexity of their operation. In the usual case, they are built as hybrid systems which integrate several software components of different nature and origins e.g.; legacy systems, web services, commercial components (typically referred as COTS) and, Free and/or Open Source Software (FOSS). The evaluation of individual software components is highly relevant in this kind of system and is usually conducted with the support of software Quality Models. However, these artifacts usually consider only the evaluation of technical quality requirements, in detriment of non-technical ones (e.g. costs, legal and quality of suppliers) which can be just as critical, particularly in the selection of COTS and FOSS. In this paper, we propose an extension to preexisting software Quality Models, intended to deal with technical and non-technical quality requirements in a homogeneous and holistic way. The relevance of the approach is illustrated in relation to four industrial FOSS adoption processes.},
  isbn = {978-3-030-29238-6},
  langid = {english}
}

@article{Castrillo2018DynamicStructuralSimilarity,
  title = {Dynamic {{Structural Similarity}} on {{Graphs}}},
  author = {Castrillo, Eduar and Le{\'o}n, Elizabeth and G{\'o}mez, Jonatan},
  year = {2018},
  month = may,
  journal = {arXiv:1805.01419 [cs]},
  eprint = {1805.01419},
  primaryclass = {cs},
  abstract = {One way of characterizing the topological and structural properties of vertices and edges in a graph is by using structural similarity measures. Measures like Cosine, Jaccard and Dice compute the similarities restricted to the immediate neighborhood of the vertices, bypassing important structural properties beyond the locality. Others measures, such as the generalized edge clustering coefficient, go beyond the locality but with high computational complexity, making them impractical in large-scale scenarios. In this paper we propose a novel similarity measure that determines the structural similarity by dynamically diffusing and capturing information beyond the locality. This new similarity is modeled as an iterated function that can be solved by fixed point iteration in super-linear time and memory complexity, so it is able to analyze large-scale graphs. In order to show the advantages of the proposed similarity in the community detection task, we replace the local structural similarity used in the SCAN algorithm with the proposed similarity measure, improving the quality of the detected community structure and also reducing the sensitivity to the parameter \${\textbackslash}epsilon\$ of the SCAN algorithm.},
  archiveprefix = {arXiv}
}

@book{Caumanns1999FastSimpleStemming,
  title = {A {{Fast}} and {{Simple Stemming Algorithm}} for {{German Words}}},
  author = {Caumanns, J{\"o}rg},
  year = {1999},
  publisher = {Freie Univ., Fachbereich Mathematik und Informatik},
  address = {Berlin},
  abstract = {In this paper I present a stemming algorithm for morphological complex languages like German or Dutch. The main idea is not to use stems as common forms in order to make the algorithm simple and fast. The algorithm consists of two steps: First certain characters and/or character sequences are substituted. This step takes linguistic rules and statistical heuristics into account. In a second step a very simple, context free suffix-stripping algorithm is applied. Three variations of the algorithm are described in this paper. The simplest one can easily be implemented with 50 lines of C++ code while the most complex one requires about 100 lines of code and a small wordlist. The algorithm is scalable in a way that linguistic rules and statistical heuristics can be added.},
  googlebooks = {iF3cGwAACAAJ},
  langid = {english}
}

@inproceedings{Cavnar1994NGramBasedTextCategorization,
  title = {N-{{Gram-Based Text Categorization}}},
  booktitle = {In {{Proceedings}} of {{SDAIR-94}}, 3rd {{Annual Symposium}} on {{Document Analysis}} and {{Information Retrieval}}},
  author = {Cavnar, William and Trenkle, John M.},
  year = {1994},
  pages = {161--175},
  abstract = {Text categorization is a fundamental task in document processing, allowing the automated handling of enormous streams of documents in electronic form. One difficulty in handling some classes of documents is the presence of different kinds of textual errors, such as spelling and grammatical errors in email, and character recognition errors in documents that come through OCR. Text categorization must work reliably on all input, and thus must tolerate some level of these kinds of problems. We describe here an N-gram-based approach to text categorization that is tolerant of textual errors. The system is small, fast and robust. This system worked very well for language classification, achieving in one test a 99.8\% correct classification rate on Usenet newsgroup articles written in different languages. The system also worked reasonably well for classifying articles from a number of different computer-oriented newsgroups according to subject, achieving as high as an 80\% correct classification...}
}

@inproceedings{Cayrol2005AcceptabilityArgumentsBipolar,
  title = {On the {{Acceptability}} of {{Arguments}} in {{Bipolar Argumentation Frameworks}}},
  booktitle = {Symbolic and {{Quantitative Approaches}} to {{Reasoning}} with {{Uncertainty}}},
  author = {Cayrol, C. and {Lagasquie-Schiex}, M. C.},
  editor = {Godo, Llu{\'i}s},
  year = {2005},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {378--389},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11518655_33},
  abstract = {In this paper, we extend the basic abstract argumentation framework proposed by Dung, by taking into account two independent kinds of interaction between arguments: a defeat relation and a support relation. In that new framework, called a bipolar argumentation framework, we focus on the concept of acceptability and propose new semantics defined from characteristic properties that a set of arguments must satisfy in order to be an output of the argumentation process. We generalize the well-known stable and preferred semantics by enforcing the coherence requirement for an acceptable set of arguments.},
  isbn = {978-3-540-31888-0},
  langid = {english}
}

@article{Cayrol2013BipolarityArgumentationGraphs,
  title = {Bipolarity in Argumentation Graphs: {{Towards}} a Better Understanding},
  shorttitle = {Bipolarity in Argumentation Graphs},
  author = {Cayrol, Claudette and {Lagasquie-Schiex}, Marie-Christine},
  year = {2013},
  month = sep,
  journal = {International Journal of Approximate Reasoning},
  series = {Special Issue: {{Uncertainty}} in {{Artificial Intelligence}} and {{Databases}}},
  volume = {54},
  number = {7},
  pages = {876--899},
  issn = {0888-613X},
  doi = {10.1016/j.ijar.2013.03.001},
  urldate = {2023-10-25},
  abstract = {Different abstract argumentation frameworks have been used for various applications within multi-agents systems. Among them, bipolar frameworks make use of both attack and support relations between arguments. However, there is no single interpretation of the support, and the handling of bipolarity cannot avoid a deeper analysis of the notion of support. In this paper we consider three recent proposals for specializing the support relation in abstract argumentation: the deductive support, the necessary support and the evidential support. These proposals have been developed independently within different frameworks. We restate these proposals in a common setting, which enables us to undertake a comparative study of the modellings obtained for the three variants of the support. We highlight relationships and differences between these variants, namely a kind of duality between the deductive and the necessary interpretations of the support.}
}

@misc{CentreForArgumentTechnology2017QuickStartGuide,
  title = {A {{Quick Start Guide}} to {{Inference Anchoring Theory}} ({{IAT}})},
  author = {{Centre for Argument Technology}},
  year = {2017},
  month = oct,
  urldate = {2018-09-01}
}

@misc{CentreForArgumentTechnology2022IATAnnotationGuidelines,
  title = {{{IAT}} Annotation Guidelines for {{QT30}}},
  author = {{Centre for Argument Technology}},
  year = {2022},
  month = may,
  urldate = {2024-09-16}
}

@misc{CentreForArgumentTechnology2023QuickStartGuide,
  title = {A {{Quick Start Guide}} to {{Inference Anchoring Theory}} ({{IAT}})},
  author = {{Centre for Argument Technology}},
  year = {2023},
  month = sep,
  urldate = {2024-09-16}
}

@article{Cer2017SemEval2017TaskSemantic,
  title = {{{SemEval-2017 Task}} 1 - {{Semantic Textual Similarity}} - {{Multilingual}} and {{Cross-lingual Focused Evaluation}}.},
  author = {Cer, Daniel M and Diab, Mona T and Agirre, Eneko and {Lopez-Gazpio}, I{\~n}igo and Specia, Lucia},
  year = {2017},
  month = jan,
  journal = {CoRR}
}

@article{Cer2018UniversalSentenceEncoder,
  title = {Universal {{Sentence Encoder}}},
  author = {Cer, Daniel and Yang, Yinfei and Kong, Sheng-yi and Hua, Nan and Limtiaco, Nicole and John, Rhomni St and Constant, Noah and {Guajardo-Cespedes}, Mario and Yuan, Steve and Tar, Chris and Sung, Yun-Hsuan and Strope, Brian and Kurzweil, Ray},
  year = {2018},
  month = apr,
  journal = {arXiv:1803.11175 [cs]},
  eprint = {1803.11175},
  primaryclass = {cs},
  urldate = {2020-08-02},
  abstract = {We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.},
  archiveprefix = {arXiv}
}

@inproceedings{Chakrabarty2019AMPERSANDArgumentMining,
  title = {{{AMPERSAND}}: {{Argument Mining}} for {{PERSuAsive oNline Discussions}}},
  shorttitle = {{{AMPERSAND}}},
  booktitle = {Proceedings of the 2019 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} and the 9th {{International Joint Conference}} on {{Natural Language Processing}} ({{EMNLP-IJCNLP}})},
  author = {Chakrabarty, Tuhin and Hidey, Christopher and Muresan, Smaranda and McKeown, Kathy and Hwang, Alyssa},
  year = {2019},
  month = nov,
  pages = {2933--2943},
  publisher = {Association for Computational Linguistics},
  address = {Hong Kong, China},
  doi = {10.18653/v1/D19-1291},
  urldate = {2020-09-02},
  abstract = {Argumentation is a type of discourse where speakers try to persuade their audience about the reasonableness of a claim by presenting supportive arguments. Most work in argument mining has focused on modeling arguments in monologues. We propose a computational model for argument mining in online persuasive discussion forums that brings together the micro-level (argument as product) and macro-level (argument as process) models of argumentation. Fundamentally, this approach relies on identifying relations between components of arguments in a discussion thread. Our approach for relation prediction uses contextual information in terms of fine-tuning a pre-trained language model and leveraging discourse relations based on Rhetorical Structure Theory. We additionally propose a candidate selection method to automatically predict what parts of one's argument will be targeted by other participants in the discussion. Our models obtain significant improvements compared to recent state-of-the-art approaches using pointer networks and a pre-trained language model.}
}

@inproceedings{Chalaguine2020PersuasiveChatbotUsing,
  title = {A {{Persuasive Chatbot Using}} a {{CrowdSourced Argument Graph}} and {{Concerns}}},
  booktitle = {Proceedings of the 8th {{International Conference}} on {{Computational Models}} of {{Argument}}},
  author = {Chalaguine, Lisa A. and Hunter, Anthony},
  editor = {Prakken, Henry and Bistarelli, Stefano and Santini, Francesco and Taticchi, Carlo},
  year = {2020},
  series = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  volume = {326},
  pages = {9--20},
  publisher = {IOS Press},
  address = {Perugia, Italy},
  doi = {10.3233/FAIA200487},
  abstract = {Chatbots are versatile tools that have the potential of being used for computational persuasion where the chatbot acts as the persuader and the human agent as the persuadee. To allow the user to type his or her arguments, as opposed to selecting them from a menu, the chatbot needs a sufficiently large knowledge base of arguments and counterarguments. And in order to make the user change their current stance on a subject, the chatbot needs a method to select persuasive counterarguments. To address this, we present a chatbot that is equipped with an argument graph and the ability to identify the concerns of the user argument in order to select appropriate counterarguments. We evaluate the bot in a study with participants and show how using our method can make the chatbot more persuasive.}
}

@article{Chen2021Election2020FirstPublic,
  title = {\#{{Election2020}}: The First Public {{Twitter}} Dataset on the 2020 {{US Presidential}} Election},
  shorttitle = {\#{{Election2020}}},
  author = {Chen, Emily and Deb, Ashok and Ferrara, Emilio},
  year = {2021},
  month = apr,
  journal = {Journal of Computational Social Science},
  issn = {2432-2725},
  doi = {10.1007/s42001-021-00117-9},
  urldate = {2022-02-06},
  abstract = {Credible evidence-based political discourse is a critical pillar of democracy and is at the core of guaranteeing free and fair elections. The study of online chatter is paramount, especially in the wake of important voting events like the recent November 3, 2020 U.S. Presidential election and the inauguration on January 21, 2021. Limited access to social media data is often the primary obstacle that limits our abilities to study and understand online political discourse. To mitigate this impediment and empower the Computational Social Science research community, we are publicly releasing a massive-scale, longitudinal dataset of U.S. politics- and election-related tweets. This multilingual dataset encompasses over 1.2 billion tweets and tracks all salient U.S. political trends, actors, and events from 2019 to the time of this writing. It predates and spans the entire period of the Republican and Democratic primaries, with real-time tracking of all presidential contenders on both sides of the aisle. The dataset also focuses on presidential and vice-presidential candidates, the presidential elections and the transition from the Trump administration to the Biden administration. Our dataset release is curated, documented, and will continue to track relevant events. We hope that the academic community, computational journalists, and research practitioners alike will all take advantage of our dataset to study relevant scientific and social issues, including problems like misinformation, information manipulation, conspiracies, and the distortion of online political discourse that has been prevalent in the context of recent election events in the United States. Our dataset is available at: https://github.com/echen102/us-pres-elections-2020.},
  langid = {english}
}

@misc{Chen2023ExploringPotentialLarge,
  title = {Exploring the {{Potential}} of {{Large Language Models}} in {{Computational Argumentation}}},
  author = {Chen, Guizhen and Cheng, Liying and Tuan, Luu Anh and Bing, Lidong},
  year = {2023},
  month = nov,
  number = {arXiv:2311.09022},
  eprint = {2311.09022},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.09022},
  urldate = {2024-02-10},
  abstract = {Computational argumentation has become an essential tool in various fields, including artificial intelligence, law, and public policy. It is an emerging research field in natural language processing (NLP) that attracts increasing attention. Research on computational argumentation mainly involves two types of tasks: argument mining and argument generation. As large language models (LLMs) have demonstrated strong abilities in understanding context and generating natural language, it is worthwhile to evaluate the performance of LLMs on various computational argumentation tasks. This work aims to embark on an assessment of LLMs, such as ChatGPT, Flan models and LLaMA2 models, under zero-shot and few-shot settings within the realm of computational argumentation. We organize existing tasks into 6 main classes and standardise the format of 14 open-sourced datasets. In addition, we present a new benchmark dataset on counter speech generation, that aims to holistically evaluate the end-to-end performance of LLMs on argument mining and argument generation. Extensive experiments show that LLMs exhibit commendable performance across most of these datasets, demonstrating their capabilities in the field of argumentation. We also highlight the limitations in evaluating computational argumentation and provide suggestions for future research directions in this field.},
  archiveprefix = {arXiv}
}

@inproceedings{Cheng2010PredictingPartialOrders,
  title = {Predicting {{Partial Orders}}: {{Ranking}} with {{Abstention}}},
  booktitle = {Machine {{Learning}} and {{Knowledge Discovery}} in {{Databases}}, {{European Conference}}, {{ECML PKDD}} 2010, {{Barcelona}}, {{Spain}}, {{September}} 20-24, 2010, {{Proceedings}}, {{Part I}}},
  author = {Cheng, Weiwei and Rademaker, Micha{\"e}l and De Baets, Bernard and H{\"u}llermeier, Eyke},
  year = {2010},
  month = jan,
  pages = {215--230},
  publisher = {Springer, Berlin, Heidelberg},
  doi = {10.1007/978-3-642-15880-3_20},
  abstract = {The prediction of structured outputs in general and rankings in particular has attracted considerable attention in machine learning in recent years, and different types of ranking problems have...}
}

@inproceedings{Chernodub2019TARGERNeuralArgument,
  title = {{{TARGER}}: {{Neural Argument Mining}} at {{Your Fingertips}}},
  shorttitle = {{{TARGER}}},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}: {{System Demonstrations}}},
  author = {Chernodub, Artem and Oliynyk, Oleksiy and Heidenreich, Philipp and Bondarenko, Alexander and Hagen, Matthias and Biemann, Chris and Panchenko, Alexander},
  year = {2019},
  month = jul,
  pages = {195--200},
  publisher = {Association for Computational Linguistics},
  address = {Florence, Italy},
  doi = {10.18653/v1/P19-3031},
  urldate = {2020-05-24},
  abstract = {We present TARGER, an open source neural argument mining framework for tagging arguments in free input texts and for keyword-based retrieval of arguments from an argument-tagged web-scale corpus. The currently available models are pre-trained on three recent argument mining datasets and enable the use of neural argument mining without any reproducibility effort on the user's side. The open source code ensures portability to other domains and use cases.}
}

@article{Chesnevar2006ArgumentInterchangeFormat,
  title = {Towards an Argument Interchange Format.},
  author = {Ches{\~n}evar, Carlos Iv{\'a}n and McGinnis, Jarred and Modgil, Sanjay and Rahwan, Iyad and Reed, Chris and Simari, Guillermo Ricardo and South, Matthew and Vreeswijk, Gerard and Willmott, Steven},
  year = {2006},
  month = jan,
  journal = {The Knowledge Enigneering Review},
  volume = {21},
  number = {04},
  pages = {293},
  doi = {10.1017/S0269888906001044},
  urldate = {2018-09-01},
  abstract = {The theory of argumentation is a rich, interdisciplinary area of research straddling the fields of artificial intelligence, philosophy, communication studies, linguistics and psychology. In the last few years, significant progress has been made in understanding the theoretical properties of different argumentation logics. However, one major barrier to the development and practical deployment of argumentation systems is the lack of a shared, agreed notation or `interchange format' for argumentation and arguments. In this paper, we describe a draft specification for an argument interchange format (AIF) intended for representation and exchange of data between various argumentation tools and agent-based applications. It represents a consensus `abstract model' established by researchers across fields of argumentation, artificial intelligence and multi-agent systems. In its current form, this specification is intended as a starting point for further discussion and elaboration by the community, rather than an attempt at a definitive, all-encompassing model. However, to demonstrate proof of concept, a use case scenario is briefly described. Moreover, three concrete realizations or `reifications' of the abstract model are illustrated.}
}

@inproceedings{Cho2010ReweightedRandomWalks,
  title = {Reweighted {{Random Walks}} for {{Graph Matching}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2010},
  author = {Cho, Minsu and Lee, Jungmin and Lee, Kyoung Mu},
  editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
  year = {2010},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {492--505},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-15555-0_36},
  abstract = {Graph matching is an essential problem in computer vision and machine learning. In this paper, we introduce a random walk view on the problem and propose a robust graph matching algorithm against outliers and deformation. Matching between two graphs is formulated as node selection on an association graph whose nodes represent candidate correspondences between the two graphs. The solution is obtained by simulating random walks with reweighting jumps enforcing the matching constraints on the association graph. Our algorithm achieves noise-robust graph matching by iteratively updating and exploiting the confidences of candidate correspondences. In a practical sense, our work is of particular importance since the real-world matching problem is made difficult by the presence of noise and outliers. Extensive and comparative experiments demonstrate that it outperforms the state-of-the-art graph matching algorithms especially in the presence of outliers and deformation.},
  isbn = {978-3-642-15555-0},
  langid = {english}
}

@article{Chollampatt2018MultilayerConvolutionalEncoderDecoder,
  title = {A {{Multilayer Convolutional Encoder-Decoder Neural Network}} for {{Grammatical Error Correction}}},
  author = {Chollampatt, Shamil and Ng, Hwee Tou},
  year = {2018},
  month = jan,
  journal = {arXiv:1801.08831 [cs]},
  eprint = {1801.08831},
  primaryclass = {cs},
  urldate = {2020-08-03},
  abstract = {We improve automatic correction of grammatical, orthographic, and collocation errors in text using a multilayer convolutional encoder-decoder neural network. The network is initialized with embeddings that make use of character N-gram information to better suit this task. When evaluated on common benchmark test data sets (CoNLL-2014 and JFLEG), our model substantially outperforms all prior neural approaches on this task as well as strong statistical machine translation-based systems with neural and task-specific features trained on the same data. Our analysis shows the superiority of convolutional neural networks over recurrent neural networks such as long short-term memory (LSTM) networks in capturing the local context via attention, and thereby improving the coverage in correcting grammatical errors. By ensembling multiple models, and incorporating an N-gram language model and edit features via rescoring, our novel method becomes the first neural approach to outperform the current state-of-the-art statistical machine translation-based approach, both in terms of grammaticality and fluency.},
  archiveprefix = {arXiv}
}

@book{Choudhary1993ElementsComplexAnalysis,
  title = {The {{Elements}} of {{Complex Analysis}}},
  author = {Choudhary, B.},
  year = {1993},
  publisher = {New Age International},
  abstract = {This Book Is Intended To Be A Simple And Easy Introduction To The Subject. It Is Meant As A Textbook For A Course In Complex Analysis At Postgraduate Level Of Indian Universities.Some Of The Welcome Features Of The Book Are: Proofs And Motivation For The Theory: Examples Are Provided To Illustrate The Concepts; Exercises Of Various Levels Of Difficulty Are Given At The End Of Every Chapter: Keeping In View The Applied Nature Of The Subject, Ordinary Linear Homogeneous Differential Equations Of The Second Order And Conformal Mapping And Its Applications Are Given More Attention Than Most Other Books: Uniform Approximation And Elliptic Functions Are Treated In Great Detail; There Is Also A Detailed Treatment Of Harmonic Functions, Weierstrass Approximation Theorem, Analytic Continuation, Riemann Mapping Theorem, Homological Version OfCauchys Theorem And Its Applications; Diagrams Are Provided Whenever Feasible To Help The Reader Develop Skill In Using Imagination To Visualise Abstract Ideas; Solutions To Some Selected Exercises Which Involve Lot Of New Ideas And Theoretical Considerations Have Been Provided At The End.},
  googlebooks = {5K9i2YwgTjYC},
  isbn = {978-81-224-0399-2},
  langid = {english}
}

@book{Cimiano2024RobustArgumentationMachines,
  title = {Robust {{Argumentation Machines}}: {{First International Conference}}, {{RATIO}} 2024, {{Bielefeld}}, {{Germany}}, {{June}} 5--7, 2024, {{Proceedings}}},
  shorttitle = {Robust {{Argumentation Machines}}},
  editor = {Cimiano, Philipp and Frank, Anette and Kohlhase, Michael and Stein, Benno},
  year = {2024},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {14638},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63536-6},
  urldate = {2024-07-18},
  copyright = {https://creativecommons.org/licenses/by/4.0},
  isbn = {978-3-031-63535-9 978-3-031-63536-6},
  langid = {english}
}

@inproceedings{Cocarascu2017IdentifyingAttackSupport,
  title = {Identifying Attack and Support Argumentative Relations Using Deep Learning},
  booktitle = {Proceedings of the 2017 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Cocarascu, Oana and Toni, Francesca},
  year = {2017},
  month = sep,
  pages = {1374--1379},
  publisher = {Association for Computational Linguistics},
  address = {Copenhagen, Denmark},
  doi = {10.18653/v1/D17-1144},
  urldate = {2022-01-13},
  abstract = {We propose a deep learning architecture to capture argumentative relations of attack and support from one piece of text to another, of the kind that naturally occur in a debate. The architecture uses two (unidirectional or bidirectional) Long Short-Term Memory networks and (trained or non-trained) word embeddings, and allows to considerably improve upon existing techniques that use syntactic features and supervised classifiers for the same form of (relation-based) argument mining.}
}

@inproceedings{Cocarascu2020DatasetIndependentBaselines,
  title = {Dataset {{Independent Baselines}} for {{Relation Prediction}} in {{Argument Mining}}},
  booktitle = {Proceedings of the 8th {{International Conference}} on {{Computational Models}} of {{Argument}}},
  author = {Cocarascu, Oana and Cabrio, Elena and Villata, Serena and Toni, Christopher},
  editor = {Prakken, Henry and Bistarelli, Stefano and Santini, Francesco and Taticchi, Carlo},
  year = {2020},
  series = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  volume = {326},
  pages = {45--52},
  publisher = {IOS Press},
  address = {Perugia, Italy},
  doi = {10.3233/FAIA200490},
  abstract = {Argument(ation) Mining (AM) is the research area which aims at extracting argument components and predicting argumentative relations (i.e., support and attack) from text. In particular, numerous approaches have been proposed in the literature to predict the relations holding between arguments, and application-specific annotated resources were built for this purpose. Despite the fact that these resources were created to experiment on the same task, the definition of a single relation prediction method to be successfully applied to a significant portion of these datasets is an open research problem in AM. This means that none of the methods proposed in the literature can be easily ported from one resource to another. In this paper, we address this problem by proposing a set of dataset independent strong neural baselines which obtain homogeneous results on all the datasets proposed in the literature for the argumentative relation prediction task in AM. Thus, our baselines can be employed by the AM community to compare more effectively how well a method performs on the argumentative relation prediction task.}
}

@misc{Cocarascu2020DatasetIndependentSet,
  title = {A {{Dataset Independent Set}} of {{Baselines}} for {{Relation Prediction}} in {{Argument Mining}}},
  author = {Cocarascu, Oana and Cabrio, Elena and Villata, Serena and Toni, Francesca},
  year = {2020},
  month = feb,
  number = {arXiv:2003.04970},
  eprint = {2003.04970},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2003.04970},
  urldate = {2023-10-20},
  abstract = {Argument Mining is the research area which aims at extracting argument components and predicting argumentative relations (i.e.,support and attack) from text. In particular, numerous approaches have been proposed in the literature to predict the relations holding between the arguments, and application-specific annotated resources were built for this purpose. Despite the fact that these resources have been created to experiment on the same task, the definition of a single relation prediction method to be successfully applied to a significant portion of these datasets is an open research problem in Argument Mining. This means that none of the methods proposed in the literature can be easily ported from one resource to another. In this paper, we address this problem by proposing a set of dataset independent strong neural baselines which obtain homogeneous results on all the datasets proposed in the literature for the argumentative relation prediction task. Thus, our baselines can be employed by the Argument Mining community to compare more effectively how well a method performs on the argumentative relation prediction task.},
  archiveprefix = {arXiv}
}

@article{Cohen1960CoefficientAgreementNominal,
  title = {A {{Coefficient}} of {{Agreement}} for {{Nominal Scales}}},
  author = {Cohen, Jacob},
  year = {1960},
  month = apr,
  journal = {Educational and Psychological Measurement},
  volume = {20},
  number = {1},
  pages = {37--46},
  publisher = {SAGE Publications Inc},
  issn = {0013-1644},
  doi = {10.1177/001316446002000104},
  urldate = {2021-03-07},
  langid = {english}
}

@article{Cohen1968WeightedKappaNominal,
  title = {Weighted Kappa: {{Nominal}} Scale Agreement Provision for Scaled Disagreement or Partial Credit.},
  shorttitle = {Weighted Kappa},
  author = {Cohen, Jacob},
  year = {1968},
  journal = {Psychological Bulletin},
  volume = {70},
  number = {4},
  pages = {213--220},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/h0026256},
  urldate = {2021-03-07},
  langid = {english}
}

@inproceedings{Collins2002DiscriminativeTrainingMethods,
  title = {Discriminative {{Training Methods}} for {{Hidden Markov Models}}: {{Theory}} and {{Experiments}} with {{Perceptron Algorithms}}},
  shorttitle = {Discriminative {{Training Methods}} for {{Hidden Markov Models}}},
  booktitle = {Proceedings of the 2002 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}} 2002)},
  author = {Collins, Michael},
  year = {2002},
  month = jul,
  pages = {1--8},
  publisher = {Association for Computational Linguistics},
  doi = {10.3115/1118693.1118694},
  urldate = {2021-02-09}
}

@article{Colom2010HumanIntelligenceBrain,
  title = {Human Intelligence and Brain Networks},
  author = {Colom, Roberto and Karama, Sherif and Jung, Rex E. and Haier, Richard J.},
  year = {2010},
  month = dec,
  journal = {Dialogues in Clinical Neuroscience},
  volume = {12},
  number = {4},
  pages = {489--501},
  issn = {1294-8322},
  urldate = {2021-01-16},
  abstract = {Intelligence can be defined as a general mental ability for reasoning, problem solving, and learning. Because of its general nature, intelligence integrates cognitive functions such as perception, attention, memory, language, or planning. On the basis of this definition, intelligence can be reliably measured by standardized tests with obtained scores predicting several broad social outcomes such as educational achievement, job performance, health, and longevity. A detailed understanding of the brain mechanisms underlying this general mental ability could provide significant individual and societal benefits. Structural and functional neuroimaging studies have generally supported a frontoparietal network relevant for intelligence. This same network has also been found to underlie cognitive functions related to perception, short-term memory storage, and language. The distributed nature of this network and its involvement in a wide range of cognitive functions fits well with the integrative nature of intelligence. A new key phase of research is beginning to investigate how functional networks relate to structural networks, with emphasis on how distributed brain areas communicate with each other.},
  pmcid = {PMC3181994},
  pmid = {21319494}
}

@inproceedings{Compton1990KnowledgeContextStrategy,
  title = {Knowledge in Context: {{A}} Strategy for Expert System Maintenance},
  shorttitle = {Knowledge in Context},
  booktitle = {{{AI}} '88},
  author = {Compton, P. and Jansen, R.},
  editor = {Barter, Christopher J. and Brooks, Michael J.},
  year = {1990},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {292--306},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-52062-7_86},
  abstract = {Knowledge engineering, obtaining knowledge from experts and incorporating it into expert systems is difficult and time consuming. We suggest that these difficulties arise because experts never report on how they reach a decision, rather they justify why the decision is correct. These justifications vary markedly with the context in which they are required, but in context they are accurate and adequate; the difficulties in knowledge engineering arise from taking the justification out of context. We therefore hypothesise that knowledge engineering may be obviated, particularly in the long term maintenance of expert systems, if the rules experts provide are used in the context in which they are given. This paper describes work in progress to test this hypothesis.},
  isbn = {978-3-540-46875-2},
  langid = {english}
}

@inproceedings{Conneau2017SupervisedLearningUniversal,
  title = {Supervised {{Learning}} of {{Universal Sentence Representations}} from {{Natural Language Inference Data}}},
  booktitle = {Proceedings of the 2017 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Conneau, Alexis and Kiela, Douwe and Schwenk, Holger and Barrault, Lo{\"i}c and Bordes, Antoine},
  year = {2017},
  month = sep,
  pages = {670--680},
  publisher = {Association for Computational Linguistics},
  address = {Copenhagen, Denmark},
  doi = {10.18653/v1/D17-1070},
  urldate = {2020-10-20},
  abstract = {Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available.}
}

@article{Craven2016ArgumentGraphsAssumptionbased,
  title = {Argument Graphs and Assumption-Based Argumentation},
  author = {Craven, Robert and Toni, Francesca},
  year = {2016},
  month = apr,
  journal = {Artificial Intelligence},
  volume = {233},
  pages = {1--59},
  issn = {0004-3702},
  doi = {10.1016/j.artint.2015.12.004},
  urldate = {2020-04-27},
  abstract = {Arguments in structured argumentation are usually defined as trees, and extensions as sets of such tree-based arguments with various properties depending on the particular argumentation semantics. However, these arguments and extensions may have redundancies as well as circularities, which are conceptually and computationally undesirable. Focusing on the specific case of Assumption-Based Argumentation (ABA), we propose novel notions of arguments and admissible/grounded extensions, both defined in terms of graphs. We show that this avoids the redundancies and circularities of standard accounts, and set out the relationship to standard tree-based arguments and admissible/grounded extensions (as sets of arguments). We also define new notions of graph-based admissible/grounded dispute derivations for ABA, for determining whether specific sentences hold under the admissible/grounded semantics. We show that these new derivations are superior with respect to standard dispute derivations in that they are complete in general, rather than solely for restricted classes of ABA frameworks. Finally, we present several experiments comparing the implementation of graph-based admissible/grounded dispute derivations with implementations of standard dispute derivations, suggesting that the graph-based approach is computationally advantageous.},
  langid = {english}
}

@inproceedings{Croitoru2025ChildRobotInteractionExperiment,
  title = {A {{Child-Robot Interaction Experiment}} to~{{Analyze Gender Stereotypes}} in~the~{{Perception}} of~{{Mathematical Abilities}}},
  booktitle = {Artificial {{Intelligence XLI}}},
  author = {Croitoru, Madalina and Laviron, Pablo and Bando, Sio and Gilles, Eric and Miled, Amine and Anders, Royce and Blanc, Nathalie and Ganesh, Gowrishankar and Brigaud, Emmanuelle},
  editor = {Bramer, Max and Stahl, Frederic},
  year = {2025},
  pages = {232--237},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-77918-3_17},
  abstract = {This study examines the use of social robotics in education, focusing on reducing the gender biases child students may have in the perception of their mathematical ability and potential. Our initial pilot with twenty 7-year-olds provides insights into the potential of combining AI with educational strategies. We discuss our findings, and experimental setup involving ChatGPT4, and future research directions.},
  isbn = {978-3-031-77918-3},
  langid = {english}
}

@article{Cui2019Integrative3CEvaluation,
  title = {An {{Integrative 3C}} Evaluation Framework for {{Explainable Artificial Intelligence}}},
  author = {Cui, Xiaocong and Lee, Jung Min and Hsieh, J. Po-An},
  year = {2019},
  month = jul,
  journal = {AMCIS 2019 Proceedings}
}

@inproceedings{Cyras2016AbstractArgumentationCasebased,
  title = {Abstract Argumentation for Case-Based Reasoning},
  booktitle = {Proceedings of the {{Fifteenth International Conference}} on {{Principles}} of {{Knowledge Representation}} and {{Reasoning}}},
  author = {{\v C}yras, Kristijonas and Satoh, Ken and Toni, Francesca},
  year = {2016},
  month = apr,
  series = {{{KR}}'16},
  pages = {549--552},
  publisher = {AAAI Press},
  address = {Cape Town, South Africa},
  urldate = {2023-07-26},
  abstract = {We investigate case-based reasoning (CBR) problems where cases are represented by abstract factors and (positive or negative) outcomes, and an outcome for a new case, represented by abstract factors, needs to be established. To this end, we employ abstract argumentation (AA) and propose a novel methodology for CBR, called AA-CBR. The argumentative formulation naturally allows to characterise the computation of an outcome as a dialogical process between a proponent and an opponent, and can also be used to extract explanations for why an outcome for a new case is (not) computed.}
}

@inproceedings{Cyras2016ExplanationCaseBasedReasoning,
  title = {Explanation for {{Case-Based Reasoning}} via {{Abstract Argumentation}}},
  booktitle = {Computational {{Models}} of {{Argument}}},
  author = {{\v C}yras, Kristijonas and Satoh, Ken and Toni, Francesca},
  year = {2016},
  pages = {243--254},
  publisher = {IOS Press},
  doi = {10.3233/978-1-61499-686-6-243},
  urldate = {2023-07-26}
}

@inproceedings{Dabbish2012SocialCodingGitHub,
  title = {Social Coding in {{GitHub}}: Transparency and Collaboration in an Open Software Repository},
  shorttitle = {Social Coding in {{GitHub}}},
  booktitle = {Proceedings of the {{ACM}} 2012 Conference on {{Computer Supported Cooperative Work}}},
  author = {Dabbish, Laura and Stuart, Colleen and Tsay, Jason and Herbsleb, Jim},
  year = {2012},
  month = feb,
  series = {{{CSCW}} '12},
  pages = {1277--1286},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2145204.2145396},
  urldate = {2022-05-03},
  abstract = {Social applications on the web let users track and follow the activities of a large number of others regardless of location or affiliation. There is a potential for this transparency to radically improve collaboration and learning in complex knowledge-based activities. Based on a series of in-depth interviews with central and peripheral GitHub users, we examined the value of transparency for large-scale distributed collaborations and communities of practice. We find that people make a surprisingly rich set of social inferences from the networked activity information in GitHub, such as inferring someone else's technical goals and vision when they edit code, or guessing which of several similar projects has the best chance of thriving in the long term. Users combine these inferences into effective strategies for coordinating work, advancing technical skills and managing their reputation.},
  isbn = {978-1-4503-1086-4}
}

@misc{Dai2017NewsArticles,
  title = {News {{Articles}}},
  author = {Dai, Tianru},
  year = {2017},
  month = mar,
  publisher = {Harvard Dataverse},
  doi = {10.7910/DVN/GMFCTR},
  urldate = {2024-02-10},
  abstract = {This is a reusable publicly-available dataset for ``media bias'' studies. The content of this dataset is publish date, title, subtitle and text for 3824 news articles. These articles are collected by a project within 3 months from December of 2016 to march 2017. The source of these news articles are from ABC News, CNN news, The Huffington Post, BBC News, DW News, TASS News, Al Jazeera News, China Daily and RTE News. All of them are collected by using RSS feeds of each news sites. (2017-3-31)},
  langid = {english}
}

@misc{Darcet2024VisionTransformersNeed,
  title = {Vision {{Transformers Need Registers}}},
  author = {Darcet, Timoth{\'e}e and Oquab, Maxime and Mairal, Julien and Bojanowski, Piotr},
  year = {2024},
  month = apr,
  number = {arXiv:2309.16588},
  eprint = {2309.16588},
  primaryclass = {cs},
  doi = {10.48550/arXiv.2309.16588},
  urldate = {2024-05-12},
  abstract = {Transformers have recently emerged as a powerful tool for learning visual representations. In this paper, we identify and characterize artifacts in feature maps of both supervised and self-supervised ViT networks. The artifacts correspond to high-norm tokens appearing during inference primarily in low-informative background areas of images, that are repurposed for internal computations. We propose a simple yet effective solution based on providing additional tokens to the input sequence of the Vision Transformer to fill that role. We show that this solution fixes that problem entirely for both supervised and self-supervised models, sets a new state of the art for self-supervised visual models on dense visual prediction tasks, enables object discovery methods with larger models, and most importantly leads to smoother feature maps and attention maps for downstream visual processing.},
  archiveprefix = {arXiv}
}

@misc{Das2024EndtoEndArgumentMining,
  title = {End-to-{{End Argument Mining}} as {{Augmented Natural Language Generation}}},
  author = {Das, Nilmadhab and Choudhary, Vishal and Saradhi, V. Vijaya and Anand, Ashish},
  year = {2024},
  month = jun,
  number = {arXiv:2406.08606},
  eprint = {2406.08606},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-06-24},
  abstract = {Argument Mining (AM) is a crucial aspect of computational argumentation, which deals with the identification and extraction of Argumentative Components (ACs) and their corresponding Argumentative Relations (ARs). Most prior works have solved these problems by dividing them into multiple subtasks. And the available end-to-end setups are mostly based on the dependency parsing approach. This work proposes a unified end-to-end framework based on a generative paradigm, in which the argumentative structures are framed into label-augmented text, called Augmented Natural Language (ANL). Additionally, we explore the role of different types of markers in solving AM tasks. Through different marker-based fine-tuning strategies, we present an extensive study by integrating marker knowledge into our generative model. The proposed framework achieves competitive results to the state-of-the-art (SoTA) model and outperforms several baselines.},
  archiveprefix = {arXiv}
}

@article{Davis2015CommonsenseReasoningCommonsense,
  title = {Commonsense Reasoning and Commonsense Knowledge in Artificial Intelligence},
  author = {Davis, Ernest and Marcus, Gary},
  year = {2015},
  month = aug,
  journal = {Communications of the ACM},
  volume = {58},
  number = {9},
  pages = {92--103},
  issn = {0001-0782},
  doi = {10.1145/2701413},
  urldate = {2020-06-07},
  abstract = {AI has seen great advances of many kinds recently, but there is one critical area where progress has been extremely slow: ordinary commonsense.}
}

@article{Daxenberger2020ArgumenTextArgumentClassification,
  title = {{{ArgumenText}}: {{Argument Classification}} and {{Clustering}} in a~{{Generalized Search Scenario}}},
  shorttitle = {{{ArgumenText}}},
  author = {Daxenberger, Johannes and Schiller, Benjamin and Stahlhut, Chris and Kaiser, Erik and Gurevych, Iryna},
  year = {2020},
  month = jun,
  journal = {Datenbank-Spektrum},
  issn = {1610-1995},
  doi = {10.1007/s13222-020-00347-7},
  urldate = {2020-07-09},
  abstract = {The ArgumenText project creates argument mining technology for big and heterogeneous data and aims to evaluate its use in real-world applications. The technology mines and clusters arguments from a~variety of textual sources for a~large range of topics and in multiple languages. Its main strength is its generalization to very different textual sources including web crawls, news data, or customer reviews. We validated the technology with a~focus on supporting decisions in innovation management as well as customer feedback analysis. Along with its public argument search engine and API, ArgumenText has released multiple datasets for argument classification and clustering. This contribution outlines the major technology-related challenges and proposed solutions for the tasks of argument extraction from heterogeneous sources and argument clustering. It also lays out exemplary industry applications and remaining challenges.},
  langid = {english}
}

@misc{DeepSeek-AI2025DeepSeekR1IncentivizingReasoning,
  title = {{{DeepSeek-R1}}: {{Incentivizing Reasoning Capability}} in {{LLMs}} via {{Reinforcement Learning}}},
  shorttitle = {{{DeepSeek-R1}}},
  author = {{DeepSeek-AI} and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
  year = {2025},
  month = jan,
  number = {arXiv:2501.12948},
  eprint = {2501.12948},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.12948},
  urldate = {2025-01-26},
  abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},
  archiveprefix = {arXiv}
}

@inproceedings{Defourneaux1997AnalogyAbductionAutomated,
  title = {Analogy and {{Abduction}} in {{Automated Deduction}}},
  booktitle = {Proc. {{IJCAI-97}}},
  author = {Defourneaux, Gilles and Peltier, Nicolas},
  year = {1997},
  pages = {216--221},
  publisher = {Morgan Kaufmann},
  abstract = {A method is presented for analogical reasoning in Automated Deduction. We focus on the abductive aspects of analogy and give a unified treatment for theorems and non-theorems. Abduction allows to deal with partial analogies thus strongly increasing the application field of the method. It also allows to detect \&quot;bad analogies\&quot; in several cases. Explanatory examples as well as more realistic examples quantifying the effects of using analogy (for theorem-proving and for counter-example building) are given. 1}
}

@inproceedings{DelCorro2013ClausIEClausebasedOpen,
  title = {{{ClausIE}}: Clause-Based Open Information Extraction},
  shorttitle = {{{ClausIE}}},
  booktitle = {Proceedings of the 22nd International Conference on {{World Wide Web}}},
  author = {Del Corro, Luciano and Gemulla, Rainer},
  year = {2013},
  month = may,
  series = {{{WWW}} '13},
  pages = {355--366},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2488388.2488420},
  urldate = {2023-07-26},
  abstract = {We propose ClausIE, a novel, clause-based approach to open information extraction, which extracts relations and their arguments from natural language text. ClausIE fundamentally differs from previous approaches in that it separates the detection of ``useful'' pieces of information expressed in a sentence from their representation in terms of extractions. In more detail, ClausIE exploits linguistic knowledge about the grammar of the English language to first detect clauses in an input sentence and to subsequently identify the type of each clause according to the grammatical function of its constituents. Based on this information, ClausIE is able to generate high-precision extractions; the representation of these extractions can be flexibly customized to the underlying application. ClausIE is based on dependency parsing and a small set of domain-independent lexica, operates sentence by sentence without any post-processing, and requires no training data (whether labeled or unlabeled). Our experimental study on various real-world datasets suggests that ClausIE obtains higher recall and higher precision than existing approaches, both on high-quality text as well as on noisy text as found in the web.},
  isbn = {978-1-4503-2035-1}
}

@inproceedings{DeLiddo2021UnderstandingFailuresPotentials,
  title = {Understanding {{Failures}} and {{Potentials}} of {{Argumentation Tools}} for {{Public Deliberation}}},
  booktitle = {Proceedings of the 10th {{International Conference}} on {{Communities}} \& {{Technologies}} - {{Wicked Problems}} in the {{Age}} of {{Tech}}},
  author = {De Liddo, Anna and Strube, Rosa},
  year = {2021},
  month = jun,
  series = {C\&amp;{{T}} '21},
  pages = {75--88},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3461564.3461584},
  urldate = {2023-09-21},
  abstract = {Argument mapping technologies have been historically proposed in Computer Supported Cooperative Work (CSCW) and Computer Supported Argument Visualisation (CSAV) research to improve online deliberation practices, but they have hardly overcome issues of non--expert users' uptake. This paper presents LiteMap a novel online collaborative argument mapping tool which combines web annotation with light-weight argument mapping features to enable visual summarisation and sensemaking of public online debates. Lessons learned from a user study indicate that LiteMap can be effectively used by untrained users to collectively summarize online discussion forum conversations. LiteMap is reported to improve self-reflection on both, group performance and assessment of the quality of an online conversation. The use of the argument mapping tool has also enhanced the mappers' understanding of the nature of the debated issues. Nonetheless, map creators have reported the need for parallel negotiation channels to disambiguate meaning and manage disagreement while co-creating an argument map.},
  isbn = {978-1-4503-9056-9}
}

@phdthesis{Dellaiera2024ReproducibilitySoftwareEngineering,
  title = {Reproducibility in {{Software Engineering}}},
  author = {Dellaiera, Pol},
  year = {2024},
  month = aug,
  doi = {10.5281/zenodo.13208605},
  urldate = {2024-08-28},
  abstract = {The concept of reproducibility has long been a cornerstone in scientific research, ensuring that results are robust, repeatable, and can be independently verified. This concept has been extended to computer science, focusing on the ability to recreate identical software artefacts. However, the importance of reproducibility in software engineering is often overlooked, leading to challenges in the validation, security, and reliability of software products. This master's thesis aims to investigate the current state of reproducibility in software engineering, exploring both the barriers and potential solutions to making software more reproducible and raising awareness. It identifies key factors that impede reproducibility such as inconsistent environments, lack of standardisation, and incomplete documentation. To tackle these issues, I propose an empirical comparison of tools facilitating software reproducibility. To provide a comprehensive assessment of reproducibility in software engineering, this study adopts a methodology that involves a hands-on evaluation of four different methods and tools. Through a systematic evaluation of these tools, this research seeks to determine their effectiveness in establishing and maintaining identical software environments and builds. This study contributes to academic knowledge and offers practical insights that could influence future software development protocols and standards.},
  langid = {english}
}

@inproceedings{Deng2023ResolutionAnalogiesStrings,
  title = {Resolution of {{Analogies Between Strings}} in the {{Case}} of {{Multiple Solutions}}},
  booktitle = {Proceedings of the {{Workshops}} at the 31st {{International Conference}} on {{Case-Based Reasoning}} ({{ICCBR-WS}} 2023)},
  author = {Deng, Xulin and Lepage, Yves},
  editor = {Malburg, Lukas and Verma, Deepika},
  year = {2023},
  month = jul,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3438},
  pages = {3--14},
  publisher = {CEUR},
  address = {Aberdeen, Scotland},
  issn = {1613-0073},
  urldate = {2023-07-31},
  langid = {english}
}

@article{Devlin2004MorphologyInternalStructure,
  title = {Morphology and the Internal Structure of Words},
  author = {Devlin, Joseph T. and Jamison, Helen L. and Matthews, Paul M. and Gonnerman, Laura M.},
  year = {2004},
  month = oct,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {101},
  number = {41},
  pages = {14984--14988},
  publisher = {National Academy of Sciences},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0403766101},
  urldate = {2021-03-08},
  abstract = {Morphology is the aspect of language concerned with the internal structure of words, and languages vary in the extent to which they rely on morphological structure. Consequently, it is not clear whether morphology is a basic element of a linguistic structure or whether it emerges from systematic regularities between the form and meaning of words. Here, we looked for evidence of morphological structure at a neural systems level by using a visual masked priming paradigm and functional MRI. Form and meaning relations were manipulated in a 2 {\texttimes} 2 design to identify reductions in blood oxygenation level-dependent signal related to shared form (e.g., corner-corn), shared meaning (e.g., idea-notion), and shared morphemes (e.g., boldly-bold, which overlapped in both form and meaning). Relative to unrelated pairs (e.g., ozone-hero), morphologically related items reduced blood oxygenation level-dependent signal in the posterior angular gyrus bilaterally, left occipitotemporal cortex, and left middle temporal gyrus. In the posterior angular gyrus, a neural priming effect was observed for all three priming conditions, possibly reflecting reduced attentional demands rather than overlapping linguistic representations per se. In contrast, the reductions seen in the left occipitotemporal cortex and left middle temporal gyrus corresponded, respectively, to main effects of orthographic and semantic overlap. As neural regions sensitive to morphological structure overlapped almost entirely with regions sensitive to orthographic and semantic relatedness, our results suggest that morphology emerges from the convergence of form and meaning.},
  chapter = {Biological Sciences},
  copyright = {Copyright {\copyright} 2004, The National Academy of Sciences},
  langid = {english},
  pmid = {15358857}
}

@inproceedings{Devlin2019BERTPretrainingDeep,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  booktitle = {Proceedings of the 2019 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}, {{Volume}} 1 ({{Long}} and {{Short Papers}})},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  editor = {Burstein, Jill and Doran, Christy and Solorio, Thamar},
  year = {2019},
  month = jun,
  pages = {4171--4186},
  publisher = {Association for Computational Linguistics},
  address = {Minneapolis, Minnesota},
  doi = {10.18653/v1/N19-1423},
  urldate = {2024-07-15},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).}
}

@misc{DeWynter2024HaveArgumentPlease,
  title = {"{{I}}'d {{Like}} to {{Have}} an {{Argument}}, {{Please}}": {{Argumentative Reasoning}} in {{Large Language Models}}},
  shorttitle = {"{{I}}'d {{Like}} to {{Have}} an {{Argument}}, {{Please}}"},
  author = {{de Wynter}, Adrian and Yuan, Tangming},
  year = {2024},
  month = jun,
  number = {arXiv:2309.16938},
  eprint = {2309.16938},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.16938},
  urldate = {2024-06-21},
  abstract = {We evaluate two large language models (LLMs) ability to perform argumentative reasoning. We experiment with argument mining (AM) and argument pair extraction (APE), and evaluate the LLMs' ability to recognize arguments under progressively more abstract input and output (I/O) representations (e.g., arbitrary label sets, graphs, etc.). Unlike the well-known evaluation of prompt phrasings, abstraction evaluation retains the prompt's phrasing but tests reasoning capabilities. We find that scoring-wise the LLMs match or surpass the SOTA in AM and APE, and under certain I/O abstractions LLMs perform well, even beating chain-of-thought--we call this symbolic prompting. However, statistical analysis on the LLMs outputs when subject to small, yet still human-readable, alterations in the I/O representations (e.g., asking for BIO tags as opposed to line numbers) showed that the models are not performing reasoning. This suggests that LLM applications to some tasks, such as data labelling and paper reviewing, must be done with care.},
  archiveprefix = {arXiv}
}

@inproceedings{Diallo2019LearningAnalogyPreservingSentence,
  title = {Learning {{Analogy-Preserving Sentence Embeddings}} for {{Answer Selection}}},
  booktitle = {Proceedings of the 23rd {{Conference}} on {{Computational Natural Language Learning}} ({{CoNLL}})},
  author = {Diallo, A{\"i}ssatou and Zopf, Markus and F{\"u}rnkranz, Johannes},
  year = {2019},
  month = nov,
  pages = {910--919},
  publisher = {Association for Computational Linguistics},
  address = {Hong Kong, China},
  doi = {10.18653/v1/K19-1085},
  urldate = {2020-08-03},
  abstract = {Answer selection aims at identifying the correct answer for a given question from a set of potentially correct answers. Contrary to previous works, which typically focus on the semantic similarity between a question and its answer, our hypothesis is that question-answer pairs are often in analogical relation to each other. Using analogical inference as our use case, we propose a framework and a neural network architecture for learning dedicated sentence embeddings that preserve analogical properties in the semantic space. We evaluate the proposed method on benchmark datasets for answer selection and demonstrate that our sentence embeddings indeed capture analogical properties better than conventional embeddings, and that analogy-based question answering outperforms a comparable similarity-based technique.}
}

@inproceedings{Diebold2024OlaaafGeneralAdaptation,
  title = {Olaaaf: {{A General Adaptation Prototype}}},
  shorttitle = {Olaaaf},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Diebold, Erwan and Kabrit, Yan and Kril, Axel and Lieber, Jean and Malvaud, Paul and Nauer, Emmanuel and Sipp, Jules},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {223--239},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_15},
  abstract = {Adaptation is often considered a complex issue during the design of a case-based reasoning system. Various approaches can be found in the literature, but their scopes are often limited to a relatively narrow range of applications.However, a general approach to adaptation based on belief revision has been developed over the years and applied in several formalisms, these formalisms being chosen for particular needs. This article presents the first version of \$\${\textbackslash}text \{Olaaaf\}\$\$Olaaaf, a general adaptation prototype based on belief revision whose long-term objective is to cover a wide range of adaptation processes. It is based on a formalism that covers both attribute-value pairs (often used for representing cases) and taxonomies (often used for representing domain knowledge). It is shown through an example how this system works, and it is discussed how it can be used for other complex adaptations.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@inproceedings{Dijkman2009GraphMatchingAlgorithms,
  title = {Graph {{Matching Algorithms}} for {{Business Process Model Similarity Search}}},
  booktitle = {Business {{Process Management}}},
  author = {Dijkman, Remco and Dumas, Marlon and {Garc{\'i}a-Ba{\~n}uelos}, Luciano},
  editor = {Dayal, Umeshwar and Eder, Johann and Koehler, Jana and Reijers, Hajo A.},
  year = {2009},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {48--63},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-03848-8_5},
  abstract = {We investigate the problem of ranking all process models in a repository according to their similarity with respect to a given process model. We focus specifically on the application of graph matching algorithms to this similarity search problem. Since the corresponding graph matching problem is NP-complete, we seek to find a compromise between computational complexity and quality of the computed ranking. Using a repository of 100 process models, we evaluate four graph matching algorithms, ranging from a greedy one to a relatively exhaustive one. The results show that the mean average precision obtained by a fast greedy algorithm is close to that obtained with the most exhaustive algorithm.},
  isbn = {978-3-642-03848-8},
  langid = {english}
}

@article{Dijkstra1959NoteTwoProblems,
  title = {A Note on Two Problems in Connexion with Graphs},
  author = {Dijkstra, E. W.},
  year = {1959},
  month = dec,
  journal = {Numerische Mathematik},
  volume = {1},
  number = {1},
  pages = {269--271},
  issn = {0945-3245},
  doi = {10.1007/BF01386390},
  urldate = {2021-03-17},
  langid = {english}
}

@phdthesis{Dolstra2006PurelyFunctionalSoftware,
  title = {The {{Purely Functional Software Deployment Model}}},
  author = {Dolstra, Eelco},
  year = {2006},
  address = {Utrecht, The Netherlands},
  langid = {english},
  school = {Utrecht University}
}

@inproceedings{Dolstra2008NixOSPurelyFunctional,
  title = {{{NixOS}}: {{A}} Purely Functional {{Linux}} Distribution},
  shorttitle = {{{NixOS}}},
  booktitle = {Proceedings of the 13th {{ACM SIGPLAN}} International Conference on {{Functional}} Programming},
  author = {Dolstra, Eelco and L{\"o}h, Andres},
  year = {2008},
  month = sep,
  series = {{{ICFP}} '08},
  pages = {367--378},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1411204.1411255},
  urldate = {2024-07-19},
  abstract = {Existing package and system configuration management tools suffer from an imperative model, where system administration actions such as upgrading packages or changes to system configuration files are stateful: they destructively update the state of the system. This leads to many problems, such as the inability to roll back changes easily, to run multiple versions of a package side-by-side, to reproduce a configuration deterministically on another machine, or to reliably upgrade a system. In this paper we show that we can overcome these problems by moving to a purely functional system configuration model. This means that all static parts of a system (such as software packages, configuration files and system startup scripts) are built by pure functions and are immutable, stored in a way analogously to a heap in a purely function language. We have implemented this model in NixOS, a non-trivial Linux distribution that uses the Nix package manager to build the entire system configuration from a purely functional specification.},
  isbn = {978-1-59593-919-7}
}

@article{Dolstra2010NixOSPurelyFunctional,
  title = {{{NixOS}}: {{A}} Purely Functional {{Linux}} Distribution},
  shorttitle = {{{NixOS}}},
  author = {Dolstra, Eelco and L{\"o}h, Andres and Pierron, Nicolas},
  year = {2010},
  month = nov,
  journal = {Journal of Functional Programming},
  volume = {20},
  number = {5-6},
  pages = {577--615},
  issn = {1469-7653, 0956-7968},
  doi = {10.1017/S0956796810000195},
  urldate = {2024-07-19},
  abstract = {Existing package and system configuration management tools suffer from an imperative model, where system administration actions such as package upgrades or changes to system configuration files are stateful: they destructively update the state of the system. This leads to many problems, such as the inability to roll back changes easily, to deploy multiple versions of a package side-by-side, to reproduce a configuration deterministically on another machine, or to reliably upgrade a system. In this paper we show that we can overcome these problems by moving to a purely functional system configuration model. This means that all static parts of a system (such as software packages, configuration files and system startup scripts) are built by pure functions and are immutable, stored in a way analogous to a heap in a purely functional language. We have implemented this model in NixOS, a non-trivial Linux distribution that uses the Nix package manager to build the entire system configuration from a modular, purely functional specification.},
  langid = {english}
}

@misc{Dong2024CanLLMBe,
  title = {Can {{LLM}} Be a {{Personalized Judge}}?},
  author = {Dong, Yijiang River and Hu, Tiancheng and Collier, Nigel},
  year = {2024},
  month = jun,
  number = {arXiv:2406.11657},
  eprint = {2406.11657},
  primaryclass = {cs},
  doi = {10.48550/arXiv.2406.11657},
  urldate = {2024-09-23},
  abstract = {Ensuring that large language models (LLMs) reflect diverse user values and preferences is crucial as their user bases expand globally. It is therefore encouraging to see the growing interest in LLM personalization within the research community. However, current works often rely on the LLM-as-a-Judge approach for evaluation without thoroughly examining its validity. In this paper, we investigate the reliability of LLM-as-a-Personalized-Judge, asking LLMs to judge user preferences based on personas. Our findings suggest that directly applying LLM-as-a-Personalized-Judge is less reliable than previously assumed, showing low and inconsistent agreement with human ground truth. The personas typically used are often overly simplistic, resulting in low predictive power. To address these issues, we introduce verbal uncertainty estimation into the LLM-as-a-Personalized-Judge pipeline, allowing the model to express low confidence on uncertain judgments. This adjustment leads to much higher agreement (above 80\%) on high-certainty samples for binary tasks. Through human evaluation, we find that the LLM-as-a-Personalized-Judge achieves comparable performance to third-party humans evaluation and even surpasses human performance on high-certainty samples. Our work indicates that certainty-enhanced LLM-as-a-Personalized-Judge offers a promising direction for developing more reliable and scalable methods for evaluating LLM personalization.},
  archiveprefix = {arXiv}
}

@inproceedings{DosSantos2018ImpactsCodingPractices,
  title = {Impacts of Coding Practices on Readability},
  booktitle = {Proceedings of the 26th {{Conference}} on {{Program Comprehension}}},
  author = {{dos Santos}, Rodrigo Magalh{\~a}es and Gerosa, Marco Aur{\'e}lio},
  year = {2018},
  month = may,
  series = {{{ICPC}} '18},
  pages = {277--285},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3196321.3196342},
  urldate = {2022-05-03},
  abstract = {Several conventions and standards aim to improve maintainability of software code. However, low levels of code readability perceived by developers still represent a barrier to their daily work. In this paper, we describe a survey that assessed the impact of a set of Java coding practices on the readability perceived by software developers. While some practices promoted an enhancement of readability, others did not show statistically significant effects. Interestingly, one of the practices worsened the readability. Our results may help to identify coding conventions with a positive impact on readability and, thus, guide the creation of coding standards.},
  isbn = {978-1-4503-5714-2}
}

@inproceedings{Douglas2017MonkeypuzzleNextGeneration,
  title = {Monkeypuzzle - {{Towards Next Generation}}, {{Free}} \& {{Open-Source}}, {{Argument Analysis Tools}}},
  booktitle = {{{CMNA}}@{{ICAIL}}},
  author = {Douglas, John and Wells, Simon},
  year = {2017},
  abstract = {A new, free, open-source, web-based argument analysis tool called Monkeypuzzle is introduced, designed to provide both a foundation for creating and visualising reproducible argument analyses as well as a flexible framework for investigating new and extending existing argument analysis techniques. We introduce a new, free, open-source, web-based argument analysis tool called Monkeypuzzle. This is designed to provide both a foundation for creating and visualising reproducible argument analyses as well as a flexible framework for investigating new and extending existing argument analysis techniques.}
}

@inproceedings{Du2019ValidationGrowingKnowledge,
  title = {Validation of {{Growing Knowledge Graphs}} by {{Abductive Text Evidences}}},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Du, Jianfeng and Pan, Jeff Z. and Wang, Sylvia and Qi, Kunxun and Shen, Yuming and Deng, Yu},
  year = {2019},
  month = jul,
  volume = {33},
  pages = {2784--2791},
  doi = {10.1609/aaai.v33i01.33012784},
  urldate = {2024-10-31},
  abstract = {This paper proposes a validation mechanism for newly added triples in a growing knowledge graph. Given a logical theory, a knowledge graph, a text corpus, and a new triple to be validated, this mechanism computes a sorted list of explanations for the new triple to facilitate the validation of it, where an explanation, called an abductive text evidence, is a set of pairs of the form (triple, window) where appending the set of triples on the left to the knowledge graph enforces entailment of the new triple under the logical theory, while every sentence window on the right which is contained in the text corpus explains to some degree why the triple on the left is true. From the angle of practice, a special class of abductive text evidences called TEP-based abductive text evidence is proposed, which is constructed from explanation patterns seen before in the knowledge graph. Accordingly, a method for computing the complete set of TEP-based abductive text evidences is proposed. Moreover, a method for sorting abductive text evidences based on distantly supervised learning is proposed. To evaluate the proposed validation mechanism, four knowledge graphs with logical theories are constructed from the four great classical masterpieces of Chinese literature. Experimental results on these datasets demonstrate the efficiency and effectiveness of the proposed mechanism.},
  copyright = {https://www.aaai.org}
}

@article{Dudley2018ReviewUserInterface,
  title = {A {{Review}} of {{User Interface Design}} for {{Interactive Machine Learning}}},
  author = {Dudley, John J. and Kristensson, Per Ola},
  year = {2018},
  month = jun,
  journal = {ACM Transactions on Interactive Intelligent Systems},
  volume = {8},
  number = {2},
  pages = {8:1--8:37},
  issn = {2160-6455},
  doi = {10.1145/3185517},
  urldate = {2022-05-03},
  abstract = {Interactive Machine Learning (IML) seeks to complement human perception and intelligence by tightly integrating these strengths with the computational power and speed of computers. The interactive process is designed to involve input from the user but does not require the background knowledge or experience that might be necessary to work with more traditional machine learning techniques. Under the IML process, non-experts can apply their domain knowledge and insight over otherwise unwieldy datasets to find patterns of interest or develop complex data-driven applications. This process is co-adaptive in nature and relies on careful management of the interaction between human and machine. User interface design is fundamental to the success of this approach, yet there is a lack of consolidated principles on how such an interface should be implemented. This article presents a detailed review and characterisation of Interactive Machine Learning from an interactive systems perspective. We propose and describe a structural and behavioural model of a generalised IML system and identify solution principles for building effective interfaces for IML. Where possible, these emergent solution principles are contextualised by reference to the broader human-computer interaction literature. Finally, we identify strands of user interface research key to unlocking more efficient and productive non-expert interactive machine learning applications.}
}

@inproceedings{Dufour-Lussier2010TextAdaptationUsing,
  title = {Text {{Adaptation Using Formal Concept Analysis}}},
  booktitle = {Case-{{Based Reasoning}}. {{Research}} and {{Development}}},
  author = {{Dufour-Lussier}, Valmi and Lieber, Jean and Nauer, Emmanuel and Toussaint, Yannick},
  editor = {Bichindaritz, Isabelle and Montani, Stefania},
  year = {2010},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {96--110},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-14274-1_9},
  abstract = {This paper addresses the issue of adapting cases represented by plain text with the help of formal concept analysis and natural language processing technologies. The actual cases represent recipes in which we classify ingredients according to culinary techniques applied to them. The complex nature of linguistic anaphoras in recipe texts make usual text mining techniques inefficient so a stronger approach, using syntactic and dynamic semantic analysis to build a formal representation of a recipe, had to be used. This representation is useful for various applications but, in this paper, we show how one can extract ingredient--action relations from it in order to use formal concept analysis and select an appropriate replacement sequence of culinary actions to use in adapting the recipe text.},
  isbn = {978-3-642-14274-1},
  langid = {english}
}

@mastersthesis{Dumani2018ReconstructingVersionHistory,
  title = {Reconstructing the Version History of {{Stack Overflow}} Posts},
  author = {Dumani, Lorik},
  year = {2018},
  month = jan,
  school = {University of Trier}
}

@inproceedings{Dumani2019GoodPremisesRetrieval,
  title = {Good {{Premises Retrieval}} via a {{Two-Stage Argument Retrieval Model}}},
  booktitle = {Proceedings of the 31st {{GI-Workshop Grundlagen}} von {{Datenbanken}}},
  author = {Dumani, Lorik},
  editor = {Schenkel, Ralf},
  year = {2019},
  month = jun,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {2367},
  pages = {3--8},
  publisher = {CEUR},
  address = {Saarburg, Germany},
  issn = {1613-0073},
  urldate = {2024-12-11},
  langid = {english}
}

@inproceedings{Dumani2019SystematicComparisonMethods,
  title = {A {{Systematic Comparison}} of {{Methods}} for {{Finding Good Premises}} for {{Claims}}},
  booktitle = {Proceedings of the 42nd {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Dumani, Lorik and Schenkel, Ralf},
  year = {2019},
  month = jul,
  series = {{{SIGIR}}'19},
  pages = {957--960},
  publisher = {Association for Computing Machinery},
  address = {Paris, France},
  doi = {10.1145/3331184.3331282},
  urldate = {2020-08-22},
  abstract = {Research on computational argumentation has recently become very popular. An argument consists of a claim that is supported or attacked by at least one premise. Its intention is the persuasion of others. An important problem in this field is retrieving good premises for a designated claim from a corpus of arguments. Given a claim, oftentimes existing approaches' first step is finding textually similar claims. In this paper we compare 196 methods systematically for determining similar claims by textual similarity, using a large corpus of (claim, premise) pairs crawled from debate portals. We also evaluate how well textual similarity of claims can predict relevance of the associated premises.},
  isbn = {978-1-4503-6172-9}
}

@inproceedings{Dumani2020FrameworkArgumentRetrieval,
  title = {A {{Framework}} for {{Argument Retrieval}}},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {Dumani, Lorik and Neumann, Patrick J. and Schenkel, Ralf},
  editor = {Jose, Joemon M. and Yilmaz, Emine and Magalh{\~a}es, Jo{\~a}o and Castells, Pablo and Ferro, Nicola and Silva, M{\'a}rio J. and Martins, Fl{\'a}vio},
  year = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {431--445},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-45439-5_29},
  abstract = {Computational argumentation has recently become a fast growing field of research. An argument consists of a claim, such as ``We should abandon fossil fuels'', which is supported or attacked by at least one premise, for example ``Burning fossil fuels is one cause for global warming''. From an information retrieval perspective, an interesting task within this setting is finding the best supporting and attacking premises for a given query claim from a large corpus of arguments. Since the same logical premise can be formulated differently, the system needs to avoid retrieving duplicate results and thus needs to use some form of clustering. In this paper we propose a principled probabilistic ranking framework for premises based on the idea of tf-idf that, given a query claim, first identifies highly similar claims in the corpus, and then clusters and ranks their premises, taking clusters of claims as well as the stances of query and premises into account. We compare our approach to a baseline system that uses BM25F which we outperform even with a primitive implementation of our framework utilising BERT.},
  isbn = {978-3-030-45439-5},
  langid = {english}
}

@inproceedings{Dumani2020QualityAwareRankingArguments,
  title = {Quality-{{Aware Ranking}} of {{Arguments}}},
  booktitle = {Proceedings of the 29th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Dumani, Lorik and Schenkel, Ralf},
  year = {2020},
  month = oct,
  series = {{{CIKM}} '20},
  pages = {335--344},
  publisher = {Association for Computing Machinery},
  address = {Virtual Event, Ireland},
  doi = {10.1145/3340531.3411960},
  urldate = {2020-10-24},
  abstract = {Argument search engines identify, extract, and rank the most important arguments for and against a given controversial topic. A number of such systems have recently been developed, usually focusing on classic information retrieval ranking methods that are based on frequency information. An important aspect that has been ignored so far by search engines is the quality of arguments. We present a quality-aware ranking framework for arguments already extracted from texts and represented as argument graphs, considering multiple established quality measures. An extensive evaluation with a standard benchmark collection demonstrates that taking quality into account significantly helps to improve retrieval quality for argument search. We also publish a dataset in which arguments with respect to topics were tediously annotated by humans with three widely accepted argument quality dimensions.},
  isbn = {978-1-4503-6859-9}
}

@inproceedings{Dumani2020RankingArgumentsCombining,
  title = {Ranking {{Arguments}} by {{Combining Claim Similarity}} and {{Argument Quality Dimensions}}},
  booktitle = {Working {{Notes}} of {{CLEF}} 2020 - {{Conference}} and {{Labs}} of the {{Evaluation Forum}}},
  author = {Dumani, Lorik and Schenkel, Ralf},
  editor = {Cappellato, Linda and Eickhoff, Carsten and Ferro, Nicola and N{\'e}v{\'e}ol, Aur{\'e}lie},
  year = {2020},
  month = sep,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {2696},
  publisher = {CEUR},
  address = {Thessaloniki, Greece},
  issn = {1613-0073},
  urldate = {2024-12-11},
  langid = {english}
}

@inproceedings{Dumani2020SegmentingClusteringNoisy,
  title = {Segmenting and {{Clustering Noisy Arguments}}},
  booktitle = {Proceedings of the {{Conference}} "{{Lernen}}, {{Wissen}}, {{Daten}}, {{Analysen}}"},
  author = {Dumani, Lorik and Kreutz, Christin Katharina and Biertz, Manuel and Witry, Alex and Schenkel, Ralf},
  editor = {Trabold, Daniel and Welke, Pascal and Piatkowski, Nico},
  year = {2020},
  month = sep,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {2738},
  pages = {23--34},
  publisher = {CEUR},
  address = {Online},
  issn = {1613-0073},
  urldate = {2023-11-27},
  abstract = {Automated argument retrieval for queries is desirable, e.g., as it helps in decision making or convincing others of certain actions. An argument consists of a claim supported or attacked by at least one premise. The claim describes a controversial viewpoint that should not be accepted without evidence given by premises. Premises are composed of Elementary Discourse Units (EDUs) which are their smallest contextual components. Oftentimes argument search engines find similar claims to a query first before returning their premises. Due to heterogeneous data sources, premises often appear repeatedly in different syntactic forms. From an information retrieval perspective, it is essential to rank premises relevant for a query claim highly in a duplicate-free manner. The main challenge in clustering them is to avoid redundancies as premises frequently address various aspects, i.e., consist of multiple EDUs. So, two tasks can be defined: segmentation of premises in EDUs and clustering of similar EDUs. In this paper we make two contributions: Our first contribution is the introduction of a noisy dataset with 480 premises for 30 queries crawled from debate portals which serves as a gold standard for the segmentation of premises into EDUs and the clustering of EDUs. Our second contribution consists of first baselines for the two mentioned tasks, for which we evaluated various methods. Our results show that an uncurated dataset is a major challenge and that clustering EDUs is only reasonable with premises as context information.},
  langid = {english}
}

@inproceedings{Dumani2021FineCoarseGranular,
  title = {Fine and {{Coarse Granular Argument Classification}} before {{Clustering}}},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Dumani, Lorik and Wiesenfeldt, Tobias and Schenkel, Ralf},
  year = {2021},
  month = oct,
  series = {{{CIKM}} '21},
  pages = {422--432},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3459637.3482431},
  urldate = {2022-09-26},
  abstract = {Computational argumentation and especially argument mining together with retrieval enjoys increasing popularity. In contrast to standard search engines that focus on finding documents relevant to a query, argument retrieval aims at finding the best supporting and attacking premises given a query claim, e.g., from a predefined collection of arguments. Here, a claim is the central part of an argument representing the standpoint of a speaker with the goal to persuade the audience, and a premise serves as evidence to the claim. In addition to the actual retrieval process, existing work has focused on (1) classifying polarities of arguments into supporting or opposing, (2) classifying arguments by their frames (such as economic or environmental), and (3) clustering similar arguments by their meaning to avoid repetitions in the result list. For experiments, either hand-made argument collections or arguments extracted from debate portals were used. In this paper, we extend existing work on argument clustering, making the following contributions: First, we introduce a novel pipeline for clustering arguments. While previous work classified arguments either by polarity, frame, or meaning, our pipeline incorporates these three, allowing a more systematic presentation of arguments. Second, we introduce a new dataset consisting of 365 argument graphs accompanying more than 11,000 high-quality arguments that, contrary to previous datasets, have been generated, displayed, and verified by journalists and were published in newspapers. A thorough evaluation with this dataset provides a first baseline for future work.},
  isbn = {978-1-4503-8446-9}
}

@inproceedings{Dumani2021ReCAPCorpusCorpus,
  title = {The {{ReCAP Corpus}}: {{A Corpus}} of {{Complex Argument Graphs}} on {{German Education Politics}}},
  shorttitle = {The {{ReCAP Corpus}}},
  booktitle = {{{IEEE Proceedings}} of the 15th {{International Conference}} on {{Semantic Computing}} ({{ICSC}})},
  author = {Dumani, Lorik and Biertz, Manuel and Witry, Alex and Ludwig, Anna-Katharina and Lenz, Mirko and Ollinger, Stefan and Bergmann, Ralph and Schenkel, Ralf},
  year = {2021},
  month = jan,
  pages = {248--255},
  publisher = {IEEE},
  address = {Laguna Hills, CA, USA},
  issn = {2325-6516},
  doi = {10.1109/ICSC50631.2021.00083},
  abstract = {The automatic extraction of arguments from natural language texts is a highly researched area and more important than ever today, as it is nearly impossible to manually capture all arguments on a controversial topic in a reasonable amount of time. For testing different algorithms such as the retrieval of the best arguments, which are still in their infancy, gold standards must exist. An argument consists of a claim or standpoint that is supported or opposed by at least one premise. The generic term for a claim or premise is Argumentative Discourse Unit (ADU). The relationships between ADUs can be specified by argument schemes and can lead to large graphs. This paper presents a corpus of 100 argument graphs with about 2,500 ADUs in German, which is unique in its size and the utilisation of argument schemes. The corpus is built from natural language texts like party press releases and parliamentary motions on education policies in the German federal states. Each high-quality text is presented by an argument graph and created by the use of a modified version of the annotation tool OVA. The final argument graphs resulted by merging two previously independently annotated graphs based on detailed discussions.},
  langid = {english}
}

@article{Dung1995AcceptabilityArgumentsIts,
  title = {On the Acceptability of Arguments and Its Fundamental Role in Nonmonotonic Reasoning, Logic Programming and n-Person Games},
  author = {Dung, Phan Minh},
  year = {1995},
  month = sep,
  journal = {Artificial Intelligence},
  volume = {77},
  number = {2},
  pages = {321--357},
  issn = {0004-3702},
  doi = {10.1016/0004-3702(94)00041-X},
  urldate = {2020-07-23},
  abstract = {The purpose of this paper is to study the fundamental mechanism, humans use in argumentation, and to explore ways to implement this mechanism on computers. We do so by first developing a theory for argumentation whose central notion is the acceptability of arguments. Then we argue for the ``correctness'' or ``appropriateness'' of our theory with two strong arguments. The first one shows that most of the major approaches to nonmonotonic reasoning in AI and logic programming are special forms of our theory of argumentation. The second argument illustrates how our theory can be used to investigate the logical structure of many practical problems. This argument is based on a result showing that our theory captures naturally the solutions of the theory of n-person games and of the well-known stable marriage problem. By showing that argumentation can be viewed as a special form of logic programming with negation as failure, we introduce a general logic-programming-based method for generating meta-interpreters for argumentation systems, a method very much similar to the compiler-compiler idea in conventional programming.},
  langid = {english}
}

@inproceedings{Dusmanu2017ArgumentMiningTwitter,
  title = {Argument {{Mining}} on {{Twitter}}: {{Arguments}}, {{Facts}} and {{Sources}}},
  shorttitle = {Argument {{Mining}} on {{Twitter}}},
  booktitle = {Proceedings of the 2017 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Dusmanu, Mihai and Cabrio, Elena and Villata, Serena},
  year = {2017},
  month = sep,
  pages = {2317--2322},
  publisher = {Association for Computational Linguistics},
  address = {Copenhagen, Denmark},
  doi = {10.18653/v1/D17-1245},
  urldate = {2023-10-20},
  abstract = {Social media collect and spread on the Web personal opinions, facts, fake news and all kind of information users may be interested in. Applying argument mining methods to such heterogeneous data sources is a challenging open research issue, in particular considering the peculiarities of the language used to write textual messages on social media. In addition, new issues emerge when dealing with arguments posted on such platforms, such as the need to make a distinction between personal opinions and actual facts, and to detect the source disseminating information about such facts to allow for provenance verification. In this paper, we apply supervised classification to identify arguments on Twitter, and we present two new tasks for argument mining, namely facts recognition and source identification. We study the feasibility of the approaches proposed to address these tasks on a set of tweets related to the Grexit and Brexit news topics.}
}

@article{Duthie2020NavigatingArgumentsHypotheses,
  title = {Navigating {{Arguments}} and {{Hypotheses}} at {{Scale}}},
  author = {Duthie, Rory and Lawrence, John and Reed, Chris and Visser, Jacky and Zografistou, Dimitra},
  year = {2020},
  journal = {Computational Models of Argument},
  pages = {459--460},
  publisher = {IOS Press},
  doi = {10.3233/FAIA200533},
  urldate = {2022-04-21}
}

@article{Dykes2020ReconstructingArgumentsNoisy,
  title = {Reconstructing {{Arguments}} from {{Noisy Text}}},
  author = {Dykes, Natalie and Evert, Stefan and G{\"o}ttlinger, Merlin and Heinrich, Philipp and Schr{\"o}der, Lutz},
  year = {2020},
  month = jul,
  journal = {Datenbank-Spektrum},
  volume = {20},
  number = {2},
  pages = {123--129},
  issn = {1610-1995},
  doi = {10.1007/s13222-020-00342-y},
  urldate = {2023-07-26},
  abstract = {Social media are of paramount importance to public discourse. RANT aims to contribute methods and formalisms for extracting, representing, and processing arguments from noisy text found in social media discussions, using a~large corpus of pre-referendum Brexit tweets as a~running case study. We identify recurring linguistic argumentation patterns in a~corpus-linguistic analysis and formulate corresponding corpus queries to extract arguments automatically. Given the huge amount of social media data available, our approach aims at high precision at the possible price of low recall. Argumentation patterns are directly associated with logical patterns in a~dedicated formalism and accordingly, individual arguments are directly parsed as logical formulae. The logical formalism for argument representation features a~broad range of modalities capturing real-life modes of expression. We cast this formalism as a~family of instance logics in the generic framework of coalgebraic logic and complement it by a~flexible framework to represent relationships between arguments; including standard relations like attack and support but also relations extracted from metadata. Some relations are inferred from the logical content of individual arguments. We are in the process of developing suitable generalizations of various extension semantics for argumentation frameworks combined with corresponding algorithmic methods to allow for the automated retrieval of large-scale argumentative positions.},
  langid = {english}
}

@inproceedings{Dykes2024FindingArgumentFragments,
  title = {Finding {{Argument Fragments}} on~{{Social Media}} with~{{Corpus Queries}} and~{{LLMs}}},
  booktitle = {Robust {{Argumentation Machines}}},
  author = {Dykes, Nathan and Evert, Stephanie and Heinrich, Philipp and Humml, Merlin and Schr{\"o}der, Lutz},
  editor = {Cimiano, Philipp and Frank, Anette and Kohlhase, Michael and Stein, Benno},
  year = {2024},
  pages = {163--181},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63536-6_10},
  abstract = {We are concerned with extracting argumentative fragments from social media, exemplified with a case study on a large corpus of English tweets about the UK Brexit referendum in 2016. Our overall approach is to parse the corpus using dedicated corpus queries that fill designated slots in predefined logical patterns. We present an inventory of logical patterns and corresponding queries, which have been carefully designed and refined. While a gold standard of substantial size is difficult to obtain by manual annotation, our queries can retrieve hundreds of thousands of examples with high precision. We show how queries can be combined to extract complex nested statements relevant to argumentation. We also show how to proceed for applications needing higher recall: high-precision query matches can be used as training data for an LLM classifier, and the trade-off between precision and recall can be freely adjusted with its cutoff threshold.},
  isbn = {978-3-031-63536-6},
  langid = {english}
}

@inproceedings{Eckle-Kohler2015RoleDiscourseMarkers,
  title = {On the {{Role}} of {{Discourse Markers}} for {{Discriminating Claims}} and {{Premises}} in {{Argumentative Discourse}}},
  booktitle = {Proceedings of the 2015 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {{Eckle-Kohler}, Judith and Kluge, Roland and Gurevych, Iryna},
  year = {2015},
  month = sep,
  pages = {2249--2255},
  publisher = {Association for Computational Linguistics},
  address = {Lisbon, Portugal},
  doi = {10.18653/v1/D15-1267},
  urldate = {2018-09-01}
}

@inproceedings{Eden2023WelcomeRealWorld,
  title = {Welcome to the {{Real World}}: {{Efficient}}, {{Incremental}} and {{Scalable Key Point Analysis}}},
  shorttitle = {Welcome to the {{Real World}}},
  booktitle = {Proceedings of the 2023 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}: {{Industry Track}}},
  author = {Eden, Lilach and Kantor, Yoav and Orbach, Matan and Katz, Yoav and Slonim, Noam and {Bar-Haim}, Roy},
  editor = {Wang, Mingxuan and Zitouni, Imed},
  year = {2023},
  month = dec,
  pages = {483--491},
  publisher = {Association for Computational Linguistics},
  address = {Singapore},
  doi = {10.18653/v1/2023.emnlp-industry.46},
  urldate = {2024-04-09},
  abstract = {Key Point Analysis (KPA) is an emerging summarization framework, which extracts the main points from a collection of opinions, and quantifies their prevalence. It has been successfully applied to diverse types of data, including arguments, user reviews and survey responses. Despite the growing academic interest in KPA, little attention has been given to the practical challenges of implementing a KPA system in production. This work presents a deployed KPA system, which regularly serves multiple teams in our organization. We discuss the main challenges we faced while building a real-world KPA system, as well as the architecture and algorithmic improvements we developed to address these challenges. Specifically, we focus on efficient matching of sentences to key points, incremental processing, scalability and resiliency. The value of our contributions is demonstrated in an extensive set of experiments, over five existing and novel datasets. Finally, we describe several use cases of the deployed system, which illustrate its practical value.}
}

@inproceedings{Eger2018CrosslingualArgumentationMining,
  title = {Cross-Lingual {{Argumentation Mining}}: {{Machine Translation}} (and a Bit of {{Projection}}) Is {{All You Need}}!},
  shorttitle = {Cross-Lingual {{Argumentation Mining}}},
  booktitle = {Proceedings of the 27th {{International Conference}} on {{Computational Linguistics}}},
  author = {Eger, Steffen and Daxenberger, Johannes and Stab, Christian and Gurevych, Iryna},
  year = {2018},
  month = aug,
  pages = {831--844},
  publisher = {Association for Computational Linguistics},
  address = {Santa Fe, New Mexico, USA},
  urldate = {2020-03-31},
  abstract = {Argumentation mining (AM) requires the identification of complex discourse structures and has lately been applied with success monolingually. In this work, we show that the existing resources are, however, not adequate for assessing cross-lingual AM, due to their heterogeneity or lack of complexity. We therefore create suitable parallel corpora by (human and machine) translating a popular AM dataset consisting of persuasive student essays into German, French, Spanish, and Chinese. We then compare (i) annotation projection and (ii) bilingual word embeddings based direct transfer strategies for cross-lingual AM, finding that the former performs considerably better and almost eliminates the loss from cross-lingual transfer. Moreover, we find that annotation projection works equally well when using either costly human or cheap machine translations. Our code and data are available at http://github.com/UKPLab/coling2018-xling\_argument\_mining.}
}

@inproceedings{Eisenstadt2024AutocompletionArchitecturalSpatial,
  title = {Autocompletion of {{Architectural Spatial Configurations Using Case-Based Reasoning}}, {{Graph Clustering}}, and {{Deep Learning}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Eisenstadt, Viktor and Langenhan, Christoph and Bielski, Jessica and Bergmann, Ralph and Althoff, Klaus-Dieter},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {321--337},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_21},
  abstract = {This paper presents an approach for autocompletion of architectural building designs in the form of graph-based floor plans during the early design phase. We utilize established case-based reasoning methods, such as subgraph matching and transformational adaptation, further we employ supervised and unsupervised machine learning techniques, such as graph clustering and graph neural networks. Combining those methods into a single approach, the goal is to predict possibly missing spaces in architectural designs of housing buildings, supporting the acceleration of the early design process of architects to make it more sustainable, while enriching it with the recent developments of artificial intelligence. The approach was validated by a performance evaluation and a user study with participation of representatives of the architecture domain.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@book{Eisenstein2019IntroductionNaturalLanguage,
  title = {Introduction to {{Natural Language Processing}}},
  author = {Eisenstein, Jacob},
  year = {2019},
  month = oct,
  publisher = {MIT Press},
  abstract = {A survey of computational methods for understanding, generating, and manipulating human language, which offers a synthesis of classical representations and algorithms with contemporary machine learning techniques.This textbook provides a technical perspective on natural language processing---methods for building computer software that understands, generates, and manipulates human language. It emphasizes contemporary data-driven approaches, focusing on techniques from supervised and unsupervised machine learning. The first section establishes a foundation in machine learning by building a set of tools that will be used throughout the book and applying them to word-based textual analysis. The second section introduces structured representations of language, including sequences, trees, and graphs. The third section explores different approaches to the representation and analysis of linguistic meaning, ranging from formal logic to neural word embeddings. The final section offers chapter-length treatments of three transformative applications of natural language processing: information extraction, machine translation, and text generation. End-of-chapter exercises include both paper-and-pencil analysis and software implementation.The text synthesizes and distills a broad and diverse research literature, linking contemporary machine learning techniques with the field's linguistic and computational foundations. It is suitable for use in advanced undergraduate and graduate-level courses and as a reference for software engineers and data scientists. Readers should have a background in computer programming and college-level mathematics. After mastering the material presented, students will have the technical skill to build and analyze novel natural language processing systems and to understand the latest research in the field.},
  googlebooks = {72yuDwAAQBAJ},
  isbn = {978-0-262-04284-0},
  langid = {english}
}

@book{Euzenat2013OntologyMatching,
  title = {Ontology {{Matching}}},
  author = {Euzenat, J{\'e}r{\^o}me and Shvaiko, Pavel},
  year = {2013},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-38721-0},
  urldate = {2019-01-05},
  isbn = {978-3-642-38720-3 978-3-642-38721-0},
  langid = {english}
}

@misc{Explosion2021FactsFigures,
  title = {Facts \& {{Figures}}},
  author = {{Explosion}},
  year = {2021},
  journal = {spaCy Documentation},
  urldate = {2021-02-09},
  howpublished = {https://spacy.io/usage/facts-figures\#benchmarks-speed}
}

@inproceedings{Fabbri2021ConvoSummConversationSummarization,
  title = {{{ConvoSumm}}: {{Conversation Summarization Benchmark}} and {{Improved Abstractive Summarization}} with {{Argument Mining}}},
  shorttitle = {{{ConvoSumm}}},
  booktitle = {Proceedings of the 59th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 11th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  author = {Fabbri, Alexander and Rahman, Faiaz and Rizvi, Imad and Wang, Borui and Li, Haoran and Mehdad, Yashar and Radev, Dragomir},
  year = {2021},
  month = aug,
  pages = {6866--6880},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  doi = {10.18653/v1/2021.acl-long.535},
  urldate = {2023-10-11},
  abstract = {While online conversations can cover a vast amount of information in many different formats, abstractive text summarization has primarily focused on modeling solely news articles. This research gap is due, in part, to the lack of standardized datasets for summarizing online discussions. To address this gap, we design annotation protocols motivated by an issues--viewpoints--assertions framework to crowdsource four new datasets on diverse online conversation forms of news comments, discussion forums, community question answering forums, and email threads. We benchmark state-of-the-art models on our datasets and analyze characteristics associated with the data. To create a comprehensive benchmark, we also evaluate these models on widely-used conversation summarization datasets to establish strong baselines in this domain. Furthermore, we incorporate argument mining through graph construction to directly model the issues, viewpoints, and assertions present in a conversation and filter noisy input, showing comparable or improved results according to automatic and human evaluations.}
}

@article{Farquhar2024DetectingHallucinationsLarge,
  title = {Detecting Hallucinations in Large Language Models Using Semantic Entropy},
  author = {Farquhar, Sebastian and Kossen, Jannik and Kuhn, Lorenz and Gal, Yarin},
  year = {2024},
  month = jun,
  journal = {Nature},
  volume = {630},
  number = {8017},
  pages = {625--630},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-024-07421-0},
  urldate = {2024-06-24},
  abstract = {Large language model (LLM) systems, such as ChatGPT1 or Gemini2, can show impressive reasoning and question-answering capabilities but often `hallucinate' false outputs and unsubstantiated answers3,4. Answering unreliably or without the necessary information prevents adoption in diverse fields, with problems including fabrication of legal precedents5 or untrue facts in news articles6 and even posing a risk to human life in medical domains such as radiology7. Encouraging truthfulness through supervision or reinforcement has~been only partially successful8. Researchers need a general method for detecting hallucinations in LLMs that works even with new and unseen questions to which humans might not know the answer. Here we develop new methods grounded in statistics, proposing entropy-based uncertainty estimators for LLMs to detect a subset of hallucinations---confabulations---which are arbitrary and incorrect generations. Our method addresses the fact that one idea can be expressed in many ways by computing uncertainty at the level of meaning rather than specific sequences of words. Our method works across datasets and tasks without a priori knowledge of the task, requires no task-specific data and robustly generalizes to new tasks not seen before. By detecting when a prompt is likely to produce a confabulation, our method helps users understand when they must take extra care with LLMs and opens up new possibilities for using LLMs that are otherwise prevented by their unreliability.},
  copyright = {2024 The Author(s)},
  langid = {english}
}

@inproceedings{Feely2025UsingPseudoCases,
  title = {Using {{Pseudo Cases}} and~{{Stratified Case-Based Reasoning}} to~{{Generate}} and~{{Evaluate Training Adjustments}} for~{{Marathon Runners}}},
  booktitle = {Artificial {{Intelligence XLI}}},
  author = {Feely, Ciara and Caulfield, Brian and Lawlor, Aonghus and Smyth, Barry},
  editor = {Bramer, Max and Stahl, Frederic},
  year = {2025},
  pages = {88--101},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-77918-3_7},
  abstract = {Recommender systems have become a regular feature in our daily lives. They influence the books we read, the movies we watch and the content we consume on social media. There is opportunity to apply recommender systems to more complex domains, such as exercise, and in this paper we consider how such systems can play a role in supporting runners as they train for a marathon. However, making recommendations for more complex domains introduces additional challenges such as how to provide varied recommendations and how to evaluate these suggestions. In this work we address both of these issues using a stratified case-based recommendation approach and the use of so-called pseudo-cases for evaluation. The stratified approach allows for different recommendations to be generated for each runner based on whether they would like to continue along their current training trajectory, or target a more ambitious or a more conservative goal. We further describe how to evaluate these recommendations in terms of their feasibility, plausibility, effectiveness and safety using a large-scale, real-world dataset of more than 130,000 runners and their marathon training experiences.},
  isbn = {978-3-031-77918-3},
  langid = {english}
}

@inproceedings{Feger2020StructureContentAssessing,
  title = {Structure or {{Content}}? {{Towards Assessing Argument Relevance}}},
  booktitle = {Proceedings of the 8th {{International Conference}} on {{Computational Models}} of {{Argument}}},
  author = {Feger, Marc and Steinmann, Jan and Meter, Christian},
  editor = {Prakken, Henry and Bistarelli, Stefano and Santini, Francesco and Taticchi, Carlo},
  year = {2020},
  series = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  volume = {326},
  pages = {203--214},
  publisher = {IOS Press},
  address = {Perugia, Italy},
  doi = {10.3233/FAIA200505},
  abstract = {In this paper, we provide a detailed analysis of PageRank to determine the relevance of arguments along with content- and knowledge-based methods from the field of natural language processing. We do not only show how the cross-linking of arguments is only slightly involved in the recognition of relevance, we rather show how basic common knowledge and reader-involving methods outperform the purely structure-related PageRank. The methods we propose are based on the latest research and correlate strongly with human awareness regarding the relevance of arguments. Altogether, we show that PageRank does not fully capture the relevance of arguments and must be extended by a contextual level in order to take concepts of natural language into account at the web level, as they are unavoidably involved in argumentation.}
}

@book{Fellbaum1998WordNetElectronicLexical,
  title = {{{WordNet}}: {{An Electronic Lexical Database}}},
  shorttitle = {{{WordNet}}},
  editor = {Fellbaum, Christiane},
  year = {1998},
  publisher = {The MIT Press},
  doi = {10.7551/mitpress/7287.001.0001},
  urldate = {2021-02-12},
  isbn = {978-0-262-27255-1},
  langid = {english}
}

@inproceedings{Ferrara2017UnsupervisedDetectionArgumentative,
  title = {Unsupervised {{Detection}} of {{Argumentative Units}} Though {{Topic Modeling Techniques}}},
  booktitle = {Proceedings of the 4th {{Workshop}} on {{Argument Mining}}},
  author = {Ferrara, Alfio and Montanelli, Stefano and Petasis, Georgios},
  year = {2017},
  month = sep,
  pages = {97--107},
  publisher = {Association for Computational Linguistics},
  address = {Copenhagen, Denmark},
  doi = {10.18653/v1/W17-5113},
  urldate = {2020-10-21},
  abstract = {In this paper we present a new unsupervised approach, ``Attraction to Topics'' -- A2T , for the detection of argumentative units, a sub-task of argument mining. Motivated by the importance of topic identification in manual annotation, we examine whether topic modeling can be used for performing unsupervised detection of argumentative sentences, and to what extend topic modeling can be used to classify sentences as claims and premises. Preliminary evaluation results suggest that topic information can be successfully used for the detection of argumentative sentences, at least for corpora used for evaluation. Our approach has been evaluated on two English corpora, the first of which contains 90 persuasive essays, while the second is a collection of 340 documents from user generated content.}
}

@article{Ferraz2013OntologyAssociationRules,
  title = {Ontology in Association Rules},
  author = {Ferraz, Inha{\'u}ma Neves and Garcia, Ana Cristina Bicharra},
  year = {2013},
  month = sep,
  journal = {SpringerPlus},
  volume = {2},
  issn = {2193-1801},
  doi = {10.1186/2193-1801-2-452},
  urldate = {2019-10-19},
  abstract = {Data mining has emerged to address the problem of transforming data into useful knowledge. Although most data mining techniques, such as the use of association rules, may substantially reduce the search effort over large data sets, often, the consequential outcomes surpass the amount of information humanly manageable. On the other hand, important association rules may be overlooked owing to the setting of the support threshold, which is a very subjective metric, but rooted in most data mining techniques. This paper presents a study on the effects, in terms of precision and recall, of using a data preparation technique, called SemPrune, which is built on domain ontology. SemPrune is intended for pre- and post-processing phases of data mining. Identifying generalization/specialization relations, as well as composition/decomposition relations, is the key to successfully applying SemPrune.},
  pmcid = {PMC3786067},
  pmid = {24083103}
}

@article{Ferreira2016JointlyLearningEmbed,
  title = {Jointly {{Learning}} to {{Embed}} and {{Predict}} with {{Multiple Languages}}.},
  author = {Ferreira, Daniel C and Martins, Andr{\'e} F T and Almeida, Mariana S C},
  year = {2016},
  month = jan,
  journal = {ACL}
}

@phdthesis{Figueroa2022FineCoarseGranular,
  title = {Fine and {{Coarse Granular Argument Identification}} and {{Classification}} in {{Persuasive Essays}}},
  author = {Figueroa, Arturo and Pednekar, Ashwin and Mehyar, Bilal},
  year = {2022},
  month = apr,
  address = {Trier, Germany},
  abstract = {Argumentation is necessary for humans to communicate thoughts in order to establish a standpoint. Argument Mining is a recent research field in NLP that addresses the task of the automatic identification and extraction of Argumentative Discourse Units (ADUs) from unstructured natural language text. This research focuses on investigating different methods of segmenting text at varying levels of granularity for ADU Identification and Classification in persuasive essays. Two different measures of assessing the quality of unit segmentation are introduced. We investigate three different classification approaches with five types of classifiers. The findings show that the sub-clause level segmentation achieves a better segmentation quality than the sentence level segmentation which is often used in previous research, and performs relatively well in classification.},
  langid = {english},
  school = {Trier University}
}

@inproceedings{Findlater2004ComparisonStaticAdaptive,
  title = {A Comparison of Static, Adaptive, and Adaptable Menus},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Findlater, Leah and McGrenere, Joanna},
  year = {2004},
  month = apr,
  series = {{{CHI}} '04},
  pages = {89--96},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/985692.985704},
  urldate = {2022-05-02},
  abstract = {Software applications continue to grow in terms of the number of features they offer, making personalization increasingly important. Research has shown that most users prefer the control afforded by an adaptable approach to personalization rather than a system-controlled adaptive approach. No study, however, has compared the efficiency of the two approaches. In a controlled lab study with 27 subjects we compared the measured and perceived efficiency of three menu conditions: static, adaptable and adaptive. Each was implemented as a split menu, in which the top four items remained static, were adaptable by the subject, or adapted according to the subject's frequently and recently used items. The static menu was found to be significantly faster than the adaptive menu, and the adaptable menu was found to be significantly faster than the adaptive menu under certain conditions. The majority of users preferred the adaptable menu overall. Implications for interface design are discussed.},
  isbn = {978-1-58113-702-6}
}

@article{Fleiss1973EquivalenceWeightedKappa,
  title = {The {{Equivalence}} of {{Weighted Kappa}} and the {{Intraclass Correlation Coefficient}} as {{Measures}} of {{Reliability}}},
  author = {Fleiss, Joseph L. and Cohen, Jacob},
  year = {1973},
  month = oct,
  journal = {Educational and Psychological Measurement},
  volume = {33},
  number = {3},
  pages = {613--619},
  publisher = {SAGE Publications Inc},
  issn = {0013-1644},
  doi = {10.1177/001316447303300309},
  urldate = {2021-03-07},
  langid = {english}
}

@article{Forbus1995MACFACModel,
  title = {{{MAC}}/{{FAC}} - {{A Model}} of {{Similarity-Based Retrieval}}.},
  author = {Forbus, Kenneth D and Gentner, Dedre and Law, Keith},
  year = {1995},
  month = jan,
  journal = {Cognitive Science},
  volume = {19},
  number = {2},
  pages = {141--205},
  doi = {10.1207/s15516709cog1902_1},
  urldate = {2018-09-01}
}

@article{Forbus2017AnalogyRelationalRepresentations,
  title = {Analogy and {{Relational Representations}} in the {{Companion Cognitive Architecture}}},
  author = {Forbus, Kenneth D. and Hinrich, Thomas},
  year = {2017},
  month = dec,
  journal = {AI Magazine},
  volume = {38},
  number = {4},
  pages = {34--42},
  issn = {2371-9621},
  doi = {10.1609/aimag.v38i4.2743},
  urldate = {2020-05-31},
  abstract = {The Companion cognitive architecture is aimed at reaching human-level AI by creating software social organisms, systems that interact with people using natural modalities, working and learning over extended periods of time as collaborators rather than tools. Our two central hypotheses about how to achieve this are (1) analogical reasoning and learning are central to cognition, and (2) qualitative representations provide a level of description that facilitates reasoning, learning, and communication. This paper discusses the evidence we have gathered supporting these hypotheses from our experiments with the Companion architecture. Although we are far from our ultimate goals, these experiments provide strong breadth for the utility of analogy and QR across a range of tasks. We also discuss three lessons learned and highlight three important open problems for cognitive systems research more broadly.},
  copyright = {Copyright (c) 2017 AI Magazine},
  langid = {english}
}

@article{Fox1989StopListGeneral,
  title = {A {{Stop List}} for {{General Text}}},
  author = {Fox, Christopher},
  year = {1989},
  month = sep,
  journal = {SIGIR Forum},
  volume = {24},
  number = {1-2},
  pages = {19--21},
  issn = {0163-5840},
  doi = {10.1145/378881.378888},
  abstract = {A stop list, or negative dictionary is a device used in automatic indexing to filter out words that would make poor index terms. Traditionally stop lists are supposed to have included only the most frequently occurring words. In practice, however, stop lists have tended to include infrequently occurring words, and have not included many frequently occurring words. Infrequently occurring words seem to have been included because stop list compilers have not, for whatever reason, consulted empirical studies of word frequencies. Frequently occurring words seem to have been left out for the same reason, and also because many of them might still be important as index terms.This paper reports an exercise in generating a stop list for general text based on the Brown corpus of 1,014,000 words drawn from a broad range of literature in English. We start with a list of tokens occurring more than 300 times in the Brown corpus. From this list of 278 words, 32 are culled on the grounds that they are too important as potential index terms. Twenty-six words are then added to the list in the belief that they may occur very frequently in certain kinds of literature. Finally, 149 words are added to the list because the finite state machine based filter in which this list is intended to be used is able to filter them at almost no cost. The final product is a list of 421 stop words that should be maximally efficient and effective in filtering the most frequently occurring and semantically neutral words in general literature in English.}
}

@article{Franz2016CytoscapeJsGraph,
  title = {Cytoscape.Js: A Graph Theory Library for Visualisation and Analysis},
  shorttitle = {Cytoscape.Js},
  author = {Franz, Max and Lopes, Christian T. and Huck, Gerardo and Dong, Yue and Sumer, Onur and Bader, Gary D.},
  year = {2016},
  month = jan,
  journal = {Bioinformatics},
  volume = {32},
  number = {2},
  pages = {309--311},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btv557},
  urldate = {2022-04-21},
  abstract = {Summary: Cytoscape.js is an open-source JavaScript-based graph library. Its most common use case is as a visualization software component, so it can be used to render interactive graphs in a web browser. It also can be used in a headless manner, useful for graph operations on a server, such as Node.js. Availability and implementation: Cytoscape.js is implemented in JavaScript. Documentation, downloads and source code are available at http://js.cytoscape.org . Contact:gary.bader@utoronto.ca}
}

@inproceedings{Frobe2023ContinuousIntegrationReproducible,
  title = {Continuous {{Integration}} for~{{Reproducible Shared Tasks}} with~{{TIRA}}.Io},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {Fr{\"o}be, Maik and Wiegmann, Matti and Kolyada, Nikolay and Grahm, Bastian and Elstner, Theresa and Loebe, Frank and Hagen, Matthias and Stein, Benno and Potthast, Martin},
  editor = {Kamps, Jaap and Goeuriot, Lorraine and Crestani, Fabio and Maistro, Maria and Joho, Hideo and Davis, Brian and Gurrin, Cathal and Kruschwitz, Udo and Caputo, Annalina},
  year = {2023},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {236--241},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-28241-6_20},
  abstract = {A major obstacle to the long-term impact of most shared tasks is their lack of reproducibility. Often only the test collections and the papers of the organizers and participants are published. Third parties who want to independently evaluate the state of the art for a task on other data must re-implement the participants' software. The tools developed to collect software from participants in shared tasks only partially verify its reliability at the time of submission, much less long-term, and do not enable third parties to reuse it later. We have overhauled the TIRA~Integrated Research Architecture to address all of these issues. The new version simplifies task setup for organizers and software submission for participants, scales from a local computer to the cloud, supports on-demand resource allocation up to parallel CPU and GPU processing, and enables export for local reproduction with just a few lines of code. This is achieved by implementing the TIRA protocol with an industry-standard continuous integration and deployment~(CI/CD) pipeline using Git, Docker, and Kubernetes.},
  isbn = {978-3-031-28241-6},
  langid = {english}
}

@inproceedings{Fromm2019TACAMTopicContext,
  title = {{{TACAM}}: {{Topic And Context Aware Argument Mining}}},
  shorttitle = {{{TACAM}}},
  booktitle = {{{IEEE}}/{{WIC}}/{{ACM International Conference}} on {{Web Intelligence}}},
  author = {Fromm, Michael and Faerman, Evgeniy and Seidl, Thomas},
  year = {2019},
  month = oct,
  series = {{{WI}} '19},
  pages = {99--106},
  publisher = {Association for Computing Machinery},
  address = {Thessaloniki, Greece},
  doi = {10.1145/3350546.3352506},
  urldate = {2020-09-02},
  abstract = {In this work we address the problem of argument search. The purpose of argument search is the distillation of pro and contra arguments for requested topics from large text corpora. In previous works, the usual approach is to use a standard search engine to extract text parts which are relevant to the given topic and subsequently use an argument recognition algorithm to select arguments from them. The main challenge in the argument recognition task, which is also known as argument mining, is that often sentences containing arguments are structurally similar to purely informative sentences without any stance about the topic. In fact, they only differ semantically. Most approaches use topic or search term information only for the first search step and therefore assume that arguments can be classified independently of a topic. We argue that topic information is crucial for argument mining, since the topic defines the semantic context of an argument. Precisely, we propose different models for the classification of arguments, which take information about a topic of an argument into account. Moreover, to enrich the context of a topic and to let models understand the context of the potential argument better, we integrate information from different external sources such as Knowledge Graphs or pre-trained NLP models. Our evaluation shows that considering topic information, especially in connection with external information, provides a significant performance boost for the argument mining task.},
  isbn = {978-1-4503-6934-3}
}

@misc{Fu2023DecoderOnlyEncoderDecoderInterpreting,
  title = {Decoder-{{Only}} or {{Encoder-Decoder}}? {{Interpreting Language Model}} as a {{Regularized Encoder-Decoder}}},
  shorttitle = {Decoder-{{Only}} or {{Encoder-Decoder}}?},
  author = {Fu, Zihao and Lam, Wai and Yu, Qian and So, Anthony Man-Cho and Hu, Shengding and Liu, Zhiyuan and Collier, Nigel},
  year = {2023},
  month = apr,
  number = {arXiv:2304.04052},
  eprint = {2304.04052},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.04052},
  urldate = {2024-04-29},
  abstract = {The sequence-to-sequence (seq2seq) task aims at generating the target sequence based on the given input source sequence. Traditionally, most of the seq2seq task is resolved by the Encoder-Decoder framework which requires an encoder to encode the source sequence and a decoder to generate the target text. Recently, a bunch of new approaches have emerged that apply decoder-only language models directly to the seq2seq task. Despite the significant advancements in applying language models to the seq2seq task, there is still a lack of thorough analysis on the effectiveness of the decoder-only language model architecture. This paper aims to address this gap by conducting a detailed comparison between the encoder-decoder architecture and the decoder-only language model framework through the analysis of a regularized encoder-decoder structure. This structure is designed to replicate all behaviors in the classical decoder-only language model but has an encoder and a decoder making it easier to be compared with the classical encoder-decoder structure. Based on the analysis, we unveil the attention degeneration problem in the language model, namely, as the generation step number grows, less and less attention is focused on the source sequence. To give a quantitative understanding of this problem, we conduct a theoretical sensitivity analysis of the attention output with respect to the source input. Grounded on our analysis, we propose a novel partial attention language model to solve the attention degeneration problem. Experimental results on machine translation, summarization, and data-to-text generation tasks support our analysis and demonstrate the effectiveness of our proposed model.},
  archiveprefix = {arXiv}
}

@misc{Fu2024FeatUpModelAgnosticFramework,
  title = {{{FeatUp}}: {{A Model-Agnostic Framework}} for {{Features}} at {{Any Resolution}}},
  shorttitle = {{{FeatUp}}},
  author = {Fu, Stephanie and Hamilton, Mark and Brandt, Laura and Feldman, Axel and Zhang, Zhoutong and Freeman, William T.},
  year = {2024},
  month = mar,
  number = {arXiv:2403.10516},
  eprint = {2403.10516},
  primaryclass = {cs},
  urldate = {2024-03-28},
  abstract = {Deep features are a cornerstone of computer vision research, capturing image semantics and enabling the community to solve downstream tasks even in the zero- or few-shot regime. However, these features often lack the spatial resolution to directly perform dense prediction tasks like segmentation and depth prediction because models aggressively pool information over large areas. In this work, we introduce FeatUp, a task- and model-agnostic framework to restore lost spatial information in deep features. We introduce two variants of FeatUp: one that guides features with high-resolution signal in a single forward pass, and one that fits an implicit model to a single image to reconstruct features at any resolution. Both approaches use a multi-view consistency loss with deep analogies to NeRFs. Our features retain their original semantics and can be swapped into existing applications to yield resolution and performance gains even without re-training. We show that FeatUp significantly outperforms other feature upsampling and image super-resolution approaches in class activation map generation, transfer learning for segmentation and depth prediction, and end-to-end training for semantic segmentation.},
  archiveprefix = {arXiv}
}

@book{Ganter1999FormalConceptAnalysis,
  title = {Formal {{Concept Analysis}}: {{Mathematical Foundations}}},
  shorttitle = {Formal {{Concept Analysis}}},
  author = {Ganter, Bernhard and Wille, Rudolf},
  year = {1999},
  publisher = {Springer-Verlag},
  address = {Berlin Heidelberg},
  doi = {10.1007/978-3-642-59830-2},
  urldate = {2020-05-29},
  abstract = {This is the first textbook on formal concept analysis. It gives a systematic presentation of the mathematical foundations and their relations to applications in computer science, especially in data analysis and knowledge processing. Above all, it presents graphical methods for representing conceptual systems that have proved themselves in communicating knowledge. Theory and graphical representation are thus closely coupled together. The mathematical foundations are treated thoroughly and illuminated by means of numerous examples. Since computers are being used ever more widely for knowledge processing, formal methods for conceptual analysis are gaining in importance. This book makes the basic theory for such methods accessible in a compact form.},
  isbn = {978-3-540-62771-5},
  langid = {english}
}

@misc{Gao2024RetrievalAugmentedGenerationLarge,
  title = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}: {{A Survey}}},
  shorttitle = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}},
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Wang, Haofen},
  year = {2024},
  month = mar,
  number = {arXiv:2312.10997},
  eprint = {2312.10997},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.10997},
  urldate = {2024-04-01},
  abstract = {Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.},
  archiveprefix = {arXiv}
}

@misc{Gao2024RetrievalAugmentedGenerationLargea,
  title = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}: {{A Survey}}},
  shorttitle = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}},
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Wang, Haofen},
  year = {2024},
  month = mar,
  number = {arXiv:2312.10997},
  eprint = {2312.10997},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.10997},
  urldate = {2024-09-30},
  abstract = {Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.},
  archiveprefix = {arXiv}
}

@inproceedings{Garcia2009IndexBalancedAccuracy,
  title = {Index of {{Balanced Accuracy}}: {{A Performance Measure}} for {{Skewed Class Distributions}}},
  shorttitle = {Index of {{Balanced Accuracy}}},
  booktitle = {Pattern {{Recognition}} and {{Image Analysis}}},
  author = {Garc{\'i}a, V. and Mollineda, R. A. and S{\'a}nchez, J. S.},
  year = {2009},
  month = jun,
  pages = {441--448},
  publisher = {Springer, Berlin, Heidelberg},
  doi = {10.1007/978-3-642-02172-5_57},
  urldate = {2021-03-13},
  abstract = {This paper introduces a new metric, named Index of Balanced Accuracy, for evaluating learning processes in two-class imbalanced domains. The method combines an unbiased index of its overall accuracy...},
  langid = {english}
}

@inproceedings{Gemechu2019DecompositionalArgumentMining,
  title = {Decompositional {{Argument Mining}}: {{A General Purpose Approach}} for {{Argument Graph Construction}}},
  shorttitle = {Decompositional {{Argument Mining}}},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Gemechu, Debela and Reed, Chris},
  year = {2019},
  month = jul,
  pages = {516--526},
  publisher = {Association for Computational Linguistics},
  address = {Florence, Italy},
  doi = {10.18653/v1/P19-1049},
  urldate = {2020-09-02},
  abstract = {This work presents an approach decomposing propositions into four functional components and identify the patterns linking those components to determine argument structure. The entities addressed by a proposition are target concepts and the features selected to make a point about the target concepts are aspects. A line of reasoning is followed by providing evidence for the points made about the target concepts via aspects. Opinions on target concepts and opinions on aspects are used to support or attack the ideas expressed by target concepts and aspects. The relations between aspects, target concepts, opinions on target concepts and aspects are used to infer the argument relations. Propositions are connected iteratively to form a graph structure. The approach is generic in that it is not tuned for a specific corpus and evaluated on three different corpora from the literature: AAEC, AMT, US2016G1tv and achieved an F score of 0.79, 0.77 and 0.64, respectively.}
}

@misc{GeminiTeam2024GeminiFamilyHighly,
  title = {Gemini: {{A Family}} of {{Highly Capable Multimodal Models}}},
  shorttitle = {Gemini},
  author = {Gemini Team and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M. and Hauth, Anja and Millican, Katie and Silver, David and Johnson, Melvin and Antonoglou, Ioannis and Schrittwieser, Julian and Glaese, Amelia and Chen, Jilin and Pitler, Emily and Lillicrap, Timothy and Lazaridou, Angeliki and Firat, Orhan and Molloy, James and Isard, Michael and Barham, Paul R. and Hennigan, Tom and Lee, Benjamin and Viola, Fabio and Reynolds, Malcolm and Xu, Yuanzhong and Doherty, Ryan and Collins, Eli and Meyer, Clemens and Rutherford, Eliza and Moreira, Erica and Ayoub, Kareem and Goel, Megha and Krawczyk, Jack and Du, Cosmo and Chi, Ed and Cheng, Heng-Tze and Ni, Eric and Shah, Purvi and Kane, Patrick and Chan, Betty and Faruqui, Manaal and Severyn, Aliaksei and Lin, Hanzhao and Li, YaGuang and Cheng, Yong and Ittycheriah, Abe and Mahdieh, Mahdis and Chen, Mia and Sun, Pei and Tran, Dustin and Bagri, Sumit and Lakshminarayanan, Balaji and Liu, Jeremiah and Orban, Andras and G{\"u}ra, Fabian and Zhou, Hao and Song, Xinying and Boffy, Aurelien and Ganapathy, Harish and Zheng, Steven and Choe, HyunJeong and Weisz, {\'A}goston and Zhu, Tao and Lu, Yifeng and Gopal, Siddharth and Kahn, Jarrod and Kula, Maciej and Pitman, Jeff and Shah, Rushin and Taropa, Emanuel and Merey, Majd Al and Baeuml, Martin and Chen, Zhifeng and Shafey, Laurent El and Zhang, Yujing and Sercinoglu, Olcan and Tucker, George and Piqueras, Enrique and Krikun, Maxim and Barr, Iain and Savinov, Nikolay and Danihelka, Ivo and Roelofs, Becca and White, Ana{\"i}s and Andreassen, Anders and {von Glehn}, Tamara and Yagati, Lakshman and Kazemi, Mehran and Gonzalez, Lucas and Khalman, Misha and Sygnowski, Jakub and Frechette, Alexandre and Smith, Charlotte and Culp, Laura and Proleev, Lev and Luan, Yi and Chen, Xi and Lottes, James and Schucher, Nathan and Lebron, Federico and Rrustemi, Alban and Clay, Natalie and Crone, Phil and Kocisky, Tomas and Zhao, Jeffrey and Perz, Bartek and Yu, Dian and Howard, Heidi and Bloniarz, Adam and Rae, Jack W. and Lu, Han and Sifre, Laurent and Maggioni, Marcello and Alcober, Fred and Garrette, Dan and Barnes, Megan and Thakoor, Shantanu and Austin, Jacob and {Barth-Maron}, Gabriel and Wong, William and Joshi, Rishabh and Chaabouni, Rahma and Fatiha, Deeni and Ahuja, Arun and Tomar, Gaurav Singh and Senter, Evan and Chadwick, Martin and Kornakov, Ilya and Attaluri, Nithya and Iturrate, I{\~n}aki and Liu, Ruibo and Li, Yunxuan and Cogan, Sarah and Chen, Jeremy and Jia, Chao and Gu, Chenjie and Zhang, Qiao and Grimstad, Jordan and Hartman, Ale Jakse and Garcia, Xavier and Pillai, Thanumalayan Sankaranarayana and Devlin, Jacob and Laskin, Michael and Casas, Diego de Las and Valter, Dasha and Tao, Connie and Blanco, Lorenzo and Badia, Adri{\`a} Puigdom{\`e}nech and Reitter, David and Chen, Mianna and Brennan, Jenny and Rivera, Clara and Brin, Sergey and Iqbal, Shariq and Surita, Gabriela and Labanowski, Jane and Rao, Abhi and Winkler, Stephanie and Parisotto, Emilio and Gu, Yiming and Olszewska, Kate and Addanki, Ravi and Miech, Antoine and Louis, Annie and Teplyashin, Denis and Brown, Geoff and Catt, Elliot and Balaguer, Jan and Xiang, Jackie and Wang, Pidong and Ashwood, Zoe and Briukhov, Anton and Webson, Albert and Ganapathy, Sanjay and Sanghavi, Smit and Kannan, Ajay and Chang, Ming-Wei and Stjerngren, Axel and Djolonga, Josip and Sun, Yuting and Bapna, Ankur and Aitchison, Matthew and Pejman, Pedram and Michalewski, Henryk and Yu, Tianhe and Wang, Cindy and Love, Juliette and Ahn, Junwhan and Bloxwich, Dawn and Han, Kehang and Humphreys, Peter and Sellam, Thibault and Bradbury, James and Godbole, Varun and Samangooei, Sina and Damoc, Bogdan and Kaskasoli, Alex and Arnold, S{\'e}bastien M. R. and Vasudevan, Vijay and Agrawal, Shubham and Riesa, Jason and Lepikhin, Dmitry and Tanburn, Richard and Srinivasan, Srivatsan and Lim, Hyeontaek and Hodkinson, Sarah and Shyam, Pranav and Ferret, Johan and Hand, Steven and Garg, Ankush and Paine, Tom Le and Li, Jian and Li, Yujia and Giang, Minh and Neitz, Alexander and Abbas, Zaheer and York, Sarah and Reid, Machel and Cole, Elizabeth and Chowdhery, Aakanksha and Das, Dipanjan and Rogozi{\'n}ska, Dominika and Nikolaev, Vitaliy and Sprechmann, Pablo and Nado, Zachary and Zilka, Lukas and Prost, Flavien and He, Luheng and Monteiro, Marianne and Mishra, Gaurav and Welty, Chris and Newlan, Josh and Jia, Dawei and Allamanis, Miltiadis and Hu, Clara Huiyi and {de Liedekerke}, Raoul and Gilmer, Justin and Saroufim, Carl and Rijhwani, Shruti and Hou, Shaobo and Shrivastava, Disha and Baddepudi, Anirudh and Goldin, Alex and Ozturel, Adnan and Cassirer, Albin and Xu, Yunhan and Sohn, Daniel and Sachan, Devendra and Amplayo, Reinald Kim and Swanson, Craig and Petrova, Dessie and Narayan, Shashi and Guez, Arthur and Brahma, Siddhartha and Landon, Jessica and Patel, Miteyan and Zhao, Ruizhe and Villela, Kevin and Wang, Luyu and Jia, Wenhao and Rahtz, Matthew and Gim{\'e}nez, Mai and Yeung, Legg and Keeling, James and Georgiev, Petko and Mincu, Diana and Wu, Boxi and Haykal, Salem and Saputro, Rachel and Vodrahalli, Kiran and Qin, James and Cankara, Zeynep and Sharma, Abhanshu and Fernando, Nick and Hawkins, Will and Neyshabur, Behnam and Kim, Solomon and Hutter, Adrian and Agrawal, Priyanka and {Castro-Ros}, Alex and van den Driessche, George and Wang, Tao and Yang, Fan and Chang, Shuo-yiin and Komarek, Paul and McIlroy, Ross and Lu{\v c}i{\'c}, Mario and Zhang, Guodong and Farhan, Wael and Sharman, Michael and Natsev, Paul and Michel, Paul and Bansal, Yamini and Qiao, Siyuan and Cao, Kris and Shakeri, Siamak and Butterfield, Christina and Chung, Justin and Rubenstein, Paul Kishan and Agrawal, Shivani and Mensch, Arthur and Soparkar, Kedar and Lenc, Karel and Chung, Timothy and Pope, Aedan and Maggiore, Loren and Kay, Jackie and Jhakra, Priya and Wang, Shibo and Maynez, Joshua and Phuong, Mary and Tobin, Taylor and Tacchetti, Andrea and Trebacz, Maja and Robinson, Kevin and Katariya, Yash and Riedel, Sebastian and Bailey, Paige and Xiao, Kefan and Ghelani, Nimesh and Aroyo, Lora and Slone, Ambrose and Houlsby, Neil and Xiong, Xuehan and Yang, Zhen and Gribovskaya, Elena and Adler, Jonas and Wirth, Mateo and Lee, Lisa and Li, Music and Kagohara, Thais and Pavagadhi, Jay and Bridgers, Sophie and Bortsova, Anna and Ghemawat, Sanjay and Ahmed, Zafarali and Liu, Tianqi and Powell, Richard and Bolina, Vijay and Iinuma, Mariko and Zablotskaia, Polina and Besley, James and Chung, Da-Woon and Dozat, Timothy and Comanescu, Ramona and Si, Xiance and Greer, Jeremy and Su, Guolong and Polacek, Martin and Kaufman, Rapha{\"e}l Lopez and Tokumine, Simon and Hu, Hexiang and Buchatskaya, Elena and Miao, Yingjie and Elhawaty, Mohamed and Siddhant, Aditya and Tomasev, Nenad and Xing, Jinwei and Greer, Christina and Miller, Helen and Ashraf, Shereen and Roy, Aurko and Zhang, Zizhao and Ma, Ada and Filos, Angelos and Besta, Milos and Blevins, Rory and Klimenko, Ted and Yeh, Chih-Kuan and Changpinyo, Soravit and Mu, Jiaqi and Chang, Oscar and Pajarskas, Mantas and Muir, Carrie and Cohen, Vered and Lan, Charline Le and Haridasan, Krishna and Marathe, Amit and Hansen, Steven and Douglas, Sholto and Samuel, Rajkumar and Wang, Mingqiu and Austin, Sophia and Lan, Chang and Jiang, Jiepu and Chiu, Justin and Lorenzo, Jaime Alonso and Sj{\"o}sund, Lars Lowe and Cevey, S{\'e}bastien and Gleicher, Zach and Avrahami, Thi and Boral, Anudhyan and Srinivasan, Hansa and Selo, Vittorio and May, Rhys and Aisopos, Konstantinos and Hussenot, L{\'e}onard and Soares, Livio Baldini and Baumli, Kate and Chang, Michael B. and Recasens, Adri{\`a} and Caine, Ben and Pritzel, Alexander and Pavetic, Filip and Pardo, Fabio and Gergely, Anita and Frye, Justin and Ramasesh, Vinay and Horgan, Dan and Badola, Kartikeya and Kassner, Nora and Roy, Subhrajit and Dyer, Ethan and Campos, V{\'i}ctor Campos and Tomala, Alex and Tang, Yunhao and Badawy, Dalia El and White, Elspeth and Mustafa, Basil and Lang, Oran and Jindal, Abhishek and Vikram, Sharad and Gong, Zhitao and Caelles, Sergi and Hemsley, Ross and Thornton, Gregory and Feng, Fangxiaoyu and Stokowiec, Wojciech and Zheng, Ce and Thacker, Phoebe and {\"U}nl{\"u}, {\c C}a{\u g}lar and Zhang, Zhishuai and Saleh, Mohammad and Svensson, James and Bileschi, Max and Patil, Piyush and Anand, Ankesh and Ring, Roman and Tsihlas, Katerina and Vezer, Arpi and Selvi, Marco and Shevlane, Toby and Rodriguez, Mikel and Kwiatkowski, Tom and Daruki, Samira and Rong, Keran and Dafoe, Allan and FitzGerald, Nicholas and {Gu-Lemberg}, Keren and Khan, Mina and Hendricks, Lisa Anne and Pellat, Marie and Feinberg, Vladimir and {Cobon-Kerr}, James and Sainath, Tara and Rauh, Maribeth and Hashemi, Sayed Hadi and Ives, Richard and Hasson, Yana and Noland, Eric and Cao, Yuan and Byrd, Nathan and Hou, Le and Wang, Qingze and Sottiaux, Thibault and Paganini, Michela and Lespiau, Jean-Baptiste and Moufarek, Alexandre and Hassan, Samer and Shivakumar, Kaushik and {van Amersfoort}, Joost and Mandhane, Amol and Joshi, Pratik and Goyal, Anirudh and Tung, Matthew and Brock, Andrew and Sheahan, Hannah and Misra, Vedant and Li, Cheng and Raki{\'c}evi{\'c}, Nemanja and Dehghani, Mostafa and Liu, Fangyu and Mittal, Sid and Oh, Junhyuk and Noury, Seb and Sezener, Eren and Huot, Fantine and Lamm, Matthew and De Cao, Nicola and Chen, Charlie and Mudgal, Sidharth and Stella, Romina and Brooks, Kevin and Vasudevan, Gautam and Liu, Chenxi and Chain, Mainak and Melinkeri, Nivedita and Cohen, Aaron and Wang, Venus and Seymore, Kristie and Zubkov, Sergey and Goel, Rahul and Yue, Summer and Krishnakumaran, Sai and Albert, Brian and Hurley, Nate and Sano, Motoki and Mohananey, Anhad and Joughin, Jonah and Filonov, Egor and K{\k e}pa, Tomasz and Eldawy, Yomna and Lim, Jiawern and Rishi, Rahul and Badiezadegan, Shirin and Bos, Taylor and Chang, Jerry and Jain, Sanil and Padmanabhan, Sri Gayatri Sundara and Puttagunta, Subha and Krishna, Kalpesh and Baker, Leslie and Kalb, Norbert and Bedapudi, Vamsi and Kurzrok, Adam and Lei, Shuntong and Yu, Anthony and Litvin, Oren and Zhou, Xiang and Wu, Zhichun and Sobell, Sam and Siciliano, Andrea and Papir, Alan and Neale, Robby and Bragagnolo, Jonas and Toor, Tej and Chen, Tina and Anklin, Valentin and Wang, Feiran and Feng, Richie and Gholami, Milad and Ling, Kevin and Liu, Lijuan and Walter, Jules and Moghaddam, Hamid and Kishore, Arun and Adamek, Jakub and Mercado, Tyler and Mallinson, Jonathan and Wandekar, Siddhinita and Cagle, Stephen and Ofek, Eran and Garrido, Guillermo and Lombriser, Clemens and Mukha, Maksim and Sun, Botu and Mohammad, Hafeezul Rahman and Matak, Josip and Qian, Yadi and Peswani, Vikas and Janus, Pawel and Yuan, Quan and Schelin, Leif and David, Oana and Garg, Ankur and He, Yifan and Duzhyi, Oleksii and {\"A}lgmyr, Anton and Lottaz, Timoth{\'e}e and Li, Qi and Yadav, Vikas and Xu, Luyao and Chinien, Alex and Shivanna, Rakesh and Chuklin, Aleksandr and Li, Josie and Spadine, Carrie and Wolfe, Travis and Mohamed, Kareem and Das, Subhabrata and Dai, Zihang and He, Kyle and {von Dincklage}, Daniel and Upadhyay, Shyam and Maurya, Akanksha and Chi, Luyan and Krause, Sebastian and Salama, Khalid and Rabinovitch, Pam G. and M, Pavan Kumar Reddy and Selvan, Aarush and Dektiarev, Mikhail and Ghiasi, Golnaz and Guven, Erdem and Gupta, Himanshu and Liu, Boyi and Sharma, Deepak and Shtacher, Idan Heimlich and Paul, Shachi and Akerlund, Oscar and Aubet, Fran{\c c}ois-Xavier and Huang, Terry and Zhu, Chen and Zhu, Eric and Teixeira, Elico and Fritze, Matthew and Bertolini, Francesco and Marinescu, Liana-Eleonora and B{\"o}lle, Martin and Paulus, Dominik and Gupta, Khyatti and Latkar, Tejasi and Chang, Max and Sanders, Jason and Wilson, Roopa and Wu, Xuewei and Tan, Yi-Xuan and Thiet, Lam Nguyen and Doshi, Tulsee and Lall, Sid and Mishra, Swaroop and Chen, Wanming and Luong, Thang and Benjamin, Seth and Lee, Jasmine and Andrejczuk, Ewa and Rabiej, Dominik and Ranjan, Vipul and Styrc, Krzysztof and Yin, Pengcheng and Simon, Jon and Harriott, Malcolm Rose and Bansal, Mudit and Robsky, Alexei and Bacon, Geoff and Greene, David and Mirylenka, Daniil and Zhou, Chen and Sarvana, Obaid and Goyal, Abhimanyu and Andermatt, Samuel and Siegler, Patrick and Horn, Ben and Israel, Assaf and Pongetti, Francesco and Chen, Chih-Wei "Louis" and Selvatici, Marco and Silva, Pedro and Wang, Kathie and Tolins, Jackson and Guu, Kelvin and Yogev, Roey and Cai, Xiaochen and Agostini, Alessandro and Shah, Maulik and Nguyen, Hung and Donnaile, Noah {\'O} and Pereira, S{\'e}bastien and Friso, Linda and Stambler, Adam and Kurzrok, Adam and Kuang, Chenkai and Romanikhin, Yan and Geller, Mark and Yan, Z. J. and Jang, Kane and Lee, Cheng-Chun and Fica, Wojciech and Malmi, Eric and Tan, Qijun and Banica, Dan and Balle, Daniel and Pham, Ryan and Huang, Yanping and Avram, Diana and Shi, Hongzhi and Singh, Jasjot and Hidey, Chris and Ahuja, Niharika and Saxena, Pranab and Dooley, Dan and Potharaju, Srividya Pranavi and O'Neill, Eileen and Gokulchandran, Anand and Foley, Ryan and Zhao, Kai and Dusenberry, Mike and Liu, Yuan and Mehta, Pulkit and Kotikalapudi, Ragha and {Safranek-Shrader}, Chalence and Goodman, Andrew and Kessinger, Joshua and Globen, Eran and Kolhar, Prateek and Gorgolewski, Chris and Ibrahim, Ali and Song, Yang and Eichenbaum, Ali and Brovelli, Thomas and Potluri, Sahitya and Lahoti, Preethi and Baetu, Cip and Ghorbani, Ali and Chen, Charles and Crawford, Andy and Pal, Shalini and Sridhar, Mukund and Gurita, Petru and Mujika, Asier and Petrovski, Igor and Cedoz, Pierre-Louis and Li, Chenmei and Chen, Shiyuan and Santo, Niccol{\`o} Dal and Goyal, Siddharth and Punjabi, Jitesh and Kappaganthu, Karthik and Kwak, Chester and LV, Pallavi and Velury, Sarmishta and Choudhury, Himadri and Hall, Jamie and Shah, Premal and Figueira, Ricardo and Thomas, Matt and Lu, Minjie and Zhou, Ting and Kumar, Chintu and Jurdi, Thomas and Chikkerur, Sharat and Ma, Yenai and Yu, Adams and Kwak, Soo and {\"A}hdel, Victor and Rajayogam, Sujeevan and Choma, Travis and Liu, Fei and Barua, Aditya and Ji, Colin and Park, Ji Ho and Hellendoorn, Vincent and Bailey, Alex and Bilal, Taylan and Zhou, Huanjie and Khatir, Mehrdad and Sutton, Charles and Rzadkowski, Wojciech and Macintosh, Fiona and Shagin, Konstantin and Medina, Paul and Liang, Chen and Zhou, Jinjing and Shah, Pararth and Bi, Yingying and Dankovics, Attila and Banga, Shipra and Lehmann, Sabine and Bredesen, Marissa and Lin, Zifan and Hoffmann, John Eric and Lai, Jonathan and Chung, Raynald and Yang, Kai and Balani, Nihal and Bra{\v z}inskas, Arthur and Sozanschi, Andrei and Hayes, Matthew and Alcalde, H{\'e}ctor Fern{\'a}ndez and Makarov, Peter and Chen, Will and Stella, Antonio and Snijders, Liselotte and Mandl, Michael and K{\"a}rrman, Ante and Nowak, Pawe{\l} and Wu, Xinyi and Dyck, Alex and Vaidyanathan, Krishnan and R, Raghavender and Mallet, Jessica and Rudominer, Mitch and Johnston, Eric and Mittal, Sushil and Udathu, Akhil and Christensen, Janara and Verma, Vishal and Irving, Zach and Santucci, Andreas and Elsayed, Gamaleldin and Davoodi, Elnaz and Georgiev, Marin and Tenney, Ian and Hua, Nan and Cideron, Geoffrey and Leurent, Edouard and Alnahlawi, Mahmoud and Georgescu, Ionut and Wei, Nan and Zheng, Ivy and Scandinaro, Dylan and Jiang, Heinrich and Snoek, Jasper and Sundararajan, Mukund and Wang, Xuezhi and Ontiveros, Zack and Karo, Itay and Cole, Jeremy and Rajashekhar, Vinu and Tumeh, Lara and {Ben-David}, Eyal and Jain, Rishub and Uesato, Jonathan and Datta, Romina and Bunyan, Oskar and Wu, Shimu and Zhang, John and Stanczyk, Piotr and Zhang, Ye and Steiner, David and Naskar, Subhajit and Azzam, Michael and Johnson, Matthew and Paszke, Adam and Chiu, Chung-Cheng and Elias, Jaume Sanchez and Mohiuddin, Afroz and Muhammad, Faizan and Miao, Jin and Lee, Andrew and Vieillard, Nino and Park, Jane and Zhang, Jiageng and Stanway, Jeff and Garmon, Drew and Karmarkar, Abhijit and Dong, Zhe and Lee, Jong and Kumar, Aviral and Zhou, Luowei and Evens, Jonathan and Isaac, William and Irving, Geoffrey and Loper, Edward and Fink, Michael and Arkatkar, Isha and Chen, Nanxin and Shafran, Izhak and Petrychenko, Ivan and Chen, Zhe and Jia, Johnson and Levskaya, Anselm and Zhu, Zhenkai and Grabowski, Peter and Mao, Yu and Magni, Alberto and Yao, Kaisheng and Snaider, Javier and Casagrande, Norman and Palmer, Evan and Suganthan, Paul and Casta{\~n}o, Alfonso and Giannoumis, Irene and Kim, Wooyeol and Rybi{\'n}ski, Miko{\l}aj and Sreevatsa, Ashwin and Prendki, Jennifer and Soergel, David and Goedeckemeyer, Adrian and Gierke, Willi and Jafari, Mohsen and Gaba, Meenu and Wiesner, Jeremy and Wright, Diana Gage and Wei, Yawen and Vashisht, Harsha and Kulizhskaya, Yana and Hoover, Jay and Le, Maigo and Li, Lu and Iwuanyanwu, Chimezie and Liu, Lu and Ramirez, Kevin and Khorlin, Andrey and Cui, Albert and LIN, Tian and Wu, Marcus and Aguilar, Ricardo and Pallo, Keith and Chakladar, Abhishek and Perng, Ginger and Abellan, Elena Allica and Zhang, Mingyang and Dasgupta, Ishita and Kushman, Nate and Penchev, Ivo and Repina, Alena and Wu, Xihui and {van der Weide}, Tom and Ponnapalli, Priya and Kaplan, Caroline and Simsa, Jiri and Li, Shuangfeng and Dousse, Olivier and Yang, Fan and Piper, Jeff and Ie, Nathan and Pasumarthi, Rama and Lintz, Nathan and Vijayakumar, Anitha and Andor, Daniel and Valenzuela, Pedro and Lui, Minnie and Paduraru, Cosmin and Peng, Daiyi and Lee, Katherine and Zhang, Shuyuan and Greene, Somer and Nguyen, Duc Dung and Kurylowicz, Paula and Hardin, Cassidy and Dixon, Lucas and Janzer, Lili and Choo, Kiam and Feng, Ziqiang and Zhang, Biao and Singhal, Achintya and Du, Dayou and McKinnon, Dan and Antropova, Natasha and Bolukbasi, Tolga and Keller, Orgad and Reid, David and Finchelstein, Daniel and Raad, Maria Abi and Crocker, Remi and Hawkins, Peter and Dadashi, Robert and Gaffney, Colin and Franko, Ken and Bulanova, Anna and Leblond, R{\'e}mi and Chung, Shirley and Askham, Harry and Cobo, Luis C. and Xu, Kelvin and Fischer, Felix and Xu, Jun and Sorokin, Christina and Alberti, Chris and Lin, Chu-Cheng and Evans, Colin and Dimitriev, Alek and Forbes, Hannah and Banarse, Dylan and Tung, Zora and Omernick, Mark and Bishop, Colton and Sterneck, Rachel and Jain, Rohan and Xia, Jiawei and Amid, Ehsan and Piccinno, Francesco and Wang, Xingyu and Banzal, Praseem and Mankowitz, Daniel J. and Polozov, Alex and Krakovna, Victoria and Brown, Sasha and Bateni, MohammadHossein and Duan, Dennis and Firoiu, Vlad and Thotakuri, Meghana and Natan, Tom and Geist, Matthieu and tan Girgin, Ser and Li, Hui and Ye, Jiayu and Roval, Ofir and Tojo, Reiko and Kwong, Michael and {Lee-Thorp}, James and Yew, Christopher and Sinopalnikov, Danila and Ramos, Sabela and Mellor, John and Sharma, Abhishek and Wu, Kathy and Miller, David and Sonnerat, Nicolas and Vnukov, Denis and Greig, Rory and Beattie, Jennifer and Caveness, Emily and Bai, Libin and Eisenschlos, Julian and Korchemniy, Alex and Tsai, Tomy and Jasarevic, Mimi and Kong, Weize and Dao, Phuong and Zheng, Zeyu and Liu, Frederick and Yang, Fan and Zhu, Rui and Teh, Tian Huey and Sanmiya, Jason and Gladchenko, Evgeny and Trdin, Nejc and Toyama, Daniel and Rosen, Evan and Tavakkol, Sasan and Xue, Linting and Elkind, Chen and Woodman, Oliver and Carpenter, John and Papamakarios, George and Kemp, Rupert and Kafle, Sushant and Grunina, Tanya and Sinha, Rishika and Talbert, Alice and Wu, Diane and {Owusu-Afriyie}, Denese and Du, Cosmo and Thornton, Chloe and {Pont-Tuset}, Jordi and Narayana, Pradyumna and Li, Jing and Fatehi, Saaber and Wieting, John and Ajmeri, Omar and Uria, Benigno and Ko, Yeongil and Knight, Laura and H{\'e}liou, Am{\'e}lie and Niu, Ning and Gu, Shane and Pang, Chenxi and Li, Yeqing and Levine, Nir and Stolovich, Ariel and {Santamaria-Fernandez}, Rebeca and Goenka, Sonam and Yustalim, Wenny and Strudel, Robin and Elqursh, Ali and Deck, Charlie and Lee, Hyo and Li, Zonglin and Levin, Kyle and Hoffmann, Raphael and {Holtmann-Rice}, Dan and Bachem, Olivier and Arora, Sho and Koh, Christy and Yeganeh, Soheil Hassas and P{\~o}der, Siim and Tariq, Mukarram and Sun, Yanhua and Ionita, Lucian and Seyedhosseini, Mojtaba and Tafti, Pouya and Liu, Zhiyu and Gulati, Anmol and Liu, Jasmine and Ye, Xinyu and Chrzaszcz, Bart and Wang, Lily and Sethi, Nikhil and Li, Tianrun and Brown, Ben and Singh, Shreya and Fan, Wei and Parisi, Aaron and Stanton, Joe and Koverkathu, Vinod and {Choquette-Choo}, Christopher A. and Li, Yunjie and Lu, T. J. and Ittycheriah, Abe and Shroff, Prakash and Varadarajan, Mani and Bahargam, Sanaz and Willoughby, Rob and Gaddy, David and Desjardins, Guillaume and Cornero, Marco and Robenek, Brona and Mittal, Bhavishya and Albrecht, Ben and Shenoy, Ashish and Moiseev, Fedor and Jacobsson, Henrik and Ghaffarkhah, Alireza and Rivi{\`e}re, Morgane and Walton, Alanna and Crepy, Cl{\'e}ment and Parrish, Alicia and Zhou, Zongwei and Farabet, Clement and Radebaugh, Carey and Srinivasan, Praveen and {van der Salm}, Claudia and Fidjeland, Andreas and Scellato, Salvatore and {Latorre-Chimoto}, Eri and {Klimczak-Pluci{\'n}ska}, Hanna and Bridson, David and {de Cesare}, Dario and Hudson, Tom and Mendolicchio, Piermaria and Walker, Lexi and Morris, Alex and Mauger, Matthew and Guseynov, Alexey and Reid, Alison and Odoom, Seth and Loher, Lucia and Cotruta, Victor and Yenugula, Madhavi and Grewe, Dominik and Petrushkina, Anastasia and Duerig, Tom and Sanchez, Antonio and Yadlowsky, Steve and Shen, Amy and Globerson, Amir and Webb, Lynette and Dua, Sahil and Li, Dong and Bhupatiraju, Surya and Hurt, Dan and Qureshi, Haroon and Agarwal, Ananth and Shani, Tomer and Eyal, Matan and Khare, Anuj and Belle, Shreyas Rammohan and Wang, Lei and Tekur, Chetan and Kale, Mihir Sanjay and Wei, Jinliang and Sang, Ruoxin and Saeta, Brennan and Liechty, Tyler and Sun, Yi and Zhao, Yao and Lee, Stephan and Nayak, Pandu and Fritz, Doug and Vuyyuru, Manish Reddy and Aslanides, John and Vyas, Nidhi and Wicke, Martin and Ma, Xiao and Eltyshev, Evgenii and Martin, Nina and Cate, Hardie and Manyika, James and Amiri, Keyvan and Kim, Yelin and Xiong, Xi and Kang, Kai and Luisier, Florian and Tripuraneni, Nilesh and Madras, David and Guo, Mandy and Waters, Austin and Wang, Oliver and Ainslie, Joshua and Baldridge, Jason and Zhang, Han and Pruthi, Garima and Bauer, Jakob and Yang, Feng and Mansour, Riham and Gelman, Jason and Xu, Yang and Polovets, George and Liu, Ji and Cai, Honglong and Chen, Warren and Sheng, XiangHai and Xue, Emily and Ozair, Sherjil and Angermueller, Christof and Li, Xiaowei and Sinha, Anoop and Wang, Weiren and Wiesinger, Julia and Koukoumidis, Emmanouil and Tian, Yuan and Iyer, Anand and Gurumurthy, Madhu and Goldenson, Mark and Shah, Parashar and Blake, M. K. and Yu, Hongkun and Urbanowicz, Anthony and Palomaki, Jennimaria and Fernando, Chrisantha and Durden, Ken and Mehta, Harsh and Momchev, Nikola and Rahimtoroghi, Elahe and Georgaki, Maria and Raul, Amit and Ruder, Sebastian and Redshaw, Morgan and Lee, Jinhyuk and Zhou, Denny and Jalan, Komal and Li, Dinghua and Hechtman, Blake and Schuh, Parker and Nasr, Milad and Milan, Kieran and Mikulik, Vladimir and Franco, Juliana and Green, Tim and Nguyen, Nam and Kelley, Joe and Mahendru, Aroma and Hu, Andrea and Howland, Joshua and Vargas, Ben and Hui, Jeffrey and Bansal, Kshitij and Rao, Vikram and Ghiya, Rakesh and Wang, Emma and Ye, Ke and Sarr, Jean Michel and Preston, Melanie Moranski and Elish, Madeleine and Li, Steve and Kaku, Aakash and Gupta, Jigar and Pasupat, Ice and Juan, Da-Cheng and Someswar, Milan and M., Tejvi and Chen, Xinyun and Amini, Aida and Fabrikant, Alex and Chu, Eric and Dong, Xuanyi and Muthal, Amruta and Buthpitiya, Senaka and Jauhari, Sarthak and Hua, Nan and Khandelwal, Urvashi and Hitron, Ayal and Ren, Jie and Rinaldi, Larissa and Drath, Shahar and Dabush, Avigail and Jiang, Nan-Jiang and Godhia, Harshal and Sachs, Uli and Chen, Anthony and Fan, Yicheng and Taitelbaum, Hagai and Noga, Hila and Dai, Zhuyun and Wang, James and Liang, Chen and Hamer, Jenny and Ferng, Chun-Sung and Elkind, Chenel and Atias, Aviel and Lee, Paulina and List{\'i}k, V{\'i}t and Carlen, Mathias and {van de Kerkhof}, Jan and Pikus, Marcin and Zaher, Krunoslav and M{\"u}ller, Paul and Zykova, Sasha and Stefanec, Richard and Gatsko, Vitaly and Hirnschall, Christoph and Sethi, Ashwin and Xu, Xingyu Federico and Ahuja, Chetan and Tsai, Beth and Stefanoiu, Anca and Feng, Bo and Dhandhania, Keshav and Katyal, Manish and Gupta, Akshay and Parulekar, Atharva and Pitta, Divya and Zhao, Jing and Bhatia, Vivaan and Bhavnani, Yashodha and Alhadlaq, Omar and Li, Xiaolin and Danenberg, Peter and Tu, Dennis and Pine, Alex and Filippova, Vera and Ghosh, Abhipso and Limonchik, Ben and Urala, Bhargava and Lanka, Chaitanya Krishna and Clive, Derik and Sun, Yi and Li, Edward and Wu, Hao and Hongtongsak, Kevin and Li, Ianna and Thakkar, Kalind and Omarov, Kuanysh and Majmundar, Kushal and Alverson, Michael and Kucharski, Michael and Patel, Mohak and Jain, Mudit and Zabelin, Maksim and Pelagatti, Paolo and Kohli, Rohan and Kumar, Saurabh and Kim, Joseph and Sankar, Swetha and Shah, Vineet and Ramachandruni, Lakshmi and Zeng, Xiangkai and Bariach, Ben and Weidinger, Laura and Vu, Tu and Andreev, Alek and He, Antoine and Hui, Kevin and Kashem, Sheleem and Subramanya, Amar and Hsiao, Sissie and Hassabis, Demis and Kavukcuoglu, Koray and Sadovsky, Adam and Le, Quoc and Strohman, Trevor and Wu, Yonghui and Petrov, Slav and Dean, Jeffrey and Vinyals, Oriol},
  year = {2024},
  month = jun,
  number = {arXiv:2312.11805},
  eprint = {2312.11805},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.11805},
  urldate = {2024-06-24},
  abstract = {This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.},
  archiveprefix = {arXiv}
}

@incollection{Gentner2012AnalogicalReasoning,
  title = {Analogical {{Reasoning}}},
  booktitle = {Encyclopedia of {{Human Behavior}} ({{Second Edition}})},
  author = {Gentner, D. and Smith, L.},
  editor = {Ramachandran, V. S.},
  year = {2012},
  month = jan,
  pages = {130--136},
  publisher = {Academic Press},
  address = {San Diego},
  doi = {10.1016/B978-0-12-375000-6.00022-7},
  urldate = {2021-02-13},
  abstract = {Analogical reasoning is a kind of reasoning that is based on finding a common relational system between two situations, exemplars, or domains. When such a common system can be found, then what is known about one situation can be used to infer new information about the other. The basic intuition behind analogical reasoning is that when there are substantial similarities between situations, there are likely to be further similarities. This article describes the processes involved in analogical reasoning, reviews seminal research and recent developments in the field, and proposes new avenues of investigation.},
  isbn = {978-0-08-096180-4},
  langid = {english}
}

@article{Gilardi2023ChatGPTOutperformsCrowd,
  title = {{{ChatGPT}} Outperforms Crowd Workers for Text-Annotation Tasks},
  author = {Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Ma{\"e}l},
  year = {2023},
  month = jul,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {120},
  number = {30},
  pages = {e2305016120},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2305016120},
  urldate = {2024-02-10},
  abstract = {Many NLP applications require manual text annotations for a variety of tasks, notably to train classifiers or evaluate the performance of unsupervised models. Depending on the size and degree of complexity, the tasks may be conducted by crowd workers on platforms such as MTurk as well as trained annotators, such as research assistants. Using four samples of tweets and news articles (n = 6,183), we show that ChatGPT outperforms crowd workers for several annotation tasks, including relevance, stance, topics, and frame detection. Across the four datasets, the zero-shot accuracy of ChatGPT exceeds that of crowd workers by about 25 percentage points on average, while ChatGPT's intercoder agreement exceeds that of both crowd workers and trained annotators for all tasks. Moreover, the per-annotation cost of ChatGPT is less than \$0.003---about thirty times cheaper than MTurk. These results demonstrate the potential of large language models to drastically increase the efficiency of text classification.}
}

@article{Gleize2019AreYouConvinced,
  title = {Are {{You Convinced}}? {{Choosing}} the {{More Convincing Evidence}} with a {{Siamese Network}}},
  shorttitle = {Are {{You Convinced}}?},
  author = {Gleize, Martin and Shnarch, Eyal and Choshen, Leshem and Dankin, Lena and Moshkowich, Guy and Aharonov, Ranit and Slonim, Noam},
  year = {2019},
  month = jul,
  journal = {arXiv:1907.08971 [cs, stat]},
  eprint = {1907.08971},
  primaryclass = {cs, stat},
  urldate = {2019-09-25},
  abstract = {With the advancement in argument detection, we suggest to pay more attention to the challenging task of identifying the more convincing arguments. Machines capable of responding and interacting with humans in helpful ways have become ubiquitous. We now expect them to discuss with us the more delicate questions in our world, and they should do so armed with effective arguments. But what makes an argument more persuasive? What will convince you? In this paper, we present a new data set, IBM-EviConv, of pairs of evidence labeled for convincingness, designed to be more challenging than existing alternatives. We also propose a Siamese neural network architecture shown to outperform several baselines on both a prior convincingness data set and our own. Finally, we provide insights into our experimental results and the various kinds of argumentative value our method is capable of detecting.},
  archiveprefix = {arXiv}
}

@incollection{Goddu2009MakingLinkedConvergentDistinction,
  title = {Against {{Making}} the {{Linked-Convergent Distinction}}},
  booktitle = {Pondering on {{Problems}} of {{Argumentation}}: {{Twenty Essays}} on {{Theoretical Issues}}},
  author = {Goddu, G. C.},
  editor = {{van Eemeren}, Frans H. and Garssen, Bart},
  year = {2009},
  pages = {181--189},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-1-4020-9165-0_13},
  urldate = {2024-06-21},
  abstract = {The intuition guiding the avowed distinction between linked and convergent argument structures is easy enough to grasp -- in various arguments some of the premises appear to link together to form a single reason for the conclusion, while other premises appear to constitute separate reasons which independently converge on the conclusion. Though the intuition is easy enough to grasp, as James Freeman has recently pointed out: ``the problem of clearly distinguishing linked from convergent argument structure has proven vexing'' (Freeman, 2001, p. 397). Indeed, the question remains whether the intuition truly captures a real distinction.},
  isbn = {978-1-4020-9165-0},
  langid = {english}
}

@inproceedings{Goebel2018ExplainableAINew,
  title = {Explainable {{AI}}: {{The New}} 42?},
  shorttitle = {Explainable {{AI}}},
  booktitle = {Machine {{Learning}} and {{Knowledge Extraction}}},
  author = {Goebel, Randy and Chander, Ajay and Holzinger, Katharina and Lecue, Freddy and Akata, Zeynep and Stumpf, Simone and Kieseberg, Peter and Holzinger, Andreas},
  editor = {Holzinger, Andreas and Kieseberg, Peter and Tjoa, A Min and Weippl, Edgar},
  year = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {295--303},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-99740-7_21},
  abstract = {Explainable AI is not a new field. Since at least the early exploitation of C.S. Pierce's abductive reasoning in expert systems of the 1980s, there were reasoning architectures to support an explanation function for complex AI systems, including applications in medical diagnosis, complex multi-component design, and reasoning about the real world. So explainability is at least as old as early AI, and a natural consequence of the design of AI systems. While early expert systems consisted of handcrafted knowledge bases that enabled reasoning over narrowly well-defined domains (e.g., INTERNIST, MYCIN), such systems had no learning capabilities and had only primitive uncertainty handling. But the evolution of formal reasoning architectures to incorporate principled probabilistic reasoning helped address the capture and use of uncertain knowledge.There has been recent and relatively rapid success of AI/machine learning solutions arises from neural network architectures. A new generation of neural methods now scale to exploit the practical applicability of statistical and algebraic learning approaches in arbitrarily high dimensional spaces. But despite their huge successes, largely in problems which can be cast as classification problems, their effectiveness is still limited by their un-debuggability, and their inability to ``explain'' their decisions in a human understandable and reconstructable way. So while AlphaGo or DeepStack can crush the best humans at Go or Poker, neither program has any internal model of its task; its representations defy interpretation by humans, there is no mechanism to explain their actions and behaviour, and furthermore, there is no obvious instructional value ... the high performance systems can not help humans improve.Even when we understand the underlying mathematical scaffolding of current machine learning architectures, it is often impossible to get insight into the internal working of the models; we need explicit modeling and reasoning tools to explain how and why a result was achieved. We also know that a significant challenge for future AI is contextual adaptation, i.e., systems that incrementally help to construct explanatory models for solving real-world problems. Here it would be beneficial not to exclude human expertise, but to augment human intelligence with artificial intelligence.},
  isbn = {978-3-319-99740-7},
  langid = {english}
}

@article{Goel2017EditorialReasoningBrain,
  title = {Editorial: {{The Reasoning Brain}}: {{The Interplay}} between {{Cognitive Neuroscience}} and {{Theories}} of {{Reasoning}}},
  shorttitle = {Editorial},
  author = {Goel, Vinod and Navarrete, Gorka and Noveck, Ira A. and Prado, J{\'e}r{\^o}me},
  year = {2017},
  journal = {Frontiers in Human Neuroscience},
  volume = {10},
  publisher = {Frontiers},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2016.00673},
  urldate = {2021-01-16},
  abstract = {Editorial: The Reasoning Brain: The Interplay between Cognitive Neuroscience and Theories of Reasoning},
  langid = {english}
}

@inproceedings{Goel2017WhatHotCaseBased,
  title = {What's {{Hot}} in {{Case-Based Reasoning}}},
  booktitle = {Thirty-{{First AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Goel, Ashok and {Diaz-Agudo}, Belen},
  year = {2017},
  month = feb,
  langid = {english}
}

@article{Gordon2007CarneadesModelArgument,
  title = {The {{Carneades}} Model of Argument and Burden of Proof},
  author = {Gordon, Thomas F. and Prakken, Henry and Walton, Douglas},
  year = {2007},
  month = jul,
  journal = {Artificial Intelligence},
  series = {Argumentation in {{Artificial Intelligence}}},
  volume = {171},
  number = {10},
  pages = {875--896},
  issn = {0004-3702},
  doi = {10.1016/j.artint.2007.04.010},
  urldate = {2022-04-21},
  abstract = {We present a formal, mathematical model of argument structure and evaluation, taking seriously the procedural and dialogical aspects of argumentation. The model applies proof standards to determine the acceptability of statements on an issue-by-issue basis. The model uses different types of premises (ordinary premises, assumptions and exceptions) and information about the dialectical status of statements (stated, questioned, accepted or rejected) to allow the burden of proof to be allocated to the proponent or the respondent, as appropriate, for each premise separately. Our approach allows the burden of proof for a premise to be assigned to a different party than the one who has the burden of proving the conclusion of the argument, and also to change the burden of proof or applicable proof standard as the dialogue progresses from stage to stage. Useful for modeling legal dialogues, the burden of production and burden of persuasion can be handled separately, with a different responsible party and applicable proof standard for each. Carneades enables critical questions of argumentation schemes to be modeled as additional premises, using premise types to capture the varying effect on the burden of proof of different kinds of questions.},
  langid = {english}
}

@inproceedings{Goudas2014ArgumentExtractionNews,
  title = {Argument {{Extraction}} from {{News}}, {{Blogs}}, and {{Social Media}}},
  booktitle = {Artificial {{Intelligence}}: {{Methods}} and {{Applications}}},
  author = {Goudas, Theodosis and Louizos, Christos and Petasis, Georgios and Karkaletsis, Vangelis},
  editor = {Likas, Aristidis and Blekas, Konstantinos and Kalles, Dimitris},
  year = {2014},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {287--299},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-07064-3_23},
  abstract = {Argument extraction is the task of identifying arguments, along with their components in text. Arguments can be usually decomposed into a claim and one or more premises justifying it. Among the novel aspects of this work is the thematic domain itself which relates to Social Media, in contrast to traditional research in the area, which concentrates mainly on law documents and scientific publications. The huge increase of social media communities, along with their user tendency to debate, makes the identification of arguments in these texts a necessity. Argument extraction from Social Media is more challenging because texts may not always contain arguments, as is the case of legal documents or scientific publications usually studied. In addition, being less formal in nature, texts in Social Media may not even have proper syntax or spelling. This paper presents a two-step approach for argument extraction from social media texts. During the first step, the proposed approach tries to classify the sentences into ``sentences that contain arguments'' and ``sentences that don't contain arguments''. In the second step, it tries to identify the exact fragments that contain the premises from the sentences that contain arguments, by utilizing conditional random fields. The results exceed significantly the base line approach, and according to literature, are quite promising.},
  isbn = {978-3-319-07064-3},
  langid = {english}
}

@article{Grosse2015IntegratingArgumentationSentiment,
  title = {Integrating Argumentation and Sentiment Analysis for Mining Opinions from {{Twitter}}},
  author = {Grosse, Kathrin and Gonz{\'a}lez, Mar{\'i}a P. and Ches{\~n}evar, Carlos I. and Maguitman, Ana G.},
  year = {2015},
  month = jul,
  journal = {AI Communications},
  volume = {28},
  number = {3},
  pages = {387--401},
  issn = {18758452, 09217126},
  doi = {10.3233/AIC-140627},
  urldate = {2023-10-20}
}

@inproceedings{Grumbach2024CaseBasedSupportResponding,
  title = {Towards a~{{Case-Based Support}} for~{{Responding Emergency Calls}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Grumbach, Lisa and Winzig, Alexander and Bergmann, Ralph},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {273--288},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_18},
  abstract = {In emergency situations, the quick and precise initiation of rescue measures is crucial. Dispatchers are responsible for answering emergency calls and deciding about measures and resources. However, currently there is no support on the basis of an intelligent system that is able to exploit experiences from previous situations. Therefore, we propose a concept for a case-based support for emergency call handling in this work. First, we investigate where case-based reasoning can be applied in the decision process and sketch our vision of a hybrid intelligent approach that combines expert and experiential knowledge. For the case-based approach, we focus on deriving adequate measures and resource types. Furthermore, we propose a mechanism that supports the dispatcher in the choice of the questions such that precise decisions can be derived. The approach is prototypically implemented and will be evaluated with experts in future work.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@book{Guarino2009HandbookOntologies,
  title = {Handbook on {{Ontologies}}},
  author = {Guarino, Nicola and Oberle, Daniel and Staab, Steffen},
  editor = {Staab, Steffen and Studer, Rudi},
  year = {2009},
  month = jan,
  series = {What {{Is}} an {{Ontology}}},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-92673-3},
  isbn = {978-3-540-70999-2}
}

@inproceedings{Guo2009DomainAdaptationLatent,
  title = {Domain {{Adaptation}} with {{Latent Semantic Association}} for {{Named Entity Recognition}}},
  booktitle = {Proceedings of {{Human Language Technologies}}: {{The}} 2009 {{Annual Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Guo, Honglei and Zhu, Huijia and Guo, Zhili and Zhang, Xiaoxun and Wu, Xian and Su, Zhong},
  year = {2009},
  month = jun,
  pages = {281--289},
  publisher = {Association for Computational Linguistics},
  address = {Boulder, Colorado},
  urldate = {2020-04-27}
}

@misc{Guo2022GradientDescentBasedKNNAlgorithm,
  title = {A {{Gradient-Descent-Based}} k-{{NN Algorithm}}},
  author = {Guo, Wenqi},
  year = {2022},
  month = apr,
  doi = {10.31219/osf.io/kqdxu},
  abstract = {In this paper, we reviewed a few works that solved the speed issue of the k-NN classification algorithm. This makes it possible to solve real problems using the classificational k-NN algorithm. We then use gradient descent to achieve the equivalent goal of feature scaling, increasing the accuracy of the k-NN classification algorithm, including on nominal data. I was just a part-time college student when I wrote this paper, things might be wrong. Don't assume its credibility is high.}
}

@inproceedings{Guo2024DSAgentAutomatedData,
  title = {{{DS-Agent}}: {{Automated Data Science}} by {{Empowering Large Language Models}} with {{Case-Based Reasoning}}},
  shorttitle = {{{DS-Agent}}},
  booktitle = {Proceedings of the 41st {{International Conference}} on {{Machine Learning}}},
  author = {Guo, Siyuan and Deng, Cheng and Wen, Ying and Chen, Hechang and Chang, Yi and Wang, Jun},
  year = {2024},
  month = jul,
  pages = {16813--16848},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2024-09-14},
  abstract = {In this work, we investigate the potential of large language models (LLMs) based agents to automate data science tasks, with the goal of comprehending task requirements, then building and training the best-fit machine learning models. Despite their widespread success, existing LLM agents are hindered by generating unreasonable experiment plans within this scenario. To this end, we present DS-Agent, a novel automatic framework that harnesses LLM agent and case-based reasoning (CBR). In the development stage, DS-Agent follows the CBR framework to structure an automatic iteration pipeline, which can flexibly capitalize on the expert knowledge from Kaggle, and facilitate consistent performance improvement through the feedback mechanism. Moreover, DS-Agent implements a low-resource deployment stage with a simplified CBR paradigm to adapt past successful solutions from the development stage for direct code generation, significantly reducing the demand on foundational capabilities of LLMs. Empirically, DS-Agent with GPT-4 achieves 100\% success rate in the development stage, while attaining 36\% improvement on average one pass rate across alternative LLMs in the deployment stage. In both stages, DS-Agent achieves the best rank in performance, costing \$1.60 and \$0.13 per run with GPT-4, respectively. Our data and code are open-sourced at https://github.com/guosyjlu/DS-Agent.},
  langid = {english}
}

@article{Gurevych2017ArgumentationSocialMedia,
  title = {Argumentation in {{Social Media}}},
  author = {Gurevych, Iryna and Lippi, Marco and Torroni, Paolo},
  year = {2017},
  month = jun,
  journal = {ACM Transactions on Internet Technology},
  volume = {17},
  number = {3},
  pages = {23:1--23:2},
  issn = {1533-5399},
  doi = {10.1145/3056539},
  urldate = {2023-10-20}
}

@inproceedings{Gutfreund2016AutomaticArgumentsConstruction,
  title = {Automatic {{Arguments Construction}}---{{From Search Engine}} to {{Research Engine}}},
  booktitle = {2016 {{AAAI Fall Symposium Series}}},
  author = {Gutfreund, Dan and Katz, Yoav and Slonim, Noam},
  year = {2016}
}

@inproceedings{Guu2015TraversingKnowledgeGraphs,
  title = {Traversing {{Knowledge Graphs}} in {{Vector Space}}},
  booktitle = {Proceedings of the 2015 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Guu, Kelvin and Miller, John and Liang, Percy},
  year = {2015},
  month = sep,
  pages = {318--327},
  publisher = {Association for Computational Linguistics},
  address = {Lisbon, Portugal},
  doi = {10.18653/v1/D15-1038},
  urldate = {2020-06-16}
}

@inproceedings{Habernal2016WhatMakesConvincing,
  title = {What Makes a Convincing Argument? {{Empirical}} Analysis and Detecting Attributes of Convincingness in {{Web}} Argumentation},
  shorttitle = {What Makes a Convincing Argument?},
  booktitle = {Proceedings of the 2016 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Habernal, Ivan and Gurevych, Iryna},
  year = {2016},
  month = nov,
  pages = {1214--1223},
  publisher = {Association for Computational Linguistics},
  address = {Austin, Texas},
  doi = {10.18653/v1/D16-1129},
  urldate = {2019-09-04}
}

@inproceedings{Habernal2016WhichArgumentMore,
  title = {Which Argument Is More Convincing? {{Analyzing}} and Predicting Convincingness of {{Web}} Arguments Using Bidirectional {{LSTM}}},
  shorttitle = {Which Argument Is More Convincing?},
  booktitle = {Proceedings of the 54th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Habernal, Ivan and Gurevych, Iryna},
  year = {2016},
  month = aug,
  pages = {1589--1599},
  publisher = {Association for Computational Linguistics},
  address = {Berlin, Germany},
  doi = {10.18653/v1/P16-1150},
  urldate = {2019-09-04}
}

@article{Hallgren2012ComputingInterRaterReliability,
  title = {Computing {{Inter-Rater Reliability}} for {{Observational Data}}: {{An Overview}} and {{Tutorial}}},
  shorttitle = {Computing {{Inter-Rater Reliability}} for {{Observational Data}}},
  author = {Hallgren, Kevin A.},
  year = {2012},
  journal = {Tutorials in quantitative methods for psychology},
  volume = {8},
  number = {1},
  pages = {23--34},
  issn = {1913-4126},
  urldate = {2021-02-23},
  abstract = {Many research designs require the assessment of inter-rater reliability (IRR) to demonstrate consistency among observational ratings provided by multiple coders. However, many studies use incorrect statistical procedures, fail to fully report the information necessary to interpret their results, or do not address how IRR affects the power of their subsequent analyses for hypothesis testing. This paper provides an overview of methodological issues related to the assessment of IRR with a focus on study design, selection of appropriate statistics, and the computation, interpretation, and reporting of some commonly-used IRR statistics. Computational examples include SPSS and R syntax for computing Cohen's kappa and intra-class correlations to assess IRR.},
  pmcid = {PMC3402032},
  pmid = {22833776}
}

@article{Hamming2013ErrorDetectingError,
  title = {Error {{Detecting}} and {{Error Correcting Codes}}},
  author = {Hamming, R W},
  year = {2013},
  month = jul,
  journal = {Bell System Technical Journal},
  volume = {29},
  number = {2},
  pages = {147--160},
  doi = {10.1002/j.1538-7305.1950.tb00463.x},
  urldate = {2018-09-01}
}

@inproceedings{Hamp1997GermaNetLexicalSemanticNet,
  title = {{{GermaNet}} - a {{Lexical-Semantic Net}} for {{German}}},
  booktitle = {Automatic {{Information Extraction}} and {{Building}} of {{Lexical Semantic Resources}} for {{NLP Applications}}},
  author = {Hamp, Birgit and Feldweg, Helmut},
  year = {1997},
  urldate = {2021-02-11}
}

@book{Hardy1988Inequalities,
  title = {Inequalities},
  author = {Hardy, G H and Littlewood, J E and P{\'o}lya, G},
  year = {1988},
  month = jan,
  series = {Cambridge {{Mathematical Library}}},
  publisher = {Cambridge University Press},
  isbn = {978-0-521-35880-4}
}

@article{Harrell2005UsingArgumentDiagramming,
  title = {Using {{Argument Diagramming Software}} in the {{Classroom}}},
  author = {Harrell, Maralee},
  year = {2005},
  month = may,
  journal = {Teaching Philosophy},
  volume = {28},
  number = {2},
  pages = {163--177},
  doi = {10.5840/teachphil200528222},
  urldate = {2022-04-21},
  abstract = {Many undergraduates, philosophy majors included, read philosophical texts similar to the way they read stories. One method for teaching students how to discern the argumentative structure of a philosophy text is through argument diagrams (text boxes used to represent claims with arrows and lines used to represent connections between these claims). This paper provides criteria for an ideal argument diagramming software and then reviews the strengths and weaknesses of such software currently available, e.g. Araucaria, Argutect, Athena Standard, Inspiration, and Reason!Able.},
  langid = {english}
}

@phdthesis{Hassan2023AnalyzingArgumentationTwitter,
  title = {Analyzing {{Argumentation}} in {{Twitter Conversations}} with {{Graphs}}},
  author = {Hassan, Ahmed and Kakande, Arthur and Masroor, Maliha},
  year = {2023},
  month = mar,
  address = {Trier, Germany},
  abstract = {Social media platforms hold an immense amount of data that can be extensively exploited for drawing insightful information. The paper dives into the Twitter platform as a data source for assessing the political side of social media spectrum, specifically, regarding the 2020 US Presidential Elections. In this paper, we explore the idea of treating Twitter conversations as argument graphs to aid the process of manual annotation. The generated graphs are also exploited in creating argument detection models such as the parent-child text relations and argument relation detection using state-of-the-art machine learning approaches. This paper explains argumentative structure, identifies the various tasks involved in argument mining, and explains the challenges of conducting argument mining on Twitter.},
  langid = {english},
  school = {Trier University}
}

@inproceedings{Hautli-Janisz2022QT30CorpusArgument,
  title = {{{QT30}}: {{A Corpus}} of {{Argument}} and {{Conflict}} in {{Broadcast Debate}}},
  shorttitle = {{{QT30}}},
  booktitle = {Proceedings of the {{Thirteenth Language Resources}} and {{Evaluation Conference}}},
  author = {{Hautli-Janisz}, Annette and Kikteva, Zlata and Siskou, Wassiliki and Gorska, Kamila and Becker, Ray and Reed, Chris},
  year = {2022},
  month = jun,
  pages = {3291--3300},
  publisher = {European Language Resources Association},
  address = {Marseille, France},
  urldate = {2023-07-26},
  abstract = {Broadcast political debate is a core pillar of democracy: it is the public's easiest access to opinions that shape policies and enables the general public to make informed choices. With QT30, we present the largest corpus of analysed dialogical argumentation ever created (19,842 utterances, 280,000 words) and also the largest corpus of analysed broadcast political debate to date, using 30 episodes of BBC's `Question Time' from 2020 and 2021. Question Time is the prime institution in UK broadcast political debate and features questions from the public on current political issues, which are responded to by a weekly panel of five figures of UK politics and society. QT30 is highly argumentative and combines language of well-versed political rhetoric with direct, often combative, justification-seeking of the general public. QT30 is annotated with Inference Anchoring Theory, a framework well-known in argument mining, which encodes the way arguments and conflicts are created and reacted to in dialogical settings. The resource is freely available at http://corpora.aifdb.org/qt30.}
}

@misc{Havrilla2024TeachingLargeLanguage,
  title = {Teaching {{Large Language Models}} to {{Reason}} with {{Reinforcement Learning}}},
  author = {Havrilla, Alex and Du, Yuqing and Raparthy, Sharath Chandra and Nalmpantis, Christoforos and {Dwivedi-Yu}, Jane and Zhuravinskyi, Maksym and Hambro, Eric and Sukhbaatar, Sainbayar and Raileanu, Roberta},
  year = {2024},
  month = mar,
  number = {arXiv:2403.04642},
  eprint = {2403.04642},
  primaryclass = {cs},
  doi = {10.48550/arXiv.2403.04642},
  urldate = {2024-03-28},
  abstract = {Reinforcement Learning from Human Feedback ({\textbackslash}textbf\{RLHF\}) has emerged as a dominant approach for aligning LLM outputs with human preferences. Inspired by the success of RLHF, we study the performance of multiple algorithms that learn from feedback (Expert Iteration, Proximal Policy Optimization ({\textbackslash}textbf\{PPO\}), Return-Conditioned RL) on improving LLM reasoning capabilities. We investigate both sparse and dense rewards provided to the LLM both heuristically and via a learned reward model. We additionally start from multiple model sizes and initializations both with and without supervised fine-tuning ({\textbackslash}textbf\{SFT\}) data. Overall, we find all algorithms perform comparably, with Expert Iteration performing best in most cases. Surprisingly, we find the sample complexity of Expert Iteration is similar to that of PPO, requiring at most on the order of \$10{\textasciicircum}6\$ samples to converge from a pretrained checkpoint. We investigate why this is the case, concluding that during RL training models fail to explore significantly beyond solutions already produced by SFT models. Additionally, we discuss a trade off between maj@1 and pass@96 metric performance during SFT training and how conversely RL training improves both simultaneously. We then conclude by discussing the implications of our findings for RLHF and the future role of RL in LLM fine-tuning.},
  archiveprefix = {arXiv}
}

@inproceedings{Heindorf2020CauseNetCausalityGraph,
  title = {{{CauseNet}}: {{Towards}} a {{Causality Graph Extracted}} from the {{Web}}},
  booktitle = {Proceedings of the 29th {{ACM International Conference}} on {{Information}} and {{Knowledge Management}} ({{CIKM}} 2020)},
  author = {Heindorf, Stefan and Scholten, Yan and Wachsmuth, Henning and Ngomo, Axel-Cyrille Ngonga and Potthast, Martin},
  year = {2020},
  month = oct,
  pages = {8},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3340531.3412763},
  abstract = {Causal knowledge is seen as one of the key ingredients to advance artificial intelligence. Yet, few knowledge bases comprise causal knowledge to date, possibly due to significant efforts required for validation. Notwithstanding this challenge, we compile CauseNet, 1 a large-scale knowledge base of claimed causal relations between causal concepts. By extraction from different semi- and unstructured web sources, we collect more than 11 million causal relations with an estimated extraction precision of 83\% and construct the first large-scale and open-domain causality graph. We analyze the graph to gain insights about causal beliefs expressed on the web and we demonstrate its benefits in basic causal question answering. Future work may use the graph for causal reasoning, computational argumentation, multi-hop question answering, and more.},
  isbn = {978-1-4503-6859-9},
  langid = {english}
}

@inproceedings{Heinisch2023ArchitecturalSweetSpots,
  title = {Architectural {{Sweet Spots}} for {{Modeling Human Label Variation}} by the {{Example}} of {{Argument Quality}}: {{It}}'s {{Best}} to {{Relate Perspectives}}!},
  shorttitle = {Architectural {{Sweet Spots}} for {{Modeling Human Label Variation}} by the {{Example}} of {{Argument Quality}}},
  booktitle = {Proceedings of the 2023 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Heinisch, Philipp and Orlikowski, Matthias and Romberg, Julia and Cimiano, Philipp},
  editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
  year = {2023},
  month = dec,
  pages = {11138--11154},
  publisher = {Association for Computational Linguistics},
  address = {Singapore},
  doi = {10.18653/v1/2023.emnlp-main.687},
  urldate = {2024-04-09},
  abstract = {Many annotation tasks in natural language processing are highly subjective in that there can be different valid and justified perspectives on what is a proper label for a given example. This also applies to the judgment of argument quality, where the assignment of a single ground truth is often questionable. At the same time, there are generally accepted concepts behind argumentation that form a common ground. To best represent the interplay of individual and shared perspectives, we consider a continuum of approaches ranging from models that fully aggregate perspectives into a majority label to ``share nothing''-architectures in which each annotator is considered in isolation from all other annotators. In between these extremes, inspired by models used in the field of recommender systems, we investigate the extent to which architectures that predict labels for single annotators but include layers that model the relations between different annotators are beneficial. By means of two tasks of argument quality classification (argument concreteness and validity/novelty of conclusions), we show that recommender architectures increase the averaged annotator-individual F1-scores up to 43\% over a majority-label model. Our findings indicate that approaches to subjectivity can benefit from relating individual perspectives.}
}

@inproceedings{Heinisch2024TellMeWho,
  title = {Tell Me Who You Are and {{I}} Tell You How You Argue: {{Predicting Stances}} and {{Arguments}} for {{Stakeholder Groups}}},
  shorttitle = {Tell Me Who You Are and {{I}} Tell You How You Argue},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{NAACL}} 2024},
  author = {Heinisch, Philipp and Dumani, Lorik and Cimiano, Philipp and Schenkel, Ralf},
  editor = {Duh, Kevin and Gomez, Helena and Bethard, Steven},
  year = {2024},
  month = jun,
  pages = {1968--1982},
  publisher = {Association for Computational Linguistics},
  address = {Mexico City, Mexico},
  doi = {10.18653/v1/2024.findings-naacl.128},
  urldate = {2024-12-11},
  abstract = {Argument mining has focused so far mainly on the identification, extraction, and formalization of arguments. An important yet unaddressedtask consists in the prediction of the argumentative behavior of stakeholders in a debate. Predicting the argumentative behavior in advance can support foreseeing issues in public policy making or help recognize potential disagreements early on and help to resolve them. In this paper, we consider the novel task of predicting the argumentative behavior of individual stakeholders. We present ARGENST, a framework that relies on a recommender-based architecture to predict the stance and the argumentative main point on a specific controversial topic for a given stakeholder, which is described in terms of a profile including properties related to demographic attributes, religious and political orientation, socio-economic background, etc. We evaluate our approach on the well-known debate.org dataset in terms of accuracy for predicting stance as well as in terms of similarity of the generated arguments to the ground truth arguments using BERTScore. As part of a case study, we show how juries of members representing different stakeholder groups and perspectives can be assembled to simulate the public opinion on a given topic.}
}

@phdthesis{Hemel2006NixOSNixBased,
  title = {{{NixOS}}: The {{Nix}} Based Operating System},
  shorttitle = {{{NixOS}}},
  author = {Hemel, Armijn},
  year = {2006},
  month = aug,
  doi = {10.5281/zenodo.12906987},
  urldate = {2024-07-28},
  abstract = {The subject of this thesis is how the Nix package management system can be applied to manage a whole Linux distribution. Many conventional packagemanagement systems have drawbacks that Nix fixes. But, Nix has never been used to deploy and manage a whole system. In this thesis a proof of concept Linux distribution called NixOS is described. NixOS uses the Nix package management system to manage all software that is installed on the system, including the Linux kernel, all software and system services. Using Nix to manage all software on a system, as is done on NixOS, has several advantages. Developers don't need to be worried that unwanted dependencies are picked up during the build of a software package, since these are completely eliminated. System administrators get the possibility to deploy services using Nix and how they can immediately use all benefits from Nix, including atomic upgrades and rollbacks, without going through a painful cycle of rolling back a service, with all its, possibly also updated, dependencies. This thesis describes the implementation NixOS, including pitfalls that were encountered and choices that were made. Also shown are some concrete results of running NixOS and how NixOS can be bettered.}
}

@article{Hesse1959DefiningAnalogy,
  title = {On {{Defining Analogy}}},
  author = {Hesse, M},
  year = {1959},
  journal = {Proc. Aristotelian Soc.},
  volume = {60},
  pages = {79--100}
}

@article{Hevner2004DesignScienceInformation,
  title = {Design {{Science}} in {{Information Systems Research}}},
  author = {Hevner, Alan R. and March, Salvatore T. and Park, Jinsoo and Ram, Sudha},
  year = {2004},
  journal = {MIS Quarterly},
  volume = {28},
  number = {1},
  eprint = {25148625},
  eprinttype = {jstor},
  pages = {75--105},
  publisher = {Management Information Systems Research Center, University of Minnesota},
  issn = {0276-7783},
  doi = {10.2307/25148625},
  urldate = {2024-06-13},
  abstract = {Two paradigms characterize much of the research in the Information Systems discipline: behavioral science and design science. The behavioral-science paradigm seeks to develop and verify theories that explain or predict human or organizational behavior. The design-science paradigm seeks to extend the boundaries of human and organizational capabilities by creating new and innovative artifacts. Both paradigms are foundational to the IS discipline, positioned as it is at the confluence of people, organizations, and technology. Our objective is to describe the performance of design-science research in Information Systems via a concise conceptual framework and clear guidelines for understanding, executing, and evaluating the research. In the design-science paradigm, knowledge and understanding of a problem domain and its solution are achieved in the building and application of the designed artifact. Three recent exemplars in the research literature are used to demonstrate the application of these guidelines. We conclude with an analysis of the challenges of performing high-quality design-science research in the context of the broader IS community.}
}

@inproceedings{Hewett2019UtilityDiscourseParsing,
  title = {The {{Utility}} of {{Discourse Parsing Features}} for {{Predicting Argumentation Structure}}},
  booktitle = {Proceedings of the 6th {{Workshop}} on {{Argument Mining}}},
  author = {Hewett, Freya and Prakash Rane, Roshan and Harlacher, Nina and Stede, Manfred},
  year = {2019},
  month = aug,
  pages = {98--103},
  publisher = {Association for Computational Linguistics},
  address = {Florence, Italy},
  doi = {10.18653/v1/W19-4512},
  urldate = {2023-10-26},
  abstract = {Research on argumentation mining from text has frequently discussed relationships to discourse parsing, but few empirical results are available so far. One corpus that has been annotated in parallel for argumentation structure and for discourse structure (RST, SDRT) are the `argumentative microtexts' (Peldszus and Stede, 2016a). While results on perusing the gold RST annotations for predicting argumentation have been published (Peldszus and Stede, 2016b), the step to automatic discourse parsing has not yet been taken. In this paper, we run various discourse parsers (RST, PDTB) on the corpus, compare their results to the gold annotations (for RST) and then assess the contribution of automatically-derived discourse features for argumentation parsing. After reproducing the state-of-the-art Evidence Graph model from Afantenos et al. (2018) for the microtexts, we find that PDTB features can indeed improve its performance.}
}

@article{Hidayaturrahman2021EnhancingArgumentationComponent,
  title = {Enhancing Argumentation Component Classification Using Contextual Language Model},
  author = {{Hidayaturrahman} and Dave, Emmanuel and Suhartono, Derwin and Arymurthy, Aniati Murni},
  year = {2021},
  month = jul,
  journal = {Journal of Big Data},
  volume = {8},
  number = {1},
  pages = {103},
  issn = {2196-1115},
  doi = {10.1186/s40537-021-00490-2},
  urldate = {2023-04-07},
  abstract = {Arguments facilitate humans to deliver their ideas. The outcome of the discussion heavily relies on the validity of the argument. If an argument is well-composed, it is more effective to grasp the core idea behind the argument. To grade the argument, machines can be utilized by decomposing into semantic label components. In natural language processing, multiple language models are available to perform this task. It is divided into context-free and contextual models. The majority of previous studies used hand-crafted features to perform argument component classification, while state of the art language models utilize machine learning. The majority of these language models ignore the context in an argument. This research paper aims to analyze whether by including the context in the classification process may improve the accuracy of the language model which will enhance the argumentation mining process as well. The same document corpus is fed into several language models. Word2Vec and GLoVe represent the context free models, while BERT and ELMo as context sensitive language models. Accuracy and time from each model are then compared to determine the importance of context. The result shows that contextual language models are proven to be able to boost classification accuracy by approximately 20\%. However, time comes as a cost where contextual models require longer training and prediction time. The benefit from the increase in accuracy outweighs the burden of time. Thus, as a contextual task, argumentation mining is suggested to use contextual model where context must be included to achieve promising results.},
  langid = {english}
}

@article{Hirschberg2015AdvancesNaturalLanguage,
  title = {Advances in Natural Language Processing},
  author = {Hirschberg, Julia and Manning, Christopher D.},
  year = {2015},
  month = jul,
  journal = {Science},
  volume = {349},
  number = {6245},
  pages = {261--266},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aaa8685},
  urldate = {2021-02-06},
  abstract = {Natural language processing employs computational techniques for the purpose of learning, understanding, and producing human language content. Early computational approaches to language research focused on automating the analysis of the linguistic structure of language and developing basic technologies such as machine translation, speech recognition, and speech synthesis. Today's researchers refine and make use of such tools in real-world applications, creating spoken dialogue systems and speech-to-speech translation engines, mining social media for information about health or finance, and identifying sentiment and emotion toward products and services. We describe successes and challenges in this rapidly advancing area.},
  chapter = {Review},
  copyright = {Copyright {\copyright} 2015, American Association for the Advancement of Science},
  langid = {english},
  pmid = {26185244}
}

@inproceedings{Hlaoui2002NewAlgorithmInexact,
  title = {A New Algorithm for Inexact Graph Matching},
  booktitle = {Object Recognition Supported by User Interaction for Service Robots},
  author = {Hlaoui, Adel and Wang, Shengrui},
  year = {2002},
  month = aug,
  volume = {4},
  pages = {180-183 vol.4},
  issn = {1051-4651},
  doi = {10.1109/ICPR.2002.1047427},
  abstract = {The graph is an essential data structure for representing relational information. When graphs are used to represent objects, comparing objects amounts to graph matching. Inexact graph matching is the process of finding the best possible matching between two graphs when exact matching is impossible. We propose a new algorithm for the inexact matching problem. The new algorithm decomposes the matching process into K phases, where the value of K ranges from 1 to the minimum of the numbers of nodes in the two graphs to be matched. The efficiency of the new algorithm results from the use of small values of K, significantly reducing the search space while still producing very good matchings (most of them optimal) between graphs. The algorithm is compared with the error-correcting subgraph isomorphism algorithm based on A*.}
}

@article{Hlavacova2017GoldenRuleMorphology,
  title = {Golden {{Rule}} of {{Morphology}} and {{Variants}} of {{Word}} Forms},
  author = {Hlav{\'a}{\v c}ov{\'a}, Jaroslava},
  year = {2017},
  month = dec,
  journal = {Journal of Linguistics/Jazykovedn{\'y} casopis},
  volume = {68},
  number = {2},
  pages = {136--144},
  publisher = {Sciendo},
  doi = {10.1515/jazcas-2017-0024},
  urldate = {2021-03-08},
  abstract = {{$<$}section class="abstract"{$><$}h2 class="abstractTitle text-title my-1" id="d1385e2"{$>$}Abstract{$<$}/h2{$><$}p{$>$}In many languages, some words can be written in several ways. We call them variants. Values of all their morphological categories are identical, which leads to an identical morphological tag. Together with the identical lemma, we have two or more wordforms with the same morphological description. This ambiguity may cause problems in various NLP applications. There are two types of variants -- those affecting the whole paradigm (global variants) and those affecting only wordforms sharing some combinations of morphological values (inflectional variants). In the paper, we propose means how to tag all wordforms, including their variants, unambiguously. We call this requirement ``Golden rule of morphology''. The paper deals mainly with Czech, but the ideas can be applied to other languages as well.{$<$}/p{$><$}/section{$>$}},
  chapter = {Journal of Linguistics/Jazykovedn{\'y} casopis},
  langid = {english}
}

@phdthesis{Hoelzmann2024UntersuchungKoreferenzaufloesungArgumentgraphen,
  type = {{Bachelor's Thesis}},
  title = {{Untersuchung der Koreferenzaufl{\"o}sung in Argumentgraphen mittels Prompting}},
  author = {H{\"o}lzmann, Lukas},
  year = {2024},
  month = dec,
  address = {Trier, Germany},
  langid = {ngerman},
  school = {Trier University}
}

@inproceedings{Hoffmann2020UsingSiameseGraph,
  title = {Using {{Siamese Graph Neural Networks}} for {{Similarity-Based Retrieval}} in {{Process-Oriented Case-Based Reasoning}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Hoffmann, Maximilian and Malburg, Lukas and Klein, Patrick and Bergmann, Ralph},
  editor = {Watson, Ian and Weber, Rosina},
  year = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {229--244},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-58342-2_15},
  abstract = {Similarity-based retrieval of semantic graphs is widely used in real-world scenarios, e. g., in the domain of business workflows. To tackle the problem of complex and time-consuming graph similarity computations during retrieval, the MAC/FAC approach is used in Process-Oriented Case-Based Reasoning (POCBR), where similar graphs are extracted from a preselected set of candidate graphs. These graphs result from a similarity computation with a computationally inexpensive similarity measure. The contribution of this paper is a novel similarity measure where vector space embeddings generated by two siamese Graph Neural Networks (GNNs) are used to approximate the similarities of a precise but therefore computationally complex graph similarity measure. Our approach includes a specific encoding scheme for semantic graphs that enables their usage in neural networks. The evaluation examines the quality and performance of these models in preselecting retrieval candidates and in approximating the ground-truth similarities of the graph similarity measure for two workflow domains. The results show great potential of the approach for being used in a MAC/FAC scenario, either as a preselection model or as an approximation of the graph similarity measure.},
  isbn = {978-3-030-58342-2},
  langid = {english}
}

@inproceedings{Hoffmann2022GPUBasedGraphMatching,
  title = {{{GPU-Based Graph Matching}} for~{{Accelerating Similarity Assessment}} in~{{Process-Oriented Case-Based Reasoning}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Hoffmann, Maximilian and Malburg, Lukas and Bach, Nico and Bergmann, Ralph},
  editor = {Keane, Mark T. and Wiratunga, Nirmalie},
  year = {2022},
  pages = {240--255},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-14923-8_16},
  abstract = {In Process-Oriented Case-Based Reasoning (POCBR), determining the similarity between cases represented as semantic graphs often requires some kind of inexact graph matching, which generally is an NP-hard problem. Heuristic search algorithms such as A* search have been successfully applied for this task, but the computational performance is still a limiting factor for large case bases. As related work shows a great potential for accelerating A* search by using GPUs, we propose a novel approach called AMonG for efficiently computing graph similarities with an A* graph matching process involving GPU computing. The three-phased matching process distributes the search process over multiple search instances running in parallel on the GPU. We develop and examine different strategies within these phases that allow to customize the matching process adjusted to the problem situation to be solved. The experimental evaluation compares the proposed GPU-based approach with a pure CPU-based one. The results clearly demonstrate that the GPU-based approach significantly outperforms the CPU-based approach in a retrieval scenario, leading to an average speedup factor of 16.},
  isbn = {978-3-031-14923-8},
  langid = {english}
}

@article{Hogan2021KnowledgeGraphs,
  title = {Knowledge {{Graphs}}},
  author = {Hogan, Aidan and Blomqvist, Eva and Cochez, Michael and {d'Amato}, Claudia and {de Melo}, Gerard and Gutierrez, Claudio and Gayo, Jos{\'e} Emilio Labra and Kirrane, Sabrina and Neumaier, Sebastian and Polleres, Axel and Navigli, Roberto and Ngomo, Axel-Cyrille Ngonga and Rashid, Sabbir M. and Rula, Anisa and Schmelzeisen, Lukas and Sequeda, Juan and Staab, Steffen and Zimmermann, Antoine},
  year = {2021},
  month = jan,
  journal = {arXiv:2003.02320 [cs]},
  eprint = {2003.02320},
  primaryclass = {cs},
  urldate = {2021-01-31},
  abstract = {In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After some opening remarks, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.},
  archiveprefix = {arXiv}
}

@article{Horn2000TeachingPhilosophyArgumentation,
  title = {Teaching Philosophy with Argumentation Maps},
  author = {Horn, Robert E.},
  year = {2000},
  journal = {Newsletter of the American Philosophical Association},
  abstract = {The greatest challenge of doing philosophy today may be one of not being able to see the forest for the trees. Whether teachers and students will readily admit to it, the content of philosophical studies is too often presented in twigs, many of which are rarely if ever connected to larger branches of thought. The problem for students is not usually one of understanding a particular argument,  but rather understanding where and how all the arguments fit together. Consider, for example, the difficulty involved in trying to determine the current status of a longstanding philosophical debate. What arguments have already been made? Which have been rebutted?  Who has argued what against whom? What counter-rebuttals have been offered?  The most interesting and important arguments are usually carried on in the journals of several different fields. Research and the debates over the nature of consciousness, for instance, appear in the journals of neurobiology, cognitive science, anthropology, psychology, and philosophy. How can we expect to keep track of what is being currently thought about or written on the subject? At the same time, philosophers and students of philosophy also have wide-ranging}
}

@article{Hossin2015ReviewEvaluationMetrics,
  title = {A {{Review}} on {{Evaluation Metrics}} for {{Data Classification Evaluations}}},
  author = {Hossin, M. and Sulaiman, M.N.},
  year = {2015},
  month = mar,
  journal = {International Journal of Data Mining \& Knowledge Management Process},
  volume = {5},
  number = {2},
  pages = {01--11},
  issn = {2231007X, 22309608},
  doi = {10.5121/ijdkp.2015.5201},
  urldate = {2021-03-13}
}

@article{Hsu2003InterraterAgreementMeasures,
  title = {Interrater {{Agreement Measures}}: {{Comments}} on {{Kappan}}, {{Cohen}}'s {{Kappa}}, {{Scott}}'s {{Pi}}, and {{Aickin}}'s {{Alpha}}},
  shorttitle = {Interrater {{Agreement Measures}}},
  author = {Hsu, Louis M. and Field, Ronald},
  year = {2003},
  month = aug,
  journal = {Understanding Statistics},
  volume = {2},
  number = {3},
  pages = {205--219},
  publisher = {Routledge},
  issn = {1534-844X},
  doi = {10.1207/S15328031US0203_03},
  urldate = {2021-03-07},
  abstract = {The Cohen (1960) kappa interrater agreement coefficient has been criticized for penalizing raters (e.g., diagnosticians) for their a priori agreement about the base rates of categories (e.g., base rates of disorders). A modification of kappa, called kappan (alias S coefficient, C coefficient, G index, and RE coefficient) has been proposed as an alternative to Cohen's kappa: Kappan was intended to reward rather than penalize classification agreements attributable to interrater agreement about base rates. In this article, we show that kappan has some serious limitations: It can be large when raters who randomly assign objects (e.g., patients) to categories (diagnoses) radically disagree about base rates, and it can be much larger when these raters have very different beliefs about base rates than when they are in complete agreement about base rates. Contrary to the views of recent critics of Cohen's kappa, we argue that Cohen's kappa (which does not have these serious limitations) is generally preferable to kappan. Cohen's kappa is also compared to two other kappa-type statistics (Scott's, 1955, {$\Pi$}; Aickin's, 1990, {$\alpha$}). Unlike Scott's {$\Pi$}, Cohen's kappa can yield useful information about interrater agreement in the presence of marginal heterogeneity; Cohen's kappa is easier to calculate and more conservative than Aickin's {$\alpha$}; and in addition, much more information is available about factors affecting Cohen's kappa than about factors affecting Aickin's {$\alpha$}.}
}

@inproceedings{Huang2008SimilarityMeasuresText,
  title = {Similarity Measures for Text Document Clustering},
  booktitle = {Proceedings of the Sixth New Zealand Computer Science Research Student Conference ({{NZCSRSC2008}})},
  author = {Huang, Anna},
  year = {2008},
  month = apr,
  pages = {49--56},
  address = {Christchurch, New Zealand},
  urldate = {2018-09-05},
  abstract = {Clustering is a useful technique that organizes a large quantity of unordered text documents into a small number of meaningful and coherent clusters, thereby providing a basis for intuitive and informative navigation and browsing mechanisms. Partitional clustering algorithms have been recognized to be more suitable as opposed to the hierarchical clustering schemes for processing large datasets. A wide variety of distance functions and similarity measures have been used for clustering, such as squared Euclidean distance, cosine similarity, and relative entropy. In this paper, we compare and analyze the effectiveness of these measures in partitional clustering for text document datasets. Our experiments utilize the standard Kmeans algorithm and we report results on seven text document datasets and five distance/similarity measures that have been most commonly used in text clustering.}
}

@inproceedings{Huang2021DocumentlevelEntitybasedExtraction,
  title = {Document-Level {{Entity-based Extraction}} as {{Template Generation}}},
  booktitle = {Proceedings of the 2021 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Huang, Kung-Hsiang and Tang, Sam and Peng, Nanyun},
  editor = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
  year = {2021},
  month = nov,
  pages = {5257--5269},
  publisher = {Association for Computational Linguistics},
  address = {Online and Punta Cana, Dominican Republic},
  doi = {10.18653/v1/2021.emnlp-main.426},
  urldate = {2024-08-15},
  abstract = {Document-level entity-based extraction (EE), aiming at extracting entity-centric information such as entity roles and entity relations, is key to automatic knowledge acquisition from text corpora for various domains. Most document-level EE systems build extractive models, which struggle to model long-term dependencies among entities at the document level. To address this issue, we propose a generative framework for two document-level EE tasks: role-filler entity extraction (REE) and relation extraction (RE). We first formulate them as a template generation problem, allowing models to efficiently capture cross-entity dependencies, exploit label semantics, and avoid the exponential computation complexity of identifying N-ary relations. A novel cross-attention guided copy mechanism, TopK Copy, is incorporated into a pre-trained sequence-to-sequence model to enhance the capabilities of identifying key information in the input document. Experiments done on the MUC-4 and SciREX dataset show new state-of-the-art results on REE (+3.26\%), binary RE (+4.8\%), and 4-ary RE (+2.7\%) in F1 score.}
}

@inproceedings{Huang2023ReasoningLargeLanguage,
  title = {Towards {{Reasoning}} in {{Large Language Models}}: {{A Survey}}},
  shorttitle = {Towards {{Reasoning}} in {{Large Language Models}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{ACL}} 2023},
  author = {Huang, Jie and Chang, Kevin Chen-Chuan},
  editor = {Rogers, Anna and {Boyd-Graber}, Jordan and Okazaki, Naoaki},
  year = {2023},
  month = jul,
  pages = {1049--1065},
  publisher = {Association for Computational Linguistics},
  address = {Toronto, Canada},
  doi = {10.18653/v1/2023.findings-acl.67},
  urldate = {2024-09-16},
  abstract = {Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking. In recent years, large language models (LLMs) have made significant progress in natural language processing, and there is observation that these models may exhibit reasoning abilities when they are sufficiently large. However, it is not yet clear to what extent LLMs are capable of reasoning. This paper provides a comprehensive overview of the current state of knowledge on reasoning in LLMs, including techniques for improving and eliciting reasoning in these models, methods and benchmarks for evaluating reasoning abilities, findings and implications of previous research in this field, and suggestions on future directions. Our aim is to provide a detailed and up-to-date review of this topic and stimulate meaningful discussion and future work.}
}

@inproceedings{Huang2024LargeLanguageModels,
  title = {Large {{Language Models}} for {{Graphs}}: {{Progresses}} and {{Directions}}},
  shorttitle = {Large {{Language Models}} for {{Graphs}}},
  booktitle = {Companion {{Proceedings}} of the {{ACM Web Conference}} 2024},
  author = {Huang, Chao and Ren, Xubin and Tang, Jiabin and Yin, Dawei and Chawla, Nitesh},
  year = {2024},
  month = may,
  series = {{{WWW}} '24},
  pages = {1284--1287},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3589335.3641251},
  urldate = {2024-09-16},
  abstract = {Graph neural networks (GNNs) have emerged as fundamental methods for handling structured graph data in various domains, including citation networks, molecule prediction, and recommender systems. They enable the learning of informative node or graph representations, which are crucial for tasks such as link prediction and node classification in the context of graphs. To achieve high-quality graph representation learning, certain essential factors come into play: clean labels, accurate graph structures, and sufficient initial node features. However, real-world graph data often suffer from noise and sparse labels, while different datasets have unique feature constructions. These factors significantly impact the generalization capabilities of graph neural networks, particularly when faced with unseen tasks. Recently, due to the efficent text processing and task generalization capability of large language models (LLMs), there has been a promising approach to address the challenges mentioned above by combining large language models with graph data.  This tutorial offers an overview of incorporating large language models into the graph domain, accompanied by practical examples. The methods are categorized into three dimensions: utilizing LLMs as augmenters, predictors, and agents for graph learning tasks. We will delve into the current progress and future directions within this field. By introducing this emerging topic, our aim is to enhance the audience's understanding of LLM-based graph learning techniques, foster idea exchange, and encourage discussions that drive continuous advancements in this domain.},
  isbn = {979-8-4007-0172-6}
}

@inproceedings{Hulpus2019ExplainingNaturalLanguage,
  title = {Towards {{Explaining Natural Language Arguments}} with {{Background Knowledge}}},
  booktitle = {Workshop on {{Semantic Explainability}} ({{SemEx}} 2019) in the 18th {{Intl}}. {{Semantic Web Conf}}. ({{ISWC}} 2019)},
  author = {Hulpus, Ioana and Kobbe, Jonathan and Becker, Maria and Opitz, Juri and Hirst, Graeme and Meilicke, Christian and Nastase, Vivi and Stuckenschmidt, Heiner and Frank, Anette},
  year = {2019},
  volume = {2465},
  pages = {16},
  address = {Christchurch, New Zealand},
  abstract = {In this paper, we propose the task of argument explicitation, a task that makes the structure of a natural language argument explicit, as well as the background knowledge the argument is built on, in the form of implicit premises or contextual knowledge. The purpose of argument explicitation is to support the understanding of an argument by providing users with an end-to-end analysis that offers a critical assessment of arguments including identification of argument weaknesses. Besides, the results of the argument explicitation process can be used by machines to retrieve similar arguments as well as counter-arguments. We propose a framework for argument explicitation that joins a variety of AI and NLPbased argumentation mining sub-tasks that by now have mostly been treated separately in the literature. We identify the challenges this task entails, while at the same time highlighting the opportunities brought by the recent development of structured, external knowledge sources.},
  langid = {english}
}

@article{Jaccard1912DistributionFloraAlpine,
  title = {The {{Distribution}} of the {{Flora}} in the {{Alpine Zone}}},
  author = {Jaccard, Paul},
  year = {1912},
  journal = {New Phytologist},
  volume = {11},
  number = {2},
  pages = {37--50},
  issn = {1469-8137},
  doi = {10.1111/j.1469-8137.1912.tb05611.x},
  urldate = {2021-03-11},
  langid = {english}
}

@article{Jaiswal2024FaNREMsFairNormalized,
  title = {{{FaN-REMs}}: {{Fair}} and {{Normalized Retrieval Evaluation Metrics}} for {{Learning Retrieval Systems}}},
  shorttitle = {{{FaN-REMs}}},
  author = {Jaiswal, Amar and Kumar, Mohit and Pathak, Ajeet Ram and Yigzaw, Kassaye Yitbarek},
  year = {2024},
  journal = {IEEE Access},
  volume = {12},
  pages = {195370--195395},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3514916},
  urldate = {2025-01-10},
  abstract = {Retrieval evaluation metrics are vital for resilient artificial intelligence (AI) retrieval systems and its subfields, such as case-based reasoning (CBR). Despite extensive research in CBR over the decades, the field still lacks a specialized retrieval evaluation metric (REM). This study aims to critically investigate and devise retrieval evaluation metrics that are generic, fair, normalized, and non-deceptive, which make it suitable for domains including learning retrieval systems such as CBR. It focuses on enhancing CBR retrievals by addressing key flaws in widely used metrics, including the normalized discounted cumulative gain at k ( nDCG{\textbackslash}text@k ) metric in IR. The proposed method entails devising a fair and normalized (FaN) relevancy metric for a case retrieved against a test query, blending system-generated and oracle-assessed relevancies. This underpins three rank-based metrics: relevancy at k ( R{\textbackslash}text@k ), average relevancy at k ( AR{\textbackslash}text@k ), and mean average relevancy at k ( MAR{\textbackslash}text@k ). These metrics are designed for both single and multiple query evaluations and offer a comprehensive retrieval analysis. Despite inherent challenges in evaluating evaluation metrics, FaN-REMs demonstrated robust performance across plausible domain values for the FaN relevancy function. These metrics effectively assess retrievals across different implementations, similarity measures, and applications, with inherent normalization allowing for comparisons across heterogeneous systems. These metrics were instrumental in developing a CBR-based clinical decision support system (CDSS) for the SupportPrim study in Norway, demonstrating the practical application and relevance of this research in real-world AI systems. FaN-REMs show promise as benchmark metrics to compare various retrieval and CBR systems. Suitable for set-based and rank-based evaluations, rank-based FaN-REMs demonstrate superior discriminatory capability. The experimental results affirm the viability of FaN-REMs in real-world CBR system development and maintenance.}
}

@article{Jamshidi2018MicroservicesJourneyFar,
  title = {Microservices: {{The Journey So Far}} and {{Challenges Ahead}}},
  shorttitle = {Microservices},
  author = {Jamshidi, Pooyan and Pahl, Claus and Mendon{\c c}a, Nabor C. and Lewis, James and Tilkov, Stefan},
  year = {2018},
  month = may,
  journal = {IEEE Software},
  volume = {35},
  number = {3},
  pages = {24--35},
  issn = {1937-4194},
  doi = {10.1109/MS.2018.2141039},
  urldate = {2023-11-20},
  abstract = {Microservices are an architectural approach emerging out of service-oriented architecture, emphasizing self-management and lightweightness as the means to improve software agility, scalability, and autonomy. This article examines microservice evolution from the technological and architectural perspectives and discusses key challenges facing future microservice developments.}
}

@inproceedings{Janier2014OVAArgumentAnalysis,
  title = {{{OVA}}+: An {{Argument Analysis Interface}}},
  shorttitle = {{{OVA}}+},
  booktitle = {Computational {{Models}} of {{Argument}} - {{Proceedings}} of {{COMMA}} 2014, {{Atholl Palace Hotel}}, {{Scottish Highlands}}, {{UK}}, {{September}} 9-12, 2014},
  author = {Janier, Mathilde and Lawrence, John and Reed, Chris},
  editor = {Parsons, Simon and Oren, Nir and Reed, Chris and Cerutti, Federico},
  year = {2014},
  series = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  volume = {266},
  pages = {463--464},
  publisher = {IOS Press},
  doi = {10.3233/978-1-61499-436-7-463},
  abstract = {This paper introduces OVA+, an on-line interface for the analysis of arguments. It is the result of an attempt to provide a tool relying on the Argument Interchange Format theory and Inference Anchoring Theory schemes.}
}

@inproceedings{Jarmulak2000GeneticAlgorithmsOptimise,
  title = {Genetic {{Algorithms}} to {{Optimise CBR Retrieval}}},
  booktitle = {Advances in {{Case-Based Reasoning}}},
  author = {Jarmulak, Jacek and Craw, Susan and Rowe, Ray},
  editor = {Blanzieri, Enrico and Portinale, Luigi},
  year = {2000},
  pages = {136--147},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-44527-7_13},
  abstract = {Knowledge in a case-based reasoning (CBR) system is often more extensive than simply the cases, therefore knowledge engineering may still be very demanding. This paper offers a first step towards an automated knowledge acquisition and refinement tool for non-case CBR knowledge. A data-driven approach is presented where a Genetic Algorithm learns effective feature selection for inducing case-base index, and feature weights for similarity measure for case retrieval. The optimisation can be viewed as knowledge acquisition or maintenance depending on whether knowledge is being created or refined. Optimising CBRretrieval is achieved using cases from the case-base and only minimal expert input, and so can be easily applied to an evolving case-base or a changing environment. Experiments with a real tablet formulation problem show the gains of simultaneously optimising the index and similarity measure. Provided that the available data represents the problem domain well, the optimisation has good generalisation properties and the domain knowledge extracted is comparable to expert knowledge.},
  isbn = {978-3-540-44527-2},
  langid = {english}
}

@article{Jarvelin2002CumulatedGainbasedEvaluation,
  title = {Cumulated Gain-Based Evaluation of {{IR}} Techniques},
  author = {J{\"a}rvelin, Kalervo and Kek{\"a}l{\"a}inen, Jaana},
  year = {2002},
  month = oct,
  journal = {ACM Transactions on Information Systems},
  volume = {20},
  number = {4},
  pages = {422--446},
  issn = {1046-8188},
  doi = {10.1145/582415.582418},
  urldate = {2020-08-18},
  abstract = {Modern large retrieval environments tend to overwhelm their users by their large output. Since all documents are not of equal relevance to their users, highly relevant documents should be identified and ranked first for presentation. In order to develop IR techniques in this direction, it is necessary to develop evaluation approaches and methods that credit IR methods for their ability to retrieve highly relevant documents. This can be done by extending traditional evaluation methods, that is, recall and precision based on binary relevance judgments, to graded relevance judgments. Alternatively, novel measures based on graded relevance judgments may be developed. This article proposes several novel measures that compute the cumulative gain the user obtains by examining the retrieval result up to a given ranked position. The first one accumulates the relevance scores of retrieved documents along the ranked result list. The second one is similar but applies a discount factor to the relevance scores in order to devaluate late-retrieved documents. The third one computes the relative-to-the-ideal performance of IR techniques, based on the cumulative gain they are able to yield. These novel measures are defined and discussed and their use is demonstrated in a case study using TREC data: sample system run results for 20 queries in TREC-7. As a relevance base we used novel graded relevance judgments on a four-point scale. The test results indicate that the proposed measures credit IR methods for their ability to retrieve highly relevant documents and allow testing of statistical significance of effectiveness differences. The graphs based on the measures also provide insight into the performance IR techniques and allow interpretation, for example, from the user point of view.}
}

@misc{Jascob2020LemmInflect,
  title = {{{LemmInflect}}},
  author = {Jascob, Brad},
  year = {2020},
  urldate = {2021-03-09},
  abstract = {A python module for English lemmatization and inflection.},
  copyright = {MIT License         ,                 MIT License}
}

@article{Jelodar2019LatentDirichletAllocation,
  title = {Latent {{Dirichlet}} Allocation ({{LDA}}) and Topic Modeling: Models, Applications, a Survey},
  shorttitle = {Latent {{Dirichlet}} Allocation ({{LDA}}) and Topic Modeling},
  author = {Jelodar, Hamed and Wang, Yongli and Yuan, Chi and Feng, Xia and Jiang, Xiahui and Li, Yanchao and Zhao, Liang},
  year = {2019},
  month = jun,
  journal = {Multimedia Tools and Applications},
  volume = {78},
  number = {11},
  pages = {15169--15211},
  issn = {1573-7721},
  doi = {10.1007/s11042-018-6894-4},
  urldate = {2020-10-21},
  abstract = {Topic modeling is one of the most powerful techniques in text mining for data mining, latent data discovery, and finding relationships among data and text documents. Researchers have published many articles in the field of topic modeling and applied in various fields such as software engineering, political science, medical and linguistic science, etc. There are various methods for topic modelling; Latent Dirichlet Allocation (LDA) is one of the most popular in this field. Researchers have proposed various models based on the LDA in topic modeling. According to previous work, this paper will be very useful and valuable for introducing LDA approaches in topic modeling. In this paper, we investigated highly scholarly articles (between 2003 to 2016) related to topic modeling based on LDA to discover the research development, current trends and intellectual structure of topic modeling. In addition, we summarize challenges and introduce famous tools and datasets in topic modeling based on LDA.},
  langid = {english}
}

@inproceedings{Jiang2023LowResourceTextClassification,
  title = {``{{Low-Resource}}'' {{Text Classification}}: {{A Parameter-Free Classification Method}} with {{Compressors}}},
  shorttitle = {``{{Low-Resource}}'' {{Text Classification}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{ACL}} 2023},
  author = {Jiang, Zhiying and Yang, Matthew and Tsirlin, Mikhail and Tang, Raphael and Dai, Yiqin and Lin, Jimmy},
  year = {2023},
  month = jul,
  pages = {6810--6828},
  publisher = {Association for Computational Linguistics},
  address = {Toronto, Canada},
  doi = {10.18653/v1/2023.findings-acl.426},
  urldate = {2023-09-04},
  abstract = {Deep neural networks (DNNs) are often used for text classification due to their high accuracy. However, DNNs can be computationally intensive, requiring millions of parameters and large amounts of labeled data, which can make them expensive to use, to optimize, and to transfer to out-of-distribution (OOD) cases in practice. In this paper, we propose a non-parametric alternative to DNNs that's easy, lightweight, and universal in text classification: a combination of a simple compressor like gzip with a k-nearest-neighbor classifier. Without any training parameters, our method achieves results that are competitive with non-pretrained deep learning methods on six in-distribution datasets.It even outperforms BERT on all five OOD datasets, including four low-resource languages. Our method also excels in the few-shot setting, where labeled data are too scarce to train DNNs effectively.}
}

@inproceedings{Jimenez-Diaz2024VisualizationSimilarityModels,
  title = {Visualization of~{{Similarity Models}} for~{{CBR Comprehension}} and~{{Maintenance}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {{Jimenez-Diaz}, Guillermo and {D{\'i}az-Agudo}, Bel{\'e}n},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {67--80},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_5},
  abstract = {Modeling similarity measures in Case-Based Reasoning systems is a critical and multifaceted task. Typically, similarity measures are manually defined, often with the input of domain experts or utilizing machine learning methods. These measures are then subjected to evaluation processes that include metrics that assess the properties of the retrieval and reuse processes on the case base. In this paper, we present SimViz, an exploratory visualization tool aimed at understanding and identifying errors in both data and similarity measures. Our tool represents an instance of Explainable Case-Based Reasoning, enabling interactive visualization through heatmaps and histograms and assisting in case comparison. These visualizations provide insight into the similarity between local and global attributes across different case representations.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@misc{Jin2024LargeLanguageModels,
  title = {Large {{Language Models}} on {{Graphs}}: {{A Comprehensive Survey}}},
  shorttitle = {Large {{Language Models}} on {{Graphs}}},
  author = {Jin, Bowen and Liu, Gang and Han, Chi and Jiang, Meng and Ji, Heng and Han, Jiawei},
  year = {2024},
  month = feb,
  number = {arXiv:2312.02783},
  eprint = {2312.02783},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.02783},
  urldate = {2024-09-16},
  abstract = {Large language models (LLMs), such as GPT4 and LLaMA, are creating significant advancements in natural language processing, due to their strong text encoding/decoding ability and newly found emergent capability (e.g., reasoning). While LLMs are mainly designed to process pure texts, there are many real-world scenarios where text data is associated with rich structure information in the form of graphs (e.g., academic networks, and e-commerce networks) or scenarios where graph data is paired with rich textual information (e.g., molecules with descriptions). Besides, although LLMs have shown their pure text-based reasoning ability, it is underexplored whether such ability can be generalized to graphs (i.e., graph-based reasoning). In this paper, we provide a systematic review of scenarios and techniques related to large language models on graphs. We first summarize potential scenarios of adopting LLMs on graphs into three categories, namely pure graphs, text-attributed graphs, and text-paired graphs. We then discuss detailed techniques for utilizing LLMs on graphs, including LLM as Predictor, LLM as Encoder, and LLM as Aligner, and compare the advantages and disadvantages of different schools of models. Furthermore, we discuss the real-world applications of such methods and summarize open-source codes and benchmark datasets. Finally, we conclude with potential future research directions in this fast-growing field. The related source can be found at https://github.com/PeterGriffinJin/Awesome-Language-Model-on-Graphs.},
  archiveprefix = {arXiv}
}

@article{Jivani2011ComparativeStudyStemming,
  title = {A Comparative Study of Stemming Algorithms},
  author = {Jivani, Anjali Ganesh},
  year = {2011},
  month = dec,
  journal = {researchgate.net},
  abstract = {Stemming is a pre-processing step in Text Mining applications as well as a very common requirement of Natural Language processing functions. In fact it is very important in most of the Information Retrieval systems. The main purpose of stemming is to reduce different grammatical forms/word forms of a word like its noun, adjective, verb, adverb etc. to its root form. We can say that the goal of stemming is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. In this paper we have~{\dots}}
}

@inproceedings{Jo2019CascadeModelProposition,
  title = {A {{Cascade Model}} for {{Proposition Extraction}} in {{Argumentation}}},
  booktitle = {Proceedings of the 6th {{Workshop}} on {{Argument Mining}}},
  author = {Jo, Yohan and Visser, Jacky and Reed, Chris and Hovy, Eduard},
  year = {2019},
  month = aug,
  pages = {11--24},
  publisher = {Association for Computational Linguistics},
  address = {Florence, Italy},
  doi = {10.18653/v1/W19-4502},
  urldate = {2023-10-26},
  abstract = {We present a model to tackle a fundamental but understudied problem in computational argumentation: proposition extraction. Propositions are the basic units of an argument and the primary building blocks of most argument mining systems. However, they are usually substituted by argumentative discourse units obtained via surface-level text segmentation, which may yield text segments that lack semantic information necessary for subsequent argument mining processes. In contrast, our cascade model aims to extract complete propositions by handling anaphora resolution, text segmentation, reported speech, questions, imperatives, missing subjects, and revision. We formulate each task as a computational problem and test various models using a corpus of the 2016 U.S. presidential debates. We show promising performance for some tasks and discuss main challenges in proposition extraction.}
}

@article{Jo2021ClassifyingArgumentativeRelations,
  title = {Classifying {{Argumentative Relations Using Logical Mechanisms}} and {{Argumentation Schemes}}},
  author = {Jo, Yohan and Bang, Seojin and Reed, Chris and Hovy, Eduard},
  year = {2021},
  month = aug,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {9},
  pages = {721--739},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00394},
  urldate = {2022-01-13},
  abstract = {While argument mining has achieved significant success in classifying argumentative relations between statements (support, attack, and neutral), we have a limited computational understanding of logical mechanisms that constitute those relations. Most recent studies rely on black-box models, which are not as linguistically insightful as desired. On the other hand, earlier studies use rather simple lexical features, missing logical relations between statements. To overcome these limitations, our work classifies argumentative relations based on four logical and theory-informed mechanisms between two statements, namely, (i) factual consistency, (ii) sentiment coherence, (iii) causal relation, and (iv) normative relation. We demonstrate that our operationalization of these logical mechanisms classifies argumentative relations without directly training on data labeled with the relations, significantly better than several unsupervised baselines. We further demonstrate that these mechanisms also improve supervised classifiers through representation learning.}
}

@inproceedings{Joslyn2009MeasuringStructuralPreservation,
  title = {Measuring the Structural Preservation of Semantic Hierarchy Alignments},
  booktitle = {Proceedings of the 4th {{International Workshop}} on {{Ontology Matching}}. {{CEUR Workshop Proceedings}}},
  author = {Joslyn, Cliff A. and Paulson, Patrick and White, Amanda and Al Saffar, Sinan},
  year = {2009},
  volume = {551},
  pages = {61--72}
}

@inproceedings{Jouili2009AttributedGraphMatching,
  title = {Attributed {{Graph Matching Using Local Descriptions}}},
  booktitle = {Advanced {{Concepts}} for {{Intelligent Vision Systems}}},
  author = {Jouili, Salim and Mili, Ines and Tabbone, Salvatore},
  editor = {{Blanc-Talon}, Jacques and Philips, Wilfried and Popescu, Dan and Scheunders, Paul},
  year = {2009},
  pages = {89--99},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-04697-1_9},
  abstract = {In the pattern recognition context, objects can be represented as graphs with attributed nodes and edges involving their relations. Consequently, matching attributed graphs plays an important role in objects recognition. In this paper, a node signatures extraction is combined with an optimal assignment method for matching attributed graphs. In particular, we show how local descriptions are used to define a node-to-node cost in an assignment problem using the Hungarian method. Moreover, we propose a distance formula to compute the distance between attributed graphs. The experiments demonstrate that the newly presented algorithm is well-suited to pattern recognition applications. Compared with well-known methods, our algorithm gives good results for retrieving images.},
  isbn = {978-3-642-04697-1},
  langid = {english}
}

@article{Jursic2010LemmaGenMultilingualLemmatisation,
  title = {{{LemmaGen}}: {{Multilingual Lemmatisation}} with {{Induced Ripple-Down Rules}}},
  author = {Jur{\v s}i{\v c}, Matja{\v z} and Mozeti{\v c}, Igor and Erjavec, Toma{\v z} and Lavra{\v c}, Nada},
  year = {2010},
  month = may,
  journal = {Journal of Universal Computer Science},
  volume = {16},
  number = {9},
  pages = {1190--1214},
  doi = {10.3217/jucs-016-09-1190},
  abstract = {Lemmatisation is the process of finding the normalised forms of words appearing in text. It is a useful preprocessing step for a number of language engineering and text mining tasks, and especially important for languages with rich inflectional morphology. This paper presents a new lemmatisation system, LemmaGen, which was trained to generate accurate and efficient lemmatisers for twelve different languages. Its evaluation on the corresponding lexicons shows that LemmaGen outperforms the lemmatisers generated by two alternative approaches, RDR and CST, both in terms of accuracy and efficiency. To our knowledge, LemmaGen is the most efficient publicly available lemmatiser trained on large lexicons of multiple languages, whose learning engine can be retrained to effectively generate lemmatisers of other languages.}
}

@article{Kalfoglou2003OntologyMappingState,
  title = {Ontology Mapping: The State of the Art},
  shorttitle = {Ontology Mapping},
  author = {Kalfoglou, Yannis and Schorlemmer, Marco},
  year = {2003},
  month = jan,
  journal = {The Knowledge Engineering Review},
  volume = {18},
  number = {1},
  pages = {1--31},
  issn = {1469-8005, 0269-8889},
  doi = {10.1017/S0269888903000651},
  urldate = {2019-01-05},
  abstract = {Ontology mapping is seen as a solution provider in today's landscape of ontology research. As the number of ontologies that are made publicly available and accessible on the Web increases steadily, so does the need for applications to use them. A single ontology is no longer enough to support the tasks envisaged by a distributed environment like the Semantic Web. Multiple ontologies need to be accessed from several applications. Mapping could provide a common layer from which several ontologies could be accessed and hence could exchange information in semantically sound manners. Developing such mappings has been the focus of a variety of works originating from diverse communities over a number of years. In this article we comprehensively review and present these works. We also provide insights on the pragmatics of ontology mapping and elaborate on a theoretical approach for defining ontology mapping.},
  langid = {english}
}

@inproceedings{Kapllani2020EmpiricalAnalysisMaintainability,
  title = {An {{Empirical Analysis}} of the {{Maintainability Evolution}} of {{Open Source Systems}}},
  booktitle = {Open {{Source Systems}}},
  author = {Kapllani, Gerta and Khomyakov, Ilya and Mirgalimova, Ruzilya and Sillitti, Alberto},
  editor = {Ivanov, Vladimir and Kruglov, Artem and Masyagin, Sergey and Sillitti, Alberto and Succi, Giancarlo},
  year = {2020},
  series = {{{IFIP Advances}} in {{Information}} and {{Communication Technology}}},
  pages = {78--86},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-47240-5_8},
  abstract = {Maintainability is a key factor for the evolution of an open source system due to the highly distributed development teams that contribute to many projects. In the literature there are a number of different approaches that has been developed to evaluate the maintainability of a product but almost each method has been developed in an independent way without leveraging on the existing work and with almost no independent evaluation of the performance of the models. In most of the cases, the models are only validated through a limited set of projects only by the people that propose the specific approach. This paper is a first step towards a different direction focusing on the independent application of the existing models to popular open source projects.},
  isbn = {978-3-030-47240-5},
  langid = {english}
}

@article{Karami2020TwitterResearchSystematic,
  title = {Twitter and {{Research}}: {{A Systematic Literature Review Through Text Mining}}},
  shorttitle = {Twitter and {{Research}}},
  author = {Karami, Amir and Lundy, Morgan and Webb, Frank and Dwivedi, Yogesh K.},
  year = {2020},
  journal = {IEEE Access},
  volume = {8},
  pages = {67698--67717},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2983656},
  urldate = {2023-10-20},
  abstract = {Researchers have collected Twitter data to study a wide range of topics. This growing body of literature, however, has not yet been reviewed systematically to synthesize Twitter-related papers. The existing literature review papers have been limited by constraints of traditional methods to manually select and analyze samples of topically related papers. The goals of this retrospective study are to identify dominant topics of Twitter-based research, summarize the temporal trend of topics, and interpret the evolution of topics withing the last ten years. This study systematically mines a large number of Twitter-based studies to characterize the relevant literature by an efficient and effective approach. This study collected relevant papers from three databases and applied text mining and trend analysis to detect semantic patterns and explore the yearly development of research themes across a decade. We found 38 topics in more than 18,000 manuscripts published between 2006 and 2019. By quantifying temporal trends, this study found that while 23.7\% of topics did not show a significant trend (P = 0.05), 21\% of topics had increasing trends and 55.3\% of topics had decreasing trends that these hot and cold topics represent three categories: application, methodology, and technology. The contributions of this paper can be utilized in the growing field of Twitter-based research and are beneficial to researchers, educators, and publishers.}
}

@inproceedings{Kawarada2024ArgumentMiningTexttoText,
  title = {Argument {{Mining}} as a {{Text-to-Text Generation Task}}},
  booktitle = {Proceedings of the 18th {{Conference}} of the {{European Chapter}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Kawarada, Masayuki and Hirao, Tsutomu and Uchida, Wataru and Nagata, Masaaki},
  editor = {Graham, Yvette and Purver, Matthew},
  year = {2024},
  month = mar,
  pages = {2002--2014},
  publisher = {Association for Computational Linguistics},
  address = {St. Julian's, Malta},
  urldate = {2024-06-24},
  abstract = {Argument Mining (AM) aims to uncover the argumentative structures within a text. Previous methods require several subtasks, such as span identification, component classification, and relation classification. Consequently, these methods need rule-based postprocessing to derive argumentative structures from the output of each subtask. This approach adds to the complexity of the model and expands the search space of the hyperparameters. To address this difficulty, we propose a simple yet strong method based on a text-to-text generation approach using a pretrained encoder-decoder language model. Our method simultaneously generates argumentatively annotated text for spans, components, and relations, eliminating the need for task-specific postprocessing and hyperparameter tuning. Furthermore, because it is a straightforward text-to-text generation method, we can easily adapt our approach to various types of argumentative structures.Experimental results demonstrate the effectiveness of our method, as it achieves state-of-the-art performance on three different types of benchmark datasets: the Argument-annotated Essays Corpus (AAEC), AbstRCT, and the Cornell eRulemaking Corpus (CDCP).}
}

@inproceedings{Keane1994AnalogicalAsidesCasebased,
  title = {Analogical Asides on Case-Based Reasoning},
  booktitle = {Topics in {{Case-Based Reasoning}}},
  author = {Keane, Mark T.},
  editor = {Wess, Stefan and Althoff, Klaus-Dieter and Richter, Michael M.},
  year = {1994},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {21--32},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-58330-0_74},
  abstract = {This paper explores some of the similarities and differences between cognitive models of analogy and case-based reasoning systems. I first point out a paradox in the treatment of adaptation in analogy and in case-based reasoning; a paradox which can be only resolved by expanding the role of adaptation in cognitive models of analogy. Some psychological research on the process of adaptation in human subjects is reported and then the implications of this research are propagated into analogy and then on into CBR. The argument is that some of the existing stages in CBR should be integrated into a more stream-lined architecture that would be more efficient than current schemes.},
  isbn = {978-3-540-48655-8},
  langid = {english}
}

@article{Kelly2009MethodsEvaluatingInteractive,
  title = {Methods for {{Evaluating Interactive Information Retrieval Systems}} with {{Users}}},
  author = {Kelly, Diane},
  year = {2009},
  month = jan,
  journal = {Foundations and Trends in Information Retrieval},
  volume = {3},
  number = {1---2},
  pages = {1--224},
  issn = {1554-0669},
  doi = {10.1561/1500000012},
  urldate = {2020-08-18},
  abstract = {This paper provides overview and instruction regarding the evaluation of interactive information retrieval systems with users. The primary goal of this article is to catalog and compile material related to this topic into a single source. This article (1) provides historical background on the development of user-centered approaches to the evaluation of interactive information retrieval systems; (2) describes the major components of interactive information retrieval system evaluation; (3) describes different experimental designs and sampling strategies; (4) presents core instruments and data collection techniques and measures; (5) explains basic data analysis techniques; and (4) reviews and discusses previous studies. This article also discusses validity and reliability issues with respect to both measures and methods, presents background information on research ethics and discusses some ethical issues which are specific to studies of interactive information retrieval (IIR). Finally, this article concludes with a discussion of outstanding challenges and future research directions.}
}

@article{Kent1955MachineLiteratureSearching,
  title = {Machine Literature Searching {{VIII}}. {{Operational}} Criteria for Designing Information Retrieval Systems},
  author = {Kent, Allen and Berry, Madeline M and Luehrs, Fred U and Perry, J W},
  year = {1955},
  month = jan,
  journal = {American Documentation},
  volume = {6},
  number = {2},
  pages = {93--101},
  doi = {10.1002/asi.5090060209},
  urldate = {2018-09-01}
}

@inproceedings{Kenter2015ShortTextSimilarity,
  title = {Short {{Text Similarity}} with {{Word Embeddings}}},
  booktitle = {Proceedings of the 24th {{ACM International}} on {{Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Kenter, Tom and {de Rijke}, Maarten},
  year = {2015},
  month = oct,
  series = {{{CIKM}} '15},
  pages = {1411--1420},
  publisher = {ACM},
  address = {Melbourne, Australia},
  doi = {10.1145/2806416.2806475},
  abstract = {Determining semantic similarity between texts is important in many tasks in information retrieval such as search, query suggestion, automatic summarization and image finding. Many approaches have been suggested, based on lexical matching, handcrafted patterns, syntactic parse trees, external sources of structured semantic knowledge and distributional semantics. However, lexical features, like string matching, do not capture semantic similarity beyond a trivial level. Furthermore, handcrafted patterns and external sources of structured semantic knowledge cannot be assumed to be available in all circumstances and for all domains. Lastly, approaches depending on parse trees are restricted to syntactically well-formed texts, typically of one sentence in length. We investigate whether determining short text similarity is possible using only semantic features---where by semantic we mean, pertaining to a representation of meaning---rather than relying on similarity in lexical or syntactic representations. We use word embeddings, vector representations of terms, computed from unlabelled data, that represent terms in a semantic space in which proximity of vectors can be interpreted as semantic similarity. We propose to go from word-level to text-level semantics by combining insights from methods based on external sources of semantic knowledge with word embeddings. A novel feature of our approach is that an arbitrary number of word embedding sets can be incorporated. We derive multiple types of meta-features from the comparison of the word vectors for short text pairs, and from the vector means of their respective word embeddings. The features representing labelled short text pairs are used to train a supervised learning algorithm. We use the trained model at testing time to predict the semantic similarity of new, unlabelled pairs of short texts  We show on a publicly available evaluation set commonly used for the task of semantic similarity that our method outperforms baseline methods that work under the same conditions.},
  isbn = {978-1-4503-3794-6}
}

@inproceedings{Khartabil2016LargescaleArgumentVisualization,
  title = {Large-Scale {{Argument Visualization}} ({{LSAV}})},
  booktitle = {{{EuroVis}}},
  author = {Khartabil, D. and Wells, S. and Kennedy, J.},
  year = {2016},
  doi = {10.2312/eurp.20161143},
  abstract = {A tool for interacting with argument corpora is proposed that will help users to explore and understand the reasoning structure of large-scale arguments, to more rapidly comprehend complex new problem domains. Arguments are structures of premises and conclusions that underpin rational reasoning processes. Within complex knowledge domains, especially if they are contentious, argument structures can become large and complex. Visualization tools have been developed that support argument analysts and help them to work with arguments. Until recently, arguments were manually analyzed from natural language text, or constructed from scratch, but new communication modes mean that increasing amounts of debate and the arguments therein can be captured digitally. Furthermore, new tools and techniques for argument mining are beginning to automate the process of extracting argument structure from natural language; leading to much larger argument datasets that present problems for the current generation of argument visualization tools. Additionally, individual argument analysts have different foci which can lead to increased complexity within datasets, and additional facets that argument visualizations should account for but do not. We propose a tool for interacting with argument corpora that enable users to explore and understand the reasoning structure of large-scale arguments. The tool will support a range of interactivity techniques and will help users to explore and analyse large-scale arguments, to more rapidly comprehend complex new problem domains.}
}

@misc{Khattab2020ColBERTEfficientEffective,
  title = {{{ColBERT}}: {{Efficient}} and {{Effective Passage Search}} via {{Contextualized Late Interaction}} over {{BERT}}},
  shorttitle = {{{ColBERT}}},
  author = {Khattab, Omar and Zaharia, Matei},
  year = {2020},
  month = jun,
  number = {arXiv:2004.12832},
  eprint = {2004.12832},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2004.12832},
  urldate = {2024-10-23},
  abstract = {Recent progress in Natural Language Understanding (NLU) is driving fast-paced advances in Information Retrieval (IR), largely owed to fine-tuning deep language models (LMs) for document ranking. While remarkably effective, the ranking models based on these LMs increase computational cost by orders of magnitude over prior approaches, particularly as they must feed each query-document pair through a massive neural network to compute a single relevance score. To tackle this, we present ColBERT, a novel ranking model that adapts deep LMs (in particular, BERT) for efficient retrieval. ColBERT introduces a late interaction architecture that independently encodes the query and the document using BERT and then employs a cheap yet powerful interaction step that models their fine-grained similarity. By delaying and yet retaining this fine-granular interaction, ColBERT can leverage the expressiveness of deep LMs while simultaneously gaining the ability to pre-compute document representations offline, considerably speeding up query processing. Beyond reducing the cost of re-ranking the documents retrieved by a traditional model, ColBERT's pruning-friendly interaction mechanism enables leveraging vector-similarity indexes for end-to-end retrieval directly from a large document collection. We extensively evaluate ColBERT using two recent passage search datasets. Results show that ColBERT's effectiveness is competitive with existing BERT-based models (and outperforms every non-BERT baseline), while executing two orders-of-magnitude faster and requiring four orders-of-magnitude fewer FLOPs per query.},
  archiveprefix = {arXiv}
}

@misc{Khosravi2024RelationalGraphConvolutional,
  title = {Relational {{Graph Convolutional Networks}} for {{Sentiment Analysis}}},
  author = {Khosravi, Asal and Rahmati, Zahed and Vefghi, Ali},
  year = {2024},
  month = apr,
  number = {arXiv:2404.13079},
  eprint = {2404.13079},
  primaryclass = {cs},
  doi = {10.48550/arXiv.2404.13079},
  urldate = {2024-04-28},
  abstract = {With the growth of textual data across online platforms, sentiment analysis has become crucial for extracting insights from user-generated content. While traditional approaches and deep learning models have shown promise, they cannot often capture complex relationships between entities. In this paper, we propose leveraging Relational Graph Convolutional Networks (RGCNs) for sentiment analysis, which offer interpretability and flexibility by capturing dependencies between data points represented as nodes in a graph. We demonstrate the effectiveness of our approach by using pre-trained language models such as BERT and RoBERTa with RGCN architecture on product reviews from Amazon and Digikala datasets and evaluating the results. Our experiments highlight the effectiveness of RGCNs in capturing relational information for sentiment analysis tasks.},
  archiveprefix = {arXiv}
}

@article{Kim2015CharacterAwareNeuralLanguage,
  title = {Character-{{Aware Neural Language Models}}},
  author = {Kim, Yoon and Jernite, Yacine and Sontag, David and Rush, Alexander M.},
  year = {2015},
  month = aug,
  journal = {arXiv:1508.06615 [cs, stat]},
  eprint = {1508.06615},
  primaryclass = {cs, stat},
  abstract = {We describe a simple neural language model that relies only on character-level inputs. Predictions are still made at the word-level. Our model employs a convolutional neural network (CNN) and a highway network over characters, whose output is given to a long short-term memory (LSTM) recurrent neural network language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60\% fewer parameters. On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model outperforms word-level/morpheme-level LSTM baselines, again with fewer parameters. The results suggest that on many languages, character inputs are sufficient for language modeling. Analysis of word representations obtained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information.},
  archiveprefix = {arXiv}
}

@inproceedings{Kirschner2015LinkingThoughtsAnalysis,
  title = {Linking the {{Thoughts}}: {{Analysis}} of {{Argumentation Structures}} in {{Scientific Publications}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}} Held in Conjunction with the 2015 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}} -- {{Human Language Technologies}}},
  author = {Kirschner, Christian and {Eckle-Kohler}, Judith and Gurevych, Iryna},
  year = {2015},
  month = jun,
  pages = {1--11},
  doi = {10.3115/v1/W15-0501},
  urldate = {2018-09-02}
}

@inproceedings{Klein2019LearningWorkflowEmbeddings,
  title = {Learning {{Workflow Embeddings}} to {{Improve}} the {{Performance}} of {{Similarity-Based Retrieval}} for {{Process-Oriented Case-Based Reasoning}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Klein, Patrick and Malburg, Lukas and Bergmann, Ralph},
  editor = {Bach, Kerstin and Marling, Cindy},
  year = {2019},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {188--203},
  publisher = {Springer International Publishing},
  abstract = {In process-oriented case-based reasoning, similarity-based retrieval of workflow cases from large case bases is still a difficult issue due to the computationally expensive similarity assessment. The two-phase MAC/FAC (``Many are called, but few are chosen'') retrieval has been proven useful to reduce the retrieval time but comes at the cost of an additional modeling effort for implementing the MAC phase. In this paper, we present a new approach to implement the MAC phase for POCBR retrieval, which makes use of the StarSpace embedding algorithm to automatically learn a vector representation for workflows, which can be used to significantly speed-up the MAC retrieval phase. In an experimental evaluation in the domain of cooking workflows, we show that the presented approach outperforms two existing MAC/FAC approaches on the same data.},
  isbn = {978-3-030-29249-2},
  langid = {english}
}

@misc{Kluge2013AnnotationGuidelines,
  title = {Annotation {{Guidelines}}},
  author = {Kluge, Roland},
  year = {2013},
  month = dec
}

@inproceedings{Knaebel2024ImpactArgumentArrangement,
  title = {The {{Impact}} of~{{Argument Arrangement}} on~{{Essay Scoring}}},
  booktitle = {Robust {{Argumentation Machines}}},
  author = {Knaebel, Ren{\'e} and Schaefer, Robin and Stede, Manfred},
  editor = {Cimiano, Philipp and Frank, Anette and Kohlhase, Michael and Stein, Benno},
  year = {2024},
  pages = {147--162},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63536-6_9},
  abstract = {We study the question to what extent the task of predicting the quality of student essays can be supported with computing ``flows'' of semantic types of argumentative units. Specifically, we use tagsets for claim and premise types that were recently applied to the Argument Annotated Essays corpus (AAE; Stab/Gurevych 2017) by Schaefer et al (2023). We train argument component and semantic type classification models on AAE and then use them to label the essays in two corpora that have numeric essay ratings, viz. FEEDBACK/PERSUADE and ICLE. We train linear classification models on flow features and find that flows of our semantic types are a better predictor for essay quality (in a simplified, good/bad dichotomy) than flows of coarse argument components (major claim, claim, premise). Finally, we calculate feature impact and perform a qualitative inspection, which shows some tendencies for pattern occurrence in the two essay classes.},
  isbn = {978-3-031-63536-6},
  langid = {english}
}

@article{Knowles2004NotionLemmaHeadwords,
  title = {The Notion of a ``Lemma'': {{Headwords}}, Roots and Lexical Sets},
  shorttitle = {The Notion of a ``Lemma''},
  author = {Knowles, Gerry and Don, Zuraidah Mohd},
  year = {2004},
  month = jan,
  journal = {International Journal of Corpus Linguistics},
  volume = {9},
  number = {1},
  pages = {69--81},
  publisher = {John Benjamins},
  issn = {1384-6655, 1569-9811},
  doi = {10.1075/ijcl.9.1.04kno},
  urldate = {2021-03-08},
  abstract = {The notion of alemmais so familiar in corpus linguistics that it scarcely needs a formal definition. When a wordlist or a text is lemmatised, the process is apparently transparent, so that any observer can understand how the lemma relates to the original set or string of words. We shall argue in this paper that, on the contrary, the concept of lemma is not well defined, and is in need of a clear formal definition. The lemma is a fundamental concept in the processing of texts in at least some languages, a point we shall illustrate with respect to Arabic and Malay. It so happens that English lemmas are not typical of the general category, so that linguists who base their understanding of the lemma on English obtain a distorted view. It is essential to reverse the direction of argument, and to start with a general understanding of the lemma, and to consider English lemmas in the wider context.},
  langid = {english}
}

@inproceedings{Kobbe2019ExploitingBackgroundKnowledge,
  title = {Exploiting {{Background Knowledge}} for {{Argumentative Relation Classification}}},
  booktitle = {Proceesings of the 2nd {{Conference}} on {{Language}}, {{Data}} and {{Knowledge}} ({{LDK}} 2019)},
  author = {Kobbe, Jonathan and Opitz, Juri and Becker, Maria and Hulpus, Ioana and Stuckenschmidt, Heiner and Frank, Anette},
  year = {2019},
  pages = {14},
  address = {Dagstuhl, Germany},
  doi = {10.4230/OASICS.LDK.2019.8},
  urldate = {2020-05-11},
  abstract = {Argumentative relation classification is the task of determining the type of relation (e.g., support or attack) that holds between two argument units. Current state-of-the-art models primarily exploit surface-linguistic features including discourse markers, modals or adverbials to classify argumentative relations. However, a system that performs argument analysis using mainly rhetorical features can be easily fooled by the stylistic presentation of the argument as opposed to its content, in cases where a weak argument is concealed by strong rhetorical means. This paper explores the difficulties and the potential effectiveness of knowledge-enhanced argument analysis, with the aim of advancing the state-of-the-art in argument analysis towards a deeper, knowledge-based understanding and representation of arguments. We propose an argumentative relation classification system that employs linguistic as well as knowledge-based features, and investigate the effects of injecting background knowledge into a neural baseline model for argumentative relation classification. Starting from a Siamese neural network that classifies pairs of argument units into support vs. attack relations, we extend this system with a set of features that encode a variety of features extracted from two complementary background knowledge resources: ConceptNet and DBpedia. We evaluate our systems on three different datasets and show that the inclusion of background knowledge can improve the classification performance by considerable margins. Thus, our work offers a first step towards effective, knowledge-rich argument analysis.},
  copyright = {Creative Commons Attribution 3.0 Unported license (CC-BY 3.0)},
  langid = {english}
}

@inproceedings{Kobbe2020UnsupervisedStanceDetection,
  title = {Unsupervised Stance Detection for Arguments from Consequences},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Kobbe, Jonathan and Hulpu{\textbackslash}textcommabelows, Ioana and Stuckenschmidt, Heiner},
  year = {2020},
  month = nov,
  pages = {50--60},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  doi = {10.18653/v1/2020.emnlp-main.4},
  urldate = {2022-01-14},
  abstract = {Social media platforms have become an essential venue for online deliberation where users discuss arguments, debate, and form opinions. In this paper, we propose an unsupervised method to detect the stance of argumentative claims with respect to a topic. Most related work focuses on topic-specific supervised models that need to be trained for every emergent debate topic. To address this limitation, we propose a topic independent approach that focuses on a frequently encountered class of arguments, specifically, on arguments from consequences. We do this by extracting the effects that claims refer to, and proposing a means for inferring if the effect is a good or bad consequence. Our experiments provide promising results that are comparable to, and in particular regards even outperform BERT. Furthermore, we publish a novel dataset of arguments relating to consequences, annotated with Amazon Mechanical Turk.}
}

@inproceedings{Koehn2005EuroparlParallelCorpus,
  title = {Europarl: {{A}} Parallel Corpus for Statistical Machine Translation},
  booktitle = {Proceedings of the Tenth {{Machine Translation Summit}}},
  author = {Koehn, Philipp},
  year = {2005},
  month = jan,
  pages = {79--86},
  urldate = {2018-09-01},
  abstract = {For this project you will build a na{\"i}ve Bayesian classifier which is able to classify text fragments according to their language. Determining the language of a document may seem trivial, since the most common few words in each language---or the character set it uses--- could be thought of as an identifying signature. But we would like to use a more principled approach that quantitatively scores the probability of some fragment of text being written in one language, relative to others.}
}

@misc{Koleva2024WikiTabNERAdvancingTable,
  title = {Wiki-{{TabNER}}: {{Advancing Table Interpretation Through Named Entity Recognition}}},
  shorttitle = {Wiki-{{TabNER}}},
  author = {Koleva, Aneta and Ringsquandl, Martin and Hatem, Ahmed and Runkler, Thomas and Tresp, Volker},
  year = {2024},
  month = mar,
  number = {arXiv:2403.04577},
  eprint = {2403.04577},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.04577},
  urldate = {2024-06-15},
  abstract = {Web tables contain a large amount of valuable knowledge and have inspired tabular language models aimed at tackling table interpretation (TI) tasks. In this paper, we analyse a widely used benchmark dataset for evaluation of TI tasks, particularly focusing on the entity linking task. Our analysis reveals that this dataset is overly simplified, potentially reducing its effectiveness for thorough evaluation and failing to accurately represent tables as they appear in the real-world. To overcome this drawback, we construct and annotate a new more challenging dataset. In addition to introducing the new dataset, we also introduce a novel problem aimed at addressing the entity linking task: named entity recognition within cells. Finally, we propose a prompting framework for evaluating the newly developed large language models (LLMs) on this novel TI task. We conduct experiments on prompting LLMs under various settings, where we use both random and similarity-based selection to choose the examples presented to the models. Our ablation study helps us gain insights into the impact of the few-shot examples. Additionally, we perform qualitative analysis to gain insights into the challenges encountered by the models and to understand the limitations of the proposed dataset.},
  archiveprefix = {arXiv}
}

@inproceedings{Koncel-Kedziorski2019TextGenerationKnowledge,
  title = {Text {{Generation}} from {{Knowledge Graphs}} with {{Graph Transformers}}},
  booktitle = {Proceedings of the 2019 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}, {{Volume}} 1 ({{Long}} and {{Short Papers}})},
  author = {{Koncel-Kedziorski}, Rik and Bekal, Dhanush and Luan, Yi and Lapata, Mirella and Hajishirzi, Hannaneh},
  year = {2019},
  month = jun,
  pages = {2284--2293},
  publisher = {Association for Computational Linguistics},
  address = {Minneapolis, Minnesota},
  doi = {10.18653/v1/N19-1238},
  urldate = {2020-10-16},
  abstract = {Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.}
}

@article{Korman2018DefiningTextualEntailment,
  title = {Defining Textual Entailment},
  author = {Korman, Daniel Z. and Mack, Eric and Jett, Jacob and Renear, Allen H.},
  year = {2018},
  journal = {Journal of the Association for Information Science and Technology},
  volume = {69},
  number = {6},
  pages = {763--772},
  issn = {2330-1643},
  doi = {10.1002/asi.24007},
  urldate = {2020-08-13},
  abstract = {Textual entailment is a relationship that obtains between fragments of text when one fragment in some sense implies the other fragment. The automation of textual entailment recognition supports a wide variety of text-based tasks, including information retrieval, information extraction, question answering, text summarization, and machine translation. Much ingenuity has been devoted to developing algorithms for identifying textual entailments, but relatively little to saying what textual entailment actually is. This article is a review of the logical and philosophical issues involved in providing an adequate definition of textual entailment. We show that many natural definitions of textual entailment are refuted by counterexamples, including the most widely cited definition of Dagan et al. We then articulate and defend the following revised definition: T textually entails H = df typically, a human reading T would be justified in inferring the proposition expressed by H from the proposition expressed by T. We also show that textual entailment is context-sensitive, nontransitive, and nonmonotonic.},
  copyright = {{\copyright} 2018 ASIS\&T},
  langid = {english}
}

@inproceedings{Kourani2024ProcessModelingLarge,
  title = {Process {{Modeling}} with~{{Large Language Models}}},
  booktitle = {Enterprise, {{Business-Process}} and {{Information Systems Modeling}}},
  author = {Kourani, Humam and Berti, Alessandro and Schuster, Daniel and {van der Aalst}, Wil M. P.},
  editor = {{van der Aa}, Han and Bork, Dominik and Schmidt, Rainer and Sturm, Arnon},
  year = {2024},
  pages = {229--244},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-61007-3_18},
  abstract = {In the realm of Business Process Management (BPM), process modeling plays a crucial role in translating complex process dynamics into comprehensible visual representations, facilitating the understanding, analysis, improvement, and automation of organizational processes. Traditional process modeling methods often require extensive expertise and can be time-consuming. This paper explores the integration of Large Language Models (LLMs) into process modeling to enhance the accessibility of process modeling, offering a more intuitive entry point for non-experts while augmenting the efficiency of experts. We propose a framework that leverages LLMs for the automated generation and iterative refinement of process models starting from textual descriptions. Our framework involves innovative prompting strategies for effective LLM utilization, along with a secure model generation protocol and an error-handling mechanism. Moreover, we instantiate a concrete system extending our framework. This system provides robust quality guarantees on the models generated and supports exporting them in standard modeling notations, such as the Business Process Modeling Notation (BPMN) and Petri nets. Preliminary results demonstrate the framework's ability to streamline process modeling tasks, underscoring the transformative potential of generative AI in the BPM field.},
  isbn = {978-3-031-61007-3},
  langid = {english}
}

@inproceedings{Koutra2011AlgorithmsGraphSimilarity,
  title = {Algorithms for Graph Similarity and Subgraph Matching},
  booktitle = {Proc. {{Ecol}}. {{Inference Conf}}.},
  author = {Koutra, Danai and Parikh, Ankur and Ramdas, Aaditya and Xiang, Jing},
  year = {2011},
  urldate = {2018-09-04}
}

@article{Kpodjedo2014UsingLocalSimilarity,
  title = {Using Local Similarity Measures to Efficiently Address Approximate Graph Matching},
  author = {Kpodjedo, Segla and Galinier, Philippe and Antoniol, Giulio},
  year = {2014},
  month = feb,
  journal = {Discrete Applied Mathematics},
  series = {Combinatorial {{Optimization}}},
  volume = {164},
  pages = {161--177},
  issn = {0166-218X},
  doi = {10.1016/j.dam.2012.01.019},
  urldate = {2024-11-11},
  abstract = {In this paper, we investigate heuristics for Approximate Graph Matching (AGM), in particular when it can be formulated as a Maximum Common Edge Subgraph (MCES) problem. First, we observe empirically that initializing a local search with a tiny subset of a known optimal solution always results in much better solutions than starting with an empty solution. The main challenge could then be to retrieve such small subsets for any problem instance. For this purpose, we propose several local similarity measures and evaluate their ability to predict node matches which could be used to start a local search. The resulting algorithm (SIM-T) is a classic tabu algorithm that is initialized by a greedy procedure relying mainly, in its earliest steps, on similarity measures. We conducted experiments on a large collection of random graphs of various orders (from 50 to 3000 nodes) and densities. Results obtained are mostly excellent, especially on similar pairs of labeled graphs. Comparisons made with two recent state-of-the-art algorithms--``BP'' and ``PATH''--indicate a superiority of our approach, in terms of both scores and computation times.}
}

@article{Kreutz2022SchenQLIndepthAnalysis,
  title = {{{SchenQL}}: In-Depth Analysis of a Query Language for Bibliographic Metadata},
  shorttitle = {{{SchenQL}}},
  author = {Kreutz, Christin Katharina and Wolz, Michael and Knack, Jascha and Weyers, Benjamin and Schenkel, Ralf},
  year = {2022},
  month = jun,
  journal = {International Journal on Digital Libraries},
  volume = {23},
  number = {2},
  pages = {113--132},
  issn = {1432-1300},
  doi = {10.1007/s00799-021-00317-8},
  urldate = {2024-02-01},
  abstract = {Information access to bibliographic metadata needs to be uncomplicated, as users may not benefit from complex and potentially richer data that may be difficult to obtain. Sophisticated research questions including complex aggregations could be answered with complex SQL queries. However, this comes with the cost of high complexity, which requires for a high level of expertise even for trained programmers. A domain-specific query language could provide a straightforward solution to this problem. Although less generic, it can support users not familiar with query construction in the formulation of complex information needs. In this paper, we present and evaluate SchenQL, a simple and applicable query language that is accompanied by a prototypical GUI. SchenQL focuses on querying bibliographic metadata using the vocabulary of domain experts. The easy-to-learn domain-specific query language is suitable for domain experts as well as casual users while still providing the possibility to answer complex information demands. Query construction and information exploration are supported by a prototypical GUI. We present an evaluation of the complete system: different variants for executing SchenQL queries are benchmarked; interviews with domain-experts and a bipartite quantitative user study demonstrate SchenQL's suitability and high level of users' acceptance.},
  langid = {english}
}

@inproceedings{Kreutz2022SchenQLQueryLanguage,
  title = {{{SchenQL}}: A Query Language for Bibliographic Data with Aggregations and Domain-Specific Functions},
  shorttitle = {{{SchenQL}}},
  booktitle = {Proceedings of the 22nd {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}}},
  author = {Kreutz, Christin Katharina and Blum, Martin and Schenkel, Ralf},
  year = {2022},
  month = jun,
  series = {{{JCDL}} '22},
  pages = {1--5},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3529372.3533282},
  urldate = {2024-02-01},
  abstract = {Current search interfaces of digital libraries are not suitable to satisfy complex or convoluted information needs directly, when it comes to cases such as "Find authors who only recently started working on a topic". They might offer possibilities to obtain this information only by requiring vast user interaction. We present SchenQL, a web interface of a domain-specific query language on bibliographic metadata, which offers information search and exploration by query formulation and navigation in the system. Our system focuses on supporting aggregation of data and providing specialised domain dependent functions while being suitable for domain experts as well as casual users of digital libraries.},
  isbn = {978-1-4503-9345-4}
}

@article{Krippendorff2004ReliabilityContentAnalysis,
  title = {Reliability in {{Content Analysis}}: {{Some Common Misconceptions}} and {{Recommendations}}},
  shorttitle = {Reliability in {{Content Analysis}}},
  author = {Krippendorff, Klaus},
  year = {2004},
  month = jul,
  journal = {Human Communication Research},
  volume = {30},
  number = {3},
  pages = {411--433},
  issn = {0360-3989},
  doi = {10.1111/j.1468-2958.2004.tb00738.x},
  urldate = {2021-03-12},
  abstract = {In a recent article in this journal, Lombard, Snyder-Duch, and Bracken (2002) surveyed 200 content analyses for their reporting of reliability tests, compared the virtues and drawbacks of five popular reliability measures, and proposed guidelines and standards for their use. Their discussion revealed that numerous misconceptions circulate in the content analysis literature regarding how these measures behave and can aid or deceive content analysts in their effort to ensure the reliability of their data. This article proposes three conditions for statistical measures to serve as indices of the reliability of data and examines the mathematical structure and the behavior of the five coefficients discussed by the authors, as well as two others. It compares common beliefs about these coefficients with what they actually do and concludes with alternative recommendations for testing reliability in content analysis and similar data-making efforts.}
}

@book{Krippendorff2018ContentAnalysisIntroduction,
  title = {Content Analysis: {{An}} Introduction to Its Methodology},
  shorttitle = {Content Analysis},
  author = {Krippendorff, Klaus},
  year = {2018},
  publisher = {Sage publications},
  abstract = {What matters in people's social lives? What motivates and inspires our society? How do we  enact what we know? Since the first edition published in 1980, Content Analysis has helped  shape and define the field. In the highly anticipated Fourth Edition, award-winning scholar and author Klaus Krippendorff introduces you to the most current method of analyzing the textual fabric of contemporary society. Students and scholars will learn to treat data not as physical events but as communications that are created and disseminated to be seen.}
}

@article{Kudenko2014SpecialIssueTransfer,
  title = {Special {{Issue}} on {{Transfer Learning}}},
  author = {Kudenko, Daniel},
  year = {2014},
  month = feb,
  journal = {KI - K{\"u}nstliche Intelligenz},
  volume = {28},
  number = {1},
  pages = {5--6},
  issn = {1610-1987},
  doi = {10.1007/s13218-013-0289-5},
  urldate = {2020-09-29},
  langid = {english}
}

@inproceedings{Kuo2010BridgingCommonSense,
  title = {Bridging Common Sense Knowledge Bases with Analogy by Graph Similarity},
  booktitle = {Proceedings of the 2nd {{AAAI Conference}} on {{Collaboratively-Built Knowledge Sources}} and {{Artificial Intelligence}}},
  author = {Kuo, Yen-Ling and Hsu, Jane Yung-Jen},
  year = {2010},
  month = jan,
  series = {{{AAAIWS}}'10-02},
  pages = {22--27},
  publisher = {AAAI Press},
  urldate = {2020-08-03},
  abstract = {Present-day programs are brittle as computers are notoriously lacking in common sense. While significant progress has been made in building large common sense knowledge bases, they are intrinsically incomplete and inconsistent. This paper presents a novel approach to bridging the gaps between multiple knowledge bases, making it possible to answer queries based on knowledge collected from multiple sources without a common ontology. New assertions are found by computing graph similarity with principle component analysis to draw analogies across multiple knowledge bases. Experiments are designed to find new assertions for a Chinese commonsense knowledge base using the OMCS ConceptNet and similarly for WordNet. The assertions are voted by online users to verify that 75.77\% / 77.59\% for Chinese ConceptNet / WordNet respectively are good, despite the low overlap in coverage among the knowledge bases.}
}

@inproceedings{Kusner2015WordEmbeddingsDocument,
  title = {From {{Word Embeddings To Document Distances}}},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Machine Learning}}, {{ICML}} 2015, {{Lille}}, {{France}}, 6-11 {{July}} 2015},
  author = {Kusner, Matt J and Sun, Yu and Kolkin, Nicholas I and Weinberger, Kilian Q},
  year = {2015},
  month = jan,
  pages = {957--966},
  urldate = {2018-09-01},
  abstract = {We present the Word Mover's Distance (WMD), a novel distance function between text documents. Our work is based on recent results in word embeddings that learn semantically meaningful representatio...}
}

@article{Landis1977MeasurementObserverAgreement,
  title = {The {{Measurement}} of {{Observer Agreement}} for {{Categorical Data}}},
  author = {Landis, J. Richard and Koch, Gary G.},
  year = {1977},
  journal = {Biometrics},
  volume = {33},
  number = {1},
  eprint = {2529310},
  eprinttype = {jstor},
  pages = {159--174},
  publisher = {[Wiley, International Biometric Society]},
  issn = {0006-341X},
  doi = {10.2307/2529310},
  urldate = {2021-03-12},
  abstract = {This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.}
}

@article{Lao2010RelationalRetrievalUsing,
  title = {Relational Retrieval Using a Combination of~Path-Constrained Random Walks},
  author = {Lao, Ni and Cohen, William W.},
  year = {2010},
  month = oct,
  journal = {Machine Learning},
  volume = {81},
  number = {1},
  pages = {53--67},
  issn = {1573-0565},
  doi = {10.1007/s10994-010-5205-8},
  urldate = {2020-06-16},
  abstract = {Scientific literature with rich metadata can be represented as a labeled directed graph. This graph representation enables a number of scientific tasks such as ad hoc retrieval or named entity recognition (NER) to be formulated as typed proximity queries in the graph. One popular proximity measure is called Random Walk with Restart (RWR), and much work has been done on the supervised learning of RWR measures by associating each edge label with a parameter. In this paper, we describe a novel learnable proximity measure which instead uses one weight per edge label sequence: proximity is defined by a weighted combination of simple ``path experts'', each corresponding to following a particular sequence of labeled edges. Experiments on eight tasks in two subdomains of biology show that the new learning method significantly outperforms the RWR model (both trained and untrained). We also extend the method to support two additional types of experts to model intrinsic properties of entities: query-independent experts, which generalize the PageRank measure, and popular entity experts which allow rankings to be adjusted for particular entities that are especially important.},
  langid = {english}
}

@inproceedings{Lawrence2015CombiningArgumentMining,
  title = {Combining {{Argument Mining Techniques}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  author = {Lawrence, John and Reed, Chris},
  year = {2015},
  month = jun,
  pages = {127--136},
  publisher = {Association for Computational Linguistics},
  address = {Denver, CO},
  doi = {10.3115/v1/W15-0516},
  urldate = {2019-08-20}
}

@article{Lawrence2016ArgumentMiningUsing,
  title = {Argument {{Mining Using Argumentation Scheme Structures}}},
  author = {Lawrence, John and Reed, Chris},
  year = {2016},
  journal = {Frontiers in Artificial Intelligence and Applications},
  pages = {379--390},
  issn = {0922-6389},
  doi = {10.3233/978-1-61499-686-6-379},
  urldate = {2019-08-20},
  abstract = {Argumentation schemes are patterns of human reasoning which have been detailed extensively in philosophy and psychology. In this paper we demonstrate that the structure of such schemes can provide rich information to the task of automatically identify complex argumentative structures in natural language text. By training a range of classifiers to identify the individual proposition types which occur in these schemes, it is possible not only to determine where a scheme is being used, but also the roles played by its component parts. Furthermore, this task can be performed on segmented natural language, with no prior knowledge of the text's argumentative structure.},
  copyright = {{\copyright}2016 \&copy; The authors and IOS Press.},
  langid = {english}
}

@inproceedings{Lawrence2017MiningArgumentativeStructure,
  title = {Mining {{Argumentative Structure}} from {{Natural Language}} Text Using {{Automatically Generated Premise-Conclusion Topic Models}}},
  booktitle = {Proceedings of the 4th {{Workshop}} on {{Argument Mining}}},
  author = {Lawrence, John and Reed, Chris},
  year = {2017},
  month = sep,
  pages = {39--48},
  publisher = {Association for Computational Linguistics},
  address = {Copenhagen, Denmark},
  doi = {10.18653/v1/W17-5105},
  urldate = {2019-08-20},
  abstract = {This paper presents a method of extracting argumentative structure from natural language text. The approach presented is based on the way in which we understand an argument being made, not just from the words said, but from existing contextual knowledge and understanding of the broader issues. We leverage high-precision, low-recall techniques in order to automatically build a large corpus of inferential statements related to the text's topic. These statements are then used to produce a matrix representing the inferential relationship between different aspects of the topic. From this matrix, we are able to determine connectedness and directionality of inference between statements in the original text. By following this approach, we obtain results that compare favourably to those of other similar techniques to classify premise-conclusion pairs (with results 22 points above baseline), but without the requirement of large volumes of annotated, domain specific data.}
}

@article{Lawrence2019ArgumentMiningSurvey,
  title = {Argument {{Mining}}: {{A Survey}}},
  shorttitle = {Argument {{Mining}}},
  author = {Lawrence, John and Reed, Chris},
  year = {2019},
  month = oct,
  journal = {Computational Linguistics},
  volume = {45},
  number = {4},
  pages = {765--818},
  publisher = {MIT Press},
  issn = {0891-2017},
  doi = {10.1162/coli_a_00364},
  urldate = {2020-08-12},
  abstract = {Argument mining is the automatic identification and extraction of the structure of inference and reasoning expressed as arguments presented in natural language. Understanding argumentative structure makes it possible to determine not only what positions people are adopting, but also why they hold the opinions they do, providing valuable insights in domains as diverse as financial market prediction and public relations. This survey explores the techniques that establish the foundations for argument mining, provides a review of recent advances in argument mining techniques, and discusses the challenges faced in automatically extracting a deeper understanding of reasoning expressed in language in general.}
}

@inproceedings{Lawrence2019OnlineAnnotationAssistant,
  title = {An {{Online Annotation Assistant}} for {{Argument Schemes}}},
  booktitle = {Proceedings of the 13th {{Linguistic Annotation Workshop}}},
  author = {Lawrence, John and Visser, Jacky and Reed, Chris},
  year = {2019},
  month = aug,
  pages = {100--107},
  publisher = {Association for Computational Linguistics},
  address = {Florence, Italy},
  doi = {10.18653/v1/W19-4012},
  urldate = {2022-04-21},
  abstract = {Understanding the inferential principles underpinning an argument is essential to the proper interpretation and evaluation of persuasive discourse. Argument schemes capture the conventional patterns of reasoning appealed to in persuasion. The empirical study of these patterns relies on the availability of data about the actual use of argumentation in communicative practice. Annotated corpora of argument schemes, however, are scarce, small, and unrepresentative. Aiming to address this issue, we present one step in the development of improved datasets by integrating the Argument Scheme Key -- a novel annotation method based on one of the most popular typologies of argument schemes -- into the widely used OVA software for argument analysis.}
}

@misc{LCMTeam2024LargeConceptModels,
  title = {Large {{Concept Models}}: {{Language Modeling}} in a {{Sentence Representation Space}}},
  shorttitle = {Large {{Concept Models}}},
  author = {{LCM Team} and Barrault, Lo{\"i}c and Duquenne, Paul-Ambroise and Elbayad, Maha and Kozhevnikov, Artyom and Alastruey, Belen and Andrews, Pierre and Coria, Mariano and Couairon, Guillaume and {Costa-juss{\`a}}, Marta R. and Dale, David and Elsahar, Hady and Heffernan, Kevin and Janeiro, Jo{\~a}o Maria and Tran, Tuan and Ropers, Christophe and S{\'a}nchez, Eduardo and Roman, Robin San and Mourachko, Alexandre and Saleem, Safiyyah and Schwenk, Holger},
  year = {2024},
  month = dec,
  number = {arXiv:2412.08821},
  eprint = {2412.08821},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.08821},
  urldate = {2025-01-02},
  abstract = {LLMs have revolutionized the field of artificial intelligence and have emerged as the de-facto tool for many tasks. The current established technology of LLMs is to process input and generate output at the token level. This is in sharp contrast to humans who operate at multiple levels of abstraction, well beyond single words, to analyze information and to generate creative content. In this paper, we present an attempt at an architecture which operates on an explicit higher-level semantic representation, which we name a concept. Concepts are language- and modality-agnostic and represent a higher level idea or action in a flow. Hence, we build a "Large Concept Model". In this study, as proof of feasibility, we assume that a concept corresponds to a sentence, and use an existing sentence embedding space, SONAR, which supports up to 200 languages in both text and speech modalities. The Large Concept Model is trained to perform autoregressive sentence prediction in an embedding space. We explore multiple approaches, namely MSE regression, variants of diffusion-based generation, and models operating in a quantized SONAR space. These explorations are performed using 1.6B parameter models and training data in the order of 1.3T tokens. We then scale one architecture to a model size of 7B parameters and training data of about 2.7T tokens. We perform an experimental evaluation on several generative tasks, namely summarization and a new task of summary expansion. Finally, we show that our model exhibits impressive zero-shot generalization performance to many languages, outperforming existing LLMs of the same size. The training code of our models is freely available.},
  archiveprefix = {arXiv}
}

@inproceedings{Leake2011HowManyCases,
  title = {How {{Many Cases Do You Need}}? {{Assessing}} and {{Predicting Case-Base Coverage}}},
  shorttitle = {How {{Many Cases Do You Need}}?},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Leake, David and Wilson, Mark},
  year = {2011},
  month = sep,
  pages = {92--106},
  publisher = {Springer, Berlin, Heidelberg},
  doi = {10.1007/978-3-642-23291-6_9},
  urldate = {2021-05-27},
  abstract = {Case acquisition is the primary learning method for case-based reasoning (CBR), and the ability of a CBR system's case-base to cover the problems it encounters is a crucial factor in its performance....},
  langid = {english}
}

@inproceedings{Leake2019CombiningCaseAdaptation,
  title = {On {{Combining Case Adaptation Rules}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Leake, David and Ye, Xiaomeng},
  editor = {Bach, Kerstin and Marling, Cindy},
  year = {2019},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {204--218},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-29249-2_14},
  abstract = {The case adaptation process in case-based reasoning is often modeled as having two steps: enumerating differences between a new problem and the problem part of a retrieved case and then applying an adaptation rule for each difference. This model is sufficient when (1) predefined adaptation rules exist for all differences the system encounters, and (2) adaptation rules are sufficiently independent that interactions are not a major issue. This paper presents an approach to handling case adaptation when these assumptions fail. It proposes an approach, RObust ADaptation (ROAD), that uses heuristics to guide multi-step adaptations, with each adaptation chosen in the context of adaptations applied previously. To reduce the potential for accumulated degradation of solution quality from long adaptation chains, it performs incremental retrieval of new source cases along the adaptation path, resetting the partially modified case to the ``ground truth'' of existing cases when an existing case is nearby. An evaluation supports the benefits of the model and illuminates some tradeoffs.},
  isbn = {978-3-030-29249-2},
  langid = {english}
}

@misc{Lehnert2024BetterPlanningTransformers,
  title = {Beyond {{A}}*: {{Better Planning}} with {{Transformers}} via {{Search Dynamics Bootstrapping}}},
  shorttitle = {Beyond {{A}}*},
  author = {Lehnert, Lucas and Sukhbaatar, Sainbayar and Mcvay, Paul and Rabbat, Michael and Tian, Yuandong},
  year = {2024},
  month = feb,
  number = {arXiv:2402.14083},
  eprint = {2402.14083},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.14083},
  urldate = {2024-02-24},
  abstract = {While Transformers have enabled tremendous progress in various application settings, such architectures still lag behind traditional symbolic planners for solving complex decision making tasks. In this work, we demonstrate how to train Transformers to solve complex planning tasks and present Searchformer, a Transformer model that optimally solves previously unseen Sokoban puzzles 93.7\% of the time, while using up to 26.8\% fewer search steps than standard \$A{\textasciicircum}*\$ search. Searchformer is an encoder-decoder Transformer model trained to predict the search dynamics of \$A{\textasciicircum}*\$. This model is then fine-tuned via expert iterations to perform fewer search steps than \$A{\textasciicircum}*\$ search while still generating an optimal plan. In our training method, \$A{\textasciicircum}*\$'s search dynamics are expressed as a token sequence outlining when task states are added and removed into the search tree during symbolic planning. In our ablation studies on maze navigation, we find that Searchformer significantly outperforms baselines that predict the optimal plan directly with a 5-10\${\textbackslash}times\$ smaller model size and a 10\${\textbackslash}times\$ smaller training dataset. We also demonstrate how Searchformer scales to larger and more complex decision making tasks like Sokoban with improved percentage of solved tasks and shortened search dynamics.},
  archiveprefix = {arXiv}
}

@book{Lenat1989BuildingLargeKnowledgebased,
  title = {Building {{Large Knowledge-based Systems}}: {{Representation}} and {{Inference}} in the {{Cyc Project}}},
  shorttitle = {Building {{Large Knowledge-based Systems}}},
  author = {Lenat, Douglas B. and Guha, R. V.},
  year = {1989},
  publisher = {Addison-Wesley Publishing Company},
  abstract = {Chapter one presents the Cyc "philosophy" or paradigm. Chapter 2 presents a global overview of Cyc, including its representation language, the ontology f its knowledge base, and teh environment which it functions. Chapter 3 goes into much more detail on the representation language, including the structure and function of Cyc's metalevel agenda mechanism. Chapter 4 presents heuristics for ontological engineering, the pricnples upon whcihc Cyc's ontology is based. Chapter 5 the provides a glimpse into the global ontology of knowledge. Chapter 6 explains how we "solve" (i.e., adequately handle) the various tough representation thorns (substances, time, space, structures, composite mental/physical objects, beliefs, uncertainty, etc. ). Chapter 7 surveys the mistakes that new knowledge tnereres most often commit. Chapter 8, the concluding chapter, includes a brief status report on the project, and a statement of goals and a timetable for the coming five years.},
  googlebooks = {55NQAAAAMAAJ},
  isbn = {978-0-201-51752-1},
  langid = {english}
}

@inproceedings{Lendvai2016MonolingualSocialMedia,
  title = {Monolingual {{Social Media Datasets}} for {{Detecting Contradiction}} and {{Entailment}}},
  booktitle = {Proceedings of the {{Tenth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'16)},
  author = {Lendvai, Piroska and Augenstein, Isabelle and Bontcheva, Kalina and Declerck, Thierry},
  year = {2016},
  month = may,
  pages = {4602--4605},
  publisher = {European Language Resources Association (ELRA)},
  address = {Portoro{\v z}, Slovenia},
  urldate = {2022-01-03},
  abstract = {Entailment recognition approaches are useful for application domains such as information extraction, question answering or summarisation, for which evidence from multiple sentences needs to be combined. We report on a new 3-way judgement Recognizing Textual Entailment (RTE) resource that originates in the Social Media domain, and explain our semi-automatic creation method for the special purpose of information verification, which draws on manually established rumourous claims reported during crisis events. From about 500 English tweets related to 70 unique claims we compile and evaluate 5.4k RTE pairs, while continue automatizing the workflow to generate similar-sized datasets in other languages.}
}

@incollection{Lenz1998TextualCBR,
  title = {Textual {{CBR}}},
  booktitle = {Case-{{Based Reasoning Technology}}: {{From Foundations}} to {{Applications}}},
  author = {Lenz, Mario and H{\"u}bner, Andr{\'e} and Kunze, Mirjam},
  editor = {Lenz, Mario and Burkhard, Hans-Dieter and {Bartsch-Sp{\"o}rl}, Brigitte and Wess, Stefan},
  year = {1998},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {115--137},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-69351-3_5},
  urldate = {2021-02-19},
  abstract = {In this chapter, we will explore a fairly new direction of research in the case-based reasoning community, namely the handling of textual documents. We will explain first why the ability to deal with natural language texts is crucial. We will then discuss more traditional methods for these tasks. Following this, we present the approach of Textual CBR and, in particular, the CBR-Answers project.},
  isbn = {978-3-540-69351-2},
  langid = {english}
}

@inproceedings{Lenz1998TextualCBRInformation,
  title = {Textual {{CBR}} and {{Information Retrieval}} - {{A Comparison}}},
  booktitle = {In {{Proceedings}} 6th {{German Workshop}} on {{CBR}}},
  author = {Lenz, Mario},
  year = {1998},
  abstract = {In recent years, quite a number of projects started to apply case-based reasoning technology to textual documents instead of highly structured cases. For this the term Textual CBR has been coined. In this paper, we give an overview over the main ideas of Textual CBR and compare it with Information Retrieval techniques. We also present some preliminary results obtained from three projects performed which further demonstrate major advantages of Textual CBR.  Keywords: Textual case-based reasoning, document management, knowledge acquisition. 1 Introduction  In recent years, case-based reasoning (CBR) researchers started to address tasks that have traditionally been coped with by the Information Retrieval community, namely the handling of textual documents. When considering the roots of CBR, this development is not surprising at all: CBR tries to solve problems by explicitly reusing experiences collected during earlier problem solving situations. In practice, however, many of these experie...}
}

@phdthesis{Lenz2018RetrievalArgumentationGraphs,
  type = {Bachelor's {{Thesis}}},
  title = {Retrieval of {{Argumentation Graphs}} Using {{Concatenated Word Embeddings}} and {{Argumentation Schemes}}},
  author = {Lenz, Mirko},
  year = {2018},
  month = jul,
  address = {Trier},
  abstract = {This thesis will outline an approach to retrieve arguments from a set of stored ones using both structural and semantic similarity computations. The novelty of the approach is the use of multiple, concatenated word embeddings and aggregation functions to increase the amount of contextual information. In existing works, this method has only been used for classification tasks. This thesis shows that the concatenation combines the benefits of multiple embeddings while not having the same weaknesses. Furthermore, argumentation schemes will be used to enhance the structural retrieval even further. These schemes provide a detailed description of the relation between two arguments. The use of them also aims at incorporating more information into the retrieval process. This thesis shows that the use of argumentation schemes provides further benefits to the retrieval process. The retrieval is performed on German texts and it will be shown that the publicly available embeddings for this language are not as detailed as their English counterparts.},
  langid = {english},
  school = {Trier University}
}

@inproceedings{Lenz2019SemanticTextualSimilarity,
  title = {Semantic {{Textual Similarity Measures}} for {{Case-Based Retrieval}} of {{Argument Graphs}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Lenz, Mirko and Ollinger, Stefan and Sahitaj, Premtim and Bergmann, Ralph},
  editor = {Bach, Kerstin and Marling, Cindy},
  year = {2019},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {11680},
  pages = {219--234},
  publisher = {Springer International Publishing},
  address = {Otzenhausen, Germany},
  doi = {10.1007/978-3-030-29249-2_15},
  abstract = {Argumentation is an important sub-field of Artificial Intelligence, which involves computational methods for reasoning and decision making based on argumentative structures. This paper contributes to case-based reasoning with argument graphs in the standardized Argument Interchange Format by improving the similarity-based retrieval phase. We explore a large range of novel approaches for semantic textual similarity measures (both supervised and unsupervised) and use them in the context of a graph-based similarity measure for argument graphs. In addition, the use of an ontology-based semantic similarity measure for argumentation schemes is investigated. With a range of experiments we demonstrate the strengths and weaknesses of the various methods and show that our methods can improve over our previous work. Our code is publicly available on GitHub.},
  isbn = {978-3-030-29249-2},
  langid = {english}
}

@inproceedings{Lenz2020ArgumentMiningPipeline,
  title = {Towards an {{Argument Mining Pipeline Transforming Texts}} to {{Argument Graphs}}},
  booktitle = {Computational {{Models}} of {{Argument}}},
  author = {Lenz, Mirko and Sahitaj, Premtim and Kallenberg, Sean and Coors, Christopher and Dumani, Lorik and Schenkel, Ralf and Bergmann, Ralph},
  year = {2020},
  series = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  volume = {326},
  pages = {263--270},
  publisher = {IOS Press},
  address = {Virtual Event},
  doi = {10.3233/FAIA200510},
  urldate = {2024-07-19},
  abstract = {This paper tackles the automated extraction of components of argumentative information and their relations from natural language text. Moreover, we address a current lack of systems to provide a complete argumentative structure from arbitrary natural language text for general usage. We present an argument mining pipeline as a universally applicable approach for transforming German and English language texts to graph-based argument representations. We also introduce new methods for evaluating the performance based on existing benchmark argument structures. Our results show that the generated argument graphs can be beneficial to detect new connections between different statements of an argumentative text.},
  langid = {english}
}

@mastersthesis{Lenz2021GeneralizationArgumentGraphs,
  title = {Generalization of {{Argument Graphs}} Based on {{User Queries}}},
  author = {Lenz, Mirko},
  year = {2021},
  month = mar,
  address = {Trier},
  abstract = {Argumentation is central to many aspects of human interaction. Finding the best arguments is possible with established web search engines, even though they are only able to process them in their textual form. Argumentation machines on the other hand are able to consider structural elements as well---for instance, when representing relations between arguments as graphs. Operating directly on graphs eliminates the user's task of manually structuring the collected information. However, the found argument may not properly fulfill the information need expressed via the query. It may happen that the topic of the found argument deals with a special case of the query---for instance, asking for arguments about ``animals'', but being presented with the special case ``dogs''. To tackle this task, this thesis investigates the generalization of argument graphs using a text-based approach. By identifying words that could benefit from being generalized, I propose two methods of determining appropriate replacements. Both techniques make extensive use of background knowledge in the form of commonsense knowledge (e.g., dog is an animal). A current limitation is that the user has to provide a ``starting point'' for this generalization, making the process not fully-automatic. The proposed approach is complemented by a fully featured implementation, a corpus containing generalizations crafted by experts, and a detailed evaluation of the techniques. I come to the conclusion that the generalization of argument graphs is a difficult task to solve, mainly caused by the high amount of subjectivity involved in the whole process. While trying to approximate the assessments of the experts does not seem to be a feasible strategy, I was able to achieve better results by allowing the system more freedom during the generalization process.},
  langid = {english},
  school = {Trier University}
}

@inproceedings{Lenz2022ComparingUnsupervisedAlgorithms,
  title = {Comparing {{Unsupervised Algorithms}} to {{Construct Argument Graphs}}},
  booktitle = {Joint {{Proceedings}} of {{Workshops}}, {{Tutorials}} and {{Doctoral Consortium}} Co-Located with the 45th {{German Conference}} on {{Artificial Intelligence}}},
  author = {Lenz, Mirko and Dumani, Lorik and Sahitaj, Premtim},
  editor = {Koert, Dorothea and Minor, Mirjam},
  year = {2022},
  month = sep,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3457},
  publisher = {CEUR},
  address = {Virtual Event, Trier},
  issn = {1613-0073},
  urldate = {2023-10-24},
  abstract = {Computational argumentation has gained considerable attention in recent years. Various areas have been addressed, such as extracting arguments from natural language texts into a structured form in order to store them in an argument base, determining stances for arguments with respect to topics, determination of inferences from statements, and much more. After so much progress has been made in the isolated tasks, in this paper we address the next level and aim to advance the automatic generation of argument graphs. To this end, we investigate various unsupervised methods for constructing the graphs and measure the performance with different metrics on three different datasets. Our implementation is publicly available on GitHub under the permissive MIT license.},
  langid = {english}
}

@inproceedings{Lenz2022UserCentricArgumentMining,
  title = {User-{{Centric Argument Mining}} with {{ArgueMapper}} and {{Arguebuf}}},
  booktitle = {Computational {{Models}} of {{Argument}}},
  author = {Lenz, Mirko and Bergmann, Ralph},
  year = {2022},
  series = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  volume = {353},
  pages = {367--368},
  publisher = {IOS Press},
  address = {Cardiff, Wales},
  doi = {10.3233/FAIA220176},
  urldate = {2022-09-14},
  abstract = {Existing tools to create argument graphs are tailored for experts in the domain of argumentation. By taking into account the needs of experts, laymen, and developers, we propose ArgueMapper as a novel argument diagramming tool and Arguebuf as its underlying format. ArgueMapper is the first of its kind to be optimized for mobile devices and provide a discoverable interface suitable for novice users. Arguebuf provides native implementations for all major programming languages via a code generation approach. To complement Arguebuf, we provide a supercharged Python implementation that enables advanced analysis. All of our contributions support AIF and are publicly available on GitHub under the MIT license.},
  langid = {english}
}

@inproceedings{Lenz2022WorkshopTextMining,
  title = {Workshop on {{Text Mining}} and {{Generation}} ({{TMG}}): {{Preface}}},
  booktitle = {Joint {{Proceedings}} of {{Workshops}}, {{Tutorials}} and {{Doctoral Consortium}} Co-Located with the 45rd {{German Conference}} on {{Artificial Intelligence}}},
  author = {Lenz, Mirko and Dumani, Lorik and Bondarenko, Alexander and Syed, Shahbaz},
  editor = {Koert, Dorothea and Minor, Mirjam},
  year = {2022},
  month = sep,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3457},
  publisher = {CEUR},
  address = {Virtual Event, Trier},
  issn = {1613-0073},
  urldate = {2023-10-24},
  abstract = {This paper is a report on the first Text Mining and Generation Workshop (TMG), which was a one-day virtual event hosted at the German Conference on Artificial Intelligence (KI 2022) in Trier, Germany. In addition to four accepted original papers, there were three invited talks by speakers who presented their works already published at high-ranked conferences as well as one keynote by a pioneer in the two research fields relevant to the workshop.},
  langid = {english}
}

@inproceedings{Lenz2023CaseBasedAdaptationArgument,
  title = {Case-{{Based Adaptation}} of~{{Argument Graphs}} with~{{WordNet}} and~{{Large Language Models}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Lenz, Mirko and Bergmann, Ralph},
  editor = {Massie, Stewart and Chakraborti, Sutanu},
  year = {2023},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {14141},
  pages = {263--278},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-40177-0_17},
  abstract = {Finding information online is hard, even more so once you get into the domain of argumentation. There have been developments around the specialized argumentation machines that incorporate structural features of arguments, but all current approaches share one pitfall: They operate on a corpora of limited sizes. Consequently, it may happen that a user searches for a rather general term like cost increases, but the machine is only able to serve arguments concerned with rent increases. We aim to bridge this gap by introducing approaches to generalize/specialize a found argument using a combination of WordNet and Large Language Models. The techniques are evaluated on a new benchmark dataset with diverse queries using our fully featured implementation. Both the dataset and the code are publicly available on GitHub.},
  isbn = {978-3-031-40177-0},
  langid = {english},
  annotation = {Best Student Paper Award at ICCBR 2023}
}

@inproceedings{Lenz2024ArgServicesMicroserviceBasedArchitecture,
  title = {{{ArgServices}}: {{A Microservice-Based Architecture}} for~{{Argumentation Machines}}},
  shorttitle = {{{ArgServices}}},
  booktitle = {Robust {{Argumentation Machines}}},
  author = {Lenz, Mirko and Dumani, Lorik and Schenkel, Ralf and Bergmann, Ralph},
  editor = {Cimiano, Philipp and Frank, Anette and Kohlhase, Michael and Stein, Benno},
  year = {2024},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {14638},
  pages = {352--369},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63536-6_21},
  abstract = {Argumentation is ubiquitous, and the development of argumentation machines could greatly assist humans in managing and navigating argumentation. However, the development of such systems is hindered by the lack of common standards and suitable tools, leading to ad-hoc solutions with little reuse value. Towards a more unified approach, we present an extensible microservice-based architecture for argumentation machines. Being built on the established gRPC framework, it provides strongly typed interfaces for the following services: (i) Argument Mining, (ii) Case-Based Reasoning on Arguments, (iii) Argument Retrieval and Ranking, and (iv) Quality Assessment of Arguments. Our system is designed to be extensible, allowing for easy integration of new tasks. We demonstrate the feasibility of our architecture via a proof-of-concept implementation and provide additional supplementary resources, such as a REST API gateway. Our contributions are publicly available on GitHub under the permissive MIT license.},
  isbn = {978-3-031-63536-6},
  langid = {english}
}

@inproceedings{Lenz2024CBRkitIntuitiveCaseBased,
  title = {{{CBRkit}}: {{An Intuitive Case-Based Reasoning Toolkit}} for~{{Python}}},
  shorttitle = {{{CBRkit}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Lenz, Mirko and Malburg, Lukas and Bergmann, Ralph},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {14775},
  pages = {289--304},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_19},
  abstract = {Developing Case-Based Reasoning (CBR) applications is a complex and demanding task that requires a lot of experience and a deep understanding of users. Additionally, current CBR frameworks are not as usable as Machine Learning (ML) frameworks that can be deployed with only a few lines of code. To address these problems and allow users to easily build hybrid Artificial Intelligence (AI) systems by combining CBR with techniques such as ML, we present the CBRkit library in this paper. CBRkit is a Python-based framework that provides generic and easily extensible functions to simplify the creation of CBR applications with advanced similarity measures and case representations. The framework is available from GitHub and PyPI under the permissive MIT license. An initial user study indicates that it is easily possible even for non-CBR experts and users who only have limited Python programming skills to develop their own customized CBR application.},
  isbn = {978-3-031-63646-2},
  langid = {english},
  annotation = {Best Student Paper Award at ICCBR 2024}
}

@inproceedings{Lenz2024PolArgUnsupervisedPolarity,
  title = {{{PolArg}}: {{Unsupervised Polarity Prediction}} of~{{Arguments}} in~{{Real-Time Online Conversations}}},
  shorttitle = {{{PolArg}}},
  booktitle = {Robust {{Argumentation Machines}}},
  author = {Lenz, Mirko and Bergmann, Ralph},
  editor = {Cimiano, Philipp and Frank, Anette and Kohlhase, Michael and Stein, Benno},
  year = {2024},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {14638},
  pages = {108--126},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63536-6_7},
  abstract = {The increasing usage of social networks has led to a growing number of discussions on the Internet that are a valuable source of argumentation that occurs in real time. Such conversations are often made up of a large number of participants and are characterized by a fast pace. Platforms like X/Twitter and Hacker News (HN) allow users to respond to other users' posts, leading to a tree-like structure. Previous work focused on training supervised models on datasets obtained from debate portals like Kialo where authors provide polarity labels (i.e., support/attack) together with their posts. Such classifiers may yield suboptimal predictions for the noisier posts from X or HN, so we propose unsupervised prompting strategies for large language models instead. Our experimental evaluation found this approach to be more effective for X conversations than a model fine-tuned on Kialo debates, but less effective for HN posts (which are more technical and less argumentative). Finally, we provide an open-source application for converting discussions on these platforms into argument graphs.},
  isbn = {978-3-031-63536-6},
  langid = {english}
}

@inproceedings{Lenz2025ArgueMapperAssistantInteractive,
  title = {{{ArgueMapper Assistant}}: {{Interactive Argument Mining Using Generative Language Models}}},
  shorttitle = {{{ArgueMapper Assistant}}},
  booktitle = {Artificial {{Intelligence XLI}}},
  author = {Lenz, Mirko and Bergmann, Ralph},
  editor = {Bramer, Max and Stahl, Frederic},
  year = {2025},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {15446},
  pages = {189--203},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-77915-2_14},
  abstract = {Structured arguments are a valuable resource for analyzing and understanding complex topics. However, manual annotation is time-consuming and often not feasible for large datasets, and automated approaches are less accurate. To address this issue, we propose an interactive argument mining system that takes advantage of generative language models to support humans in the creation of argument graphs. We present the open source ArgueMapper Assistant featuring two prompting strategies and evaluate it on a real-world news dataset. The resulting corpus containing 88 argument graphs is publicly available as well. With generative models, the annotation time is reduced by about 20\% while the number of errors is slightly increased (mostly due to missing argumentative units and wrong relation types). A survey provides insights into the usefulness and reliability of the assistant features and shows that participants prefer to use the assistant in the future.},
  isbn = {978-3-031-77915-2},
  langid = {english}
}

@article{Levenshtein1966BinaryCodesCapable,
  title = {Binary {{Codes Capable}} of {{Correcting Deletions}}, {{Insertions}} and {{Reversals}}},
  author = {Levenshtein, V. I.},
  year = {1966},
  month = feb,
  journal = {Soviet Physics Doklady},
  volume = {10},
  pages = {707},
  urldate = {2018-09-01},
  abstract = {Not Available}
}

@inproceedings{Lewis2020RetrievalAugmentedGenerationKnowledgeIntensive,
  title = {Retrieval-{{Augmented Generation}} for {{Knowledge-Intensive NLP Tasks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  year = {2020},
  volume = {33},
  pages = {9459--9474},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-04-01},
  abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.}
}

@inproceedings{Lieber2018MakingBestCases,
  title = {Making the {{Best}} of {{Cases}} by {{Approximation}}, {{Interpolation}} and {{Extrapolation}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Lieber, Jean and Nauer, Emmanuel and Prade, Henri and Richard, Gilles},
  editor = {Cox, Michael T. and Funk, Peter and Begum, Shahina},
  year = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {580--596},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-01081-2_38},
  abstract = {Case-based reasoning usually exploits source cases (consisting of a source problem and its solution) individually, on the basis of the similarity between the target problem and a particular source problem. This corresponds to approximation. Then the solution of the source case has to be adapted to the target. We advocate in this paper that it is also worthwhile to consider source cases by two, or by three. Handling cases by two allows for a form of interpolation, when the target problem is between two similar source problems. When cases come by three, it offers a basis for extrapolation. Namely the solution of the target problem is obtained, when possible, as the fourth term of an analogical proportion linking the three source cases with the target, where the analogical proportion handles both similarity and dissimilarity between cases. Experiments show that interpolation and extrapolation techniques are of interest for reusing cases, either in an independent or in a combined way.},
  isbn = {978-3-030-01081-2},
  langid = {english}
}

@article{Likert1932TechniqueMeasurementAttitudes,
  title = {A Technique for the Measurement of Attitudes},
  author = {Likert, R.},
  year = {1932},
  journal = {Archives of Psychology},
  volume = {22  140},
  pages = {55--55},
  abstract = {The project conceived in 1929 by Gardner Murphy and the writer aimed first to present a wide array of problems having to do with five major "attitude areas"---international relations, race relations, economic conflict, political conflict, and religion. The kind of questionnaire material falls into four classes: yes-no, multiple choice, propositions to be responded to by degrees of approval, and a series of brief newspaper narratives to be approved or disapproved in various degrees. The monograph aims to describe a technique rather than to give results. The appendix, covering ten pages, shows the method of constructing an attitude scale. A bibliography is also given. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@inproceedings{Lin2015ModelingRelationPaths,
  title = {Modeling {{Relation Paths}} for {{Representation Learning}} of {{Knowledge Bases}}},
  booktitle = {Proceedings of the 2015 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Lin, Yankai and Liu, Zhiyuan and Luan, Huanbo and Sun, Maosong and Rao, Siwei and Liu, Song},
  year = {2015},
  month = sep,
  pages = {705--714},
  publisher = {Association for Computational Linguistics},
  address = {Lisbon, Portugal},
  doi = {10.18653/v1/D15-1082},
  urldate = {2020-05-31}
}

@article{Liu2004ConceptNetPracticalCommonsense,
  title = {{{ConceptNet}} --- {{A Practical Commonsense Reasoning Tool-Kit}}},
  author = {Liu, H. and Singh, P.},
  year = {2004},
  month = oct,
  journal = {BT Technology Journal},
  volume = {22},
  number = {4},
  pages = {211--226},
  issn = {1573-1995},
  doi = {10.1023/B:BTTJ.0000047600.45421.6d},
  urldate = {2021-02-10},
  abstract = {ConceptNet is a freely available commonsense knowledge base and natural-language-processing tool-kit which supports many practical textual-reasoning tasks over real-world documents including topic-gisting, analogy-making, and other context oriented inferences. The knowledge base is a semantic network presently consisting of over 1.6 million assertions of commonsense knowledge encompassing the spatial, physical, social, temporal, and psychological aspects of everyday life. ConceptNet is generated automatically from the 700 000 sentences of the Open Mind Common Sense Project --- a World Wide Web based collaboration with over 14 000 authors.},
  langid = {english}
}

@article{Lloyd1982LeastSquaresQuantization,
  title = {Least Squares Quantization in {{PCM}}},
  author = {Lloyd, S.},
  year = {1982},
  month = mar,
  journal = {IEEE Transactions on Information Theory},
  volume = {28},
  number = {2},
  pages = {129--137},
  issn = {1557-9654},
  doi = {10.1109/TIT.1982.1056489},
  abstract = {It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quautization schemes for2{\textasciicircum}bquanta,b=1,2, {\textbackslash}cdots, 7, are given numerically for Gaussian and for Laplacian distribution of signal amplitudes.}
}

@article{Lu2012FastProjectedFixedPoint,
  title = {A {{Fast Projected Fixed-Point Algorithm}} for {{Large Graph Matching}}},
  author = {Lu, Yao and Huang, Kaizhu and Liu, Cheng-Lin},
  year = {2012},
  month = jul,
  journal = {arXiv:1207.1114 [cs]},
  eprint = {1207.1114},
  primaryclass = {cs},
  urldate = {2019-01-07},
  abstract = {We propose a fast approximate algorithm for large graph matching. A new projected fixed-point method is defined and a new doubly stochastic projection is adopted to derive the algorithm. Previous graph matching algorithms suffer from high computational complexity and therefore do not have good scalability with respect to graph size. For matching two weighted graphs of \$n\$ nodes, our algorithm has time complexity only \$O(n{\textasciicircum}3)\$ per iteration and space complexity \$O(n{\textasciicircum}2)\$. In addition to its scalability, our algorithm is easy to implement, robust, and able to match undirected weighted attributed graphs of different sizes. While the convergence rate of previous iterative graph matching algorithms is unknown, our algorithm is theoretically guaranteed to converge at a linear rate. Extensive experiments on large synthetic and real graphs (more than 1,000 nodes) were conducted to evaluate the performance of various algorithms. Results show that in most cases our proposed algorithm achieves better performance than previous state-of-the-art algorithms in terms of both speed and accuracy in large graph matching. In particular, with high accuracy, our algorithm takes only a few seconds (in a PC) to match two graphs of 1,000 nodes.},
  archiveprefix = {arXiv}
}

@book{Lukaszewicz1990NonmonotonicReasoningFormalization,
  title = {Non-Monotonic {{Reasoning}}: {{Formalization}} of {{Commonsense Reasoning}}},
  shorttitle = {Non-Monotonic {{Reasoning}}},
  author = {{\L}ukaszewicz, Witold},
  year = {1990},
  publisher = {Ellis Horwood},
  googlebooks = {ZnZQAAAAMAAJ},
  isbn = {978-0-13-624446-2},
  langid = {english}
}

@inproceedings{MacQueen1967MethodsClassificationAnalysis,
  title = {Some Methods for Classification and Analysis of Multivariate Observations},
  booktitle = {Proceedings of the {{Fifth Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}},
  author = {MacQueen, J.},
  year = {1967},
  volume = {1},
  pages = {281--297},
  address = {Berkeley, USA}
}

@mastersthesis{Maggiore2022SurveySemanticSimilarity,
  title = {Survey on {{Semantic Similarity Measures}} for {{Argument Graphs}}},
  author = {Maggiore, Federico},
  year = {2022},
  month = sep,
  address = {Trier, Germany},
  langid = {english},
  school = {Trier University}
}

@article{Majumder2021InterpretableSemanticTextual,
  title = {Interpretable Semantic Textual Similarity of Sentences Using Alignment of Chunks with Classification and Regression},
  author = {Majumder, Goutam and Pakray, Partha and Das, Ranjita and Pinto, David},
  year = {2021},
  month = mar,
  journal = {Applied Intelligence},
  pages = {1--28},
  publisher = {Springer US},
  issn = {1573-7497},
  doi = {10.1007/s10489-020-02144-x},
  urldate = {2021-03-13},
  abstract = {The proposed work is focused on establishing an interpretable Semantic Textual Similarity (iSTS) method for a pair of sentences, which can clarify why two sentences are completely or partially similar or have some variations. This proposed interpretable approach is a pipeline of five modules that begins with the pre-processing and chunking of text. Further chunks of two sentences are aligned using a one--to--multi (1:M) chunk aligner. Thereafter, support vector, Gaussian Naive Bayes and k--Nearest Neighbours classifiers are then used to create a multiclass classification algorithm, and different class labels are used to define an alignment type. At last, a multivariate regression algorithm is developed to find the semantic equivalence of an alignment with a score (that ranges from 0 to 5). The efficiency of the proposed method is verified on three different datasets and also compared to other state--of--the--art interpretable STS (iSTS) methods. The evaluated results show that the proposed method performs better than other iSTS methods. Most importantly, the modules of the proposed iSTS method are used to develop a Textual Entailment (TE) method. It is found that, when we combined chunk level, alignment, and sentence level features the entailment results significantly improves.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature},
  langid = {english}
}

@inproceedings{Malburg2021ImprovingSimilarityBasedRetrieval,
  title = {Improving {{Similarity-Based Retrieval Efficiency}} by {{Using Graphic Processing Units}} in {{Case-Based Reasoning}}},
  booktitle = {The {{International FLAIRS Conference Proceedings}}},
  author = {Malburg, Lukas and Hoffmann, Maximilian and Trumm, Simon and Bergmann, Ralph},
  year = {2021},
  month = apr,
  volume = {34},
  address = {Florida},
  doi = {10.32473/flairs.v34i1.128345},
  urldate = {2024-04-01},
  abstract = {The accelerated growth of available data causes case bases of increasing sizes and thus lowers efficiency during the case retrieval phase in Case-Based Reasoning (CBR) systems. Even though, many complex and data-intensive tasks are solved by using Graphic Processing Units (GPUs), its application in CBR research has yet to advance past the early stage phase. In this paper, we present an approach to use CUDA-compatible GPUs for similarity assessment of structural, feature vector based cases. Our approach supports several syntactic and semantic similarity measures and is implemented in the open-source case-based reasoning framework ProCAKE. When comparing to current retrieval techniques that calculate similarities on the CPU, our GPU-based approach outperforms them by a factor of up to 37. In addition, our evaluation indicates that the performance gains increase with higher case complexity.},
  copyright = {http://creativecommons.org/licenses/by-nc/4.0}
}

@inproceedings{Malburg2024ImprovingComplexAdaptations,
  title = {Improving {{Complex Adaptations}} in {{Process-Oriented Case-Based Reasoning}} by {{Applying Rule-Based Adaptation}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Malburg, Lukas and Hotz, Maxim and Bergmann, Ralph},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {50--66},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_4},
  abstract = {Adaptation is a complex and error-prone task in Case-Based Reasoning (CBR), including the adaptation knowledge acquisition and modeling efforts required for performing adaptations. This is also evident for the subfield of Process-Oriented Case-Based Reasoning (POCBR) in which cases represent procedural experiential knowledge, making creation and maintaining adaptation knowledge even for domain experts exceedingly challenging. Current adaptation methods in POCBR address the adaptation knowledge bottleneck by learning adaptation knowledge based on cases in the case base. However, these approaches are based on proprietary representation formats, resulting in low usability and maintainability. Therefore, we present an approach of using adaptation rules and rule engines for complex adaptations in POCBR in this paper. The results of an experimental evaluation indicate that the rule-based adaptation approach leads to significantly better results during runtime than an already available POCBR adaptation method.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@article{Manne2012FeatureTermsBased,
  title = {A {{Feature Terms}} Based {{Method}} for {{Improving Text Summarization}} with {{Supervised POS Tagging}}},
  author = {Manne, Suneetha and Sameen Fatima, S.},
  year = {2012},
  month = jul,
  journal = {International Journal of Computer Applications},
  volume = {47},
  number = {23},
  pages = {7--14},
  issn = {09758887},
  doi = {10.5120/7494-0541},
  urldate = {2023-10-26}
}

@book{Manning2008IntroductionInformationRetrieval,
  title = {Introduction to Information Retrieval},
  author = {Manning, Christopher D. and Raghavan, Prabhakar and Sch{\"u}tze, Hinrich},
  year = {2008},
  publisher = {Cambridge University Press},
  address = {New York},
  isbn = {978-0-521-86571-5},
  lccn = {QA76.9.T48 M26 2008},
  annotation = {OCLC: ocn190786122}
}

@article{Manning2022HumanLanguageUnderstanding,
  title = {Human {{Language Understanding}} \& {{Reasoning}}},
  author = {Manning, Christopher D.},
  year = {2022},
  month = may,
  journal = {Daedalus},
  volume = {151},
  number = {2},
  pages = {127--138},
  issn = {0011-5266},
  doi = {10.1162/daed_a_01905},
  urldate = {2023-04-01},
  abstract = {The last decade has yielded dramatic and quite surprising breakthroughs in natural language processing through the use of simple artificial neural network computations, replicated on a very large scale and trained over exceedingly large amounts of data. The resulting pretrained language models, such as BERT and GPT-3, have provided a powerful universal language understanding and generation base, which can easily be adapted to many understanding, writing, and reasoning tasks. These models show the first inklings of a more general form of artificial intelligence, which may lead to powerful foundation models in domains of sensory experience beyond just language.}
}

@inproceedings{Mao2023EmbeddingToEmbeddingMethodBased,
  title = {Embedding-{{To-Embedding Method Based}} on {{Autoencoder}} for {{Solving Sentence Analogies}}},
  booktitle = {Proceedings of the {{Workshops}} at the 31st {{International Conference}} on {{Case-Based Reasoning}} ({{ICCBR-WS}} 2023)},
  author = {Mao, Weihao and Lepage, Yves},
  editor = {Malburg, Lukas and Verma, Deepika},
  year = {2023},
  month = jul,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3438},
  pages = {15--26},
  publisher = {CEUR},
  address = {Aberdeen, Scotland},
  issn = {1613-0073},
  urldate = {2023-07-31},
  langid = {english}
}

@article{Marcus1993BuildingLargeAnnotated,
  title = {Building a {{Large Annotated Corpus}} of {{English}}: {{The Penn Treebank}}},
  shorttitle = {Building a {{Large Annotated Corpus}} of {{English}}},
  author = {Marcus, Mitchell P. and Santorini, Beatrice and Marcinkiewicz, Mary Ann},
  year = {1993},
  journal = {Computational Linguistics},
  volume = {19},
  number = {2},
  pages = {313--330},
  urldate = {2021-02-09}
}

@misc{Marjieh2022PredictingHumanSimilarity,
  title = {Predicting {{Human Similarity Judgments Using Large Language Models}}},
  author = {Marjieh, Raja and Sucholutsky, Ilia and Sumers, Theodore R. and Jacoby, Nori and Griffiths, Thomas L.},
  year = {2022},
  month = feb,
  number = {arXiv:2202.04728},
  eprint = {2202.04728},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2202.04728},
  urldate = {2024-03-15},
  abstract = {Similarity judgments provide a well-established method for accessing mental representations, with applications in psychology, neuroscience and machine learning. However, collecting similarity judgments can be prohibitively expensive for naturalistic datasets as the number of comparisons grows quadratically in the number of stimuli. One way to tackle this problem is to construct approximation procedures that rely on more accessible proxies for predicting similarity. Here we leverage recent advances in language models and online recruitment, proposing an efficient domain-general procedure for predicting human similarity judgments based on text descriptions. Intuitively, similar stimuli are likely to evoke similar descriptions, allowing us to use description similarity to predict pairwise similarity judgments. Crucially, the number of descriptions required grows only linearly with the number of stimuli, drastically reducing the amount of data required. We test this procedure on six datasets of naturalistic images and show that our models outperform previous approaches based on visual information.},
  archiveprefix = {arXiv}
}

@inproceedings{Marquer2023LessBetterEnergyBased,
  title = {Less Is {{Better}}: {{An Energy-Based Approach}} to {{Case Base Competence}}},
  shorttitle = {Less Is {{Better}}},
  booktitle = {Proceedings of the {{Workshops}} at the 31st {{International Conference}} on {{Case-Based Reasoning}} ({{ICCBR-WS}} 2023)},
  author = {Marquer, Esteban and Badra, Fadi and Lesot, Marie-Jeanne and Couceiro, Miguel and Leake, David},
  editor = {Malburg, Lukas and Verma, Deepika},
  year = {2023},
  month = jul,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3438},
  pages = {27--42},
  publisher = {CEUR},
  address = {Aberdeen, Scotland},
  issn = {1613-0073},
  urldate = {2023-07-31},
  langid = {english}
}

@book{Massie2023CaseBasedReasoningResearch,
  title = {Case-{{Based Reasoning Research}} and {{Development}}: 31st {{International Conference}}, {{ICCBR}} 2023, {{Aberdeen}}, {{UK}}, {{July}} 17--20, 2023, {{Proceedings}}},
  shorttitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  editor = {Massie, Stewart and Chakraborti, Sutanu},
  year = {2023},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {14141},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-40177-0},
  urldate = {2024-06-26},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-031-40176-3 978-3-031-40177-0},
  langid = {english}
}

@article{Mathet2015UnifiedHolisticMethod,
  title = {The {{Unified}} and {{Holistic Method Gamma}} ({$\gamma$}) for {{Inter-Annotator Agreement Measure}} and {{Alignment}}},
  author = {Mathet, Yann and Widl{\"o}cher, Antoine and M{\'e}tivier, Jean-Philippe},
  year = {2015},
  month = sep,
  journal = {Computational Linguistics},
  volume = {41},
  number = {3},
  pages = {437--479},
  issn = {0891-2017},
  doi = {10.1162/COLI_a_00227},
  urldate = {2023-07-26},
  abstract = {Agreement measures have been widely used in computational linguistics for more than 15 years to check the reliability of annotation processes. Although considerable effort has been made concerning categorization, fewer studies address unitizing, and when both paradigms are combined even fewer methods are available and discussed. The aim of this article is threefold. First, we advocate that to deal with unitizing, alignment and agreement measures should be considered as a unified process, because a relevant measure should rely on an alignment of the units from different annotators, and this alignment should be computed according to the principles of the measure. Second, we propose the new versatile measure {$\gamma$}, which fulfills this requirement and copes with both paradigms, and we introduce its implementation. Third, we show that this new method performs as well as, or even better than, other more specialized methods devoted to categorization or segmentation, while combining the two paradigms at the same time.}
}

@inproceedings{Maxwell2017StudySnippetLength,
  title = {A {{Study}} of {{Snippet Length}} and {{Informativeness}}: {{Behaviour}}, {{Performance}} and {{User Experience}}},
  shorttitle = {A {{Study}} of {{Snippet Length}} and {{Informativeness}}},
  booktitle = {Proceedings of the 40th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Maxwell, David and Azzopardi, Leif and Moshfeghi, Yashar},
  year = {2017},
  month = aug,
  series = {{{SIGIR}} '17},
  pages = {135--144},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3077136.3080824},
  urldate = {2025-01-13},
  abstract = {The design and presentation of a Search Engine Results Page (SERP) has been subject to much research. With many contemporary aspects of the SERP now under scrutiny, work still remains in investigating more traditional SERP components, such as the result summary. Prior studies have examined a variety of different aspects of result summaries, but in this paper we investigate the influence of result summary length on search behaviour, performance and user experience. To this end, we designed and conducted a within-subjects experiment using the TREC AQUAINT news collection with 53 participants. Using Kullback-Leibler distance as a measure of information gain, we examined result summaries of different lengths and selected four conditions where the change in information gain was the greatest: (i) title only; (ii) title plus one snippet; (iii) title plus two snippets; and (iv) title plus four snippets. Findings show that participants broadly preferred longer result summaries, as they were perceived to be more informative. However, their performance in terms of correctly identifying relevant documents was similar across all four conditions. Furthermore, while the participants felt that longer summaries were more informative, empirical observations suggest otherwise; while participants were more likely to click on relevant items given longer summaries, they also were more likely to click on non-relevant items. This shows that longer is not necessarily better, though participants perceived that to be the case - and second, they reveal a positive relationship between the length and informativeness of summaries and their attractiveness (i.e. clickthrough rates). These findings show that there are tensions between perception and performance when designing result summaries that need to be taken into account.},
  isbn = {978-1-4503-5022-8}
}

@inproceedings{Mayer2020TransformerBasedArgumentMining,
  title = {Transformer-{{Based Argument Mining}} for {{Healthcare Applications}}},
  booktitle = {{{ECAI}} 2020},
  author = {Mayer, Tobias and Cabrio, Elena and Villata, Serena},
  year = {2020},
  pages = {2108--2115},
  publisher = {IOS Press},
  doi = {10.3233/FAIA200334},
  urldate = {2023-10-11}
}

@inproceedings{McCarthy1968ProgramsCommonSense,
  title = {Programs with {{Common Sense}}},
  booktitle = {Semantic {{Information Processing}}},
  author = {McCarthy, John},
  year = {1968},
  pages = {403--418},
  publisher = {MIT Press},
  abstract = {This paper will discuss programs to manipulate in a suitable formal lan- guage (most likely a part of the predicate calculus) common instrumental statements. The basic program will draw immediate conclusions from a list of premises. These conclusions will be either declarative or imperative sentences. When an imperative sentence is deduced the program takes a corresponding action. These actions may include printing sentences, moving sentences on lists. and reinitiating the basic deduction process on these lists. Facilities will be provided for communication with humans in the system via manual intervention and display devices connected to the computer}
}

@inproceedings{McInnes2017AcceleratedHierarchicalDensity,
  title = {Accelerated {{Hierarchical Density Based Clustering}}},
  booktitle = {2017 {{IEEE International Conference}} on {{Data Mining Workshops}} ({{ICDMW}})},
  author = {McInnes, Leland and Healy, John},
  year = {2017},
  month = nov,
  pages = {33--42},
  issn = {2375-9259},
  doi = {10.1109/ICDMW.2017.12},
  abstract = {We present an accelerated algorithm for hierarchical density based clustering. Our new algorithm improves upon HDBSCAN*, which itself provided a significant qualitative improvement over the popular DBSCAN algorithm. The accelerated HDBSCAN* algorithm provides comparable performance to DBSCAN, while supporting variable density clusters, and eliminating the need for the difficult to tune distance scale parameter epsilon. This makes accelerated HDBSCAN* the default choice for density based clustering.}
}

@article{McInnes2017HdbscanHierarchicalDensity,
  title = {Hdbscan: {{Hierarchical}} Density Based Clustering},
  shorttitle = {Hdbscan},
  author = {McInnes, Leland and Healy, John and Astels, Steve},
  year = {2017},
  month = mar,
  journal = {The Journal of Open Source Software},
  volume = {2},
  number = {11},
  pages = {205},
  issn = {2475-9066},
  doi = {10.21105/joss.00205},
  urldate = {2022-08-02}
}

@article{McNemar1947NoteSamplingError,
  title = {Note on the Sampling Error of the Difference between Correlated Proportions or Percentages},
  author = {McNemar, Quinn},
  year = {1947},
  month = jun,
  journal = {Psychometrika},
  volume = {12},
  number = {2},
  pages = {153--157},
  issn = {1860-0980},
  doi = {10.1007/BF02295996},
  urldate = {2024-04-05},
  abstract = {Two formulas are presented for judging the significance of the difference between correlated proportions. The chi square equivalent of one of the developed formulas is pointed out.},
  langid = {english}
}

@inproceedings{Meilicke2015NewParadigmAlignment,
  title = {New Paradigm for Alignment Extraction.},
  booktitle = {{{OM}}},
  author = {Meilicke, Christian and Stuckenschmidt, Heiner},
  year = {2015},
  pages = {1--12}
}

@inproceedings{Meilicke2019AnytimeBottomUpRule,
  title = {Anytime {{Bottom-Up Rule Learning}} for {{Knowledge Graph Completion}}},
  booktitle = {Proceedings of the {{Twenty-Eighth International Joint Conference}} on {{Artificial Intelligence}} ({{IJCAI}})},
  author = {Meilicke, Christian and Chekol, Melisachew Wudage and Ruffinelli, Daniel and Stuckenschmidt, Heiner},
  year = {2019},
  month = jul,
  pages = {3137--3143},
  doi = {10.24963/ijcai.2019/435},
  urldate = {2020-05-11},
  abstract = {We propose an anytime bottom-up technique for learning logical rules from large knowledge graphs. We apply the learned rules to predict candidates in the context of knowledge graph completion. Our approach outperforms other rule-based approaches and it is competitive with current state of the art, which is based on latent representations. Besides, our approach is significantly faster, requires less computational resources, and yields an explanation in terms of the rules that propose a candidate.}
}

@article{Memoli2011GromovWassersteinDistances,
  title = {Gromov--{{Wasserstein Distances}} and the {{Metric Approach}} to {{Object Matching}}},
  author = {M{\'e}moli, Facundo},
  year = {2011},
  month = aug,
  journal = {Foundations of Computational Mathematics},
  volume = {11},
  number = {4},
  pages = {417--487},
  issn = {1615-3375, 1615-3383},
  doi = {10.1007/s10208-011-9093-5},
  urldate = {2019-01-07},
  langid = {english}
}

@misc{Merriam-Webster2021Argumentation,
  title = {Argumentation},
  author = {{Merriam-Webster}},
  year = {2021},
  month = jan,
  journal = {Merriam-Webster Thesaurus},
  urldate = {2021-01-17},
  abstract = {Argumentation: an exchange of views for the purpose of exploring a subject or deciding an issue. Synonyms: argument, argy-bargy, back-and-forth{\dots} Find the right word.},
  howpublished = {https://www.merriam-webster.com/thesaurus/argumentation},
  langid = {english}
}

@article{Metzinger1999TeachingPhilosophyArgumentation,
  title = {Teaching {{Philosophy}} with {{Argumentation Maps}}: {{Review}} of {{Can Computers Think}}? {{The Debate}} by {{Robert E}}. {{Horn}}},
  shorttitle = {Teaching {{Philosophy}} with {{Argumentation Maps}}},
  author = {Metzinger, Thomas},
  year = {1999},
  journal = {PSYCHE: An Interdisciplinary Journal of Research On Consciousness},
  volume = {5},
  publisher = {Association for the Scientific Study of Consciousness}
}

@inproceedings{Mihalcea2004TextRankBringingOrder,
  title = {{{TextRank}}: {{Bringing Order}} into {{Text}}},
  shorttitle = {{{TextRank}}},
  booktitle = {Proceedings of the 2004 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Mihalcea, Rada and Tarau, Paul},
  year = {2004},
  month = jul,
  pages = {404--411},
  publisher = {Association for Computational Linguistics},
  address = {Barcelona, Spain},
  urldate = {2020-09-08}
}

@article{Mikolov2013EfficientEstimationWord,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year = {2013},
  month = jan,
  journal = {arXiv:1301.3781 [cs]},
  eprint = {1301.3781},
  primaryclass = {cs},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arXiv}
}

@article{Miller1990WordNetOnlineLexical,
  title = {{{WordNet}}: {{An}} on-Line Lexical Database},
  shorttitle = {{{WordNet}}},
  author = {Miller, George A. and Beckwith, Richard and Fellbaum, Christiane and Gross, Derek and Miller, Katherine},
  year = {1990},
  journal = {International Journal of Lexicography},
  volume = {3},
  pages = {235--244},
  abstract = {WordNet is an on-line lexical reference system whose design is inspired by current}
}

@article{Miller1995WordNetLexicalDatabase,
  title = {{{WordNet}}: A Lexical Database for {{English}}},
  shorttitle = {{{WordNet}}},
  author = {Miller, George A.},
  year = {1995},
  month = nov,
  journal = {Communications of the ACM},
  volume = {38},
  number = {11},
  pages = {39--41},
  issn = {0001-0782},
  doi = {10.1145/219717.219748},
  urldate = {2021-01-06},
  abstract = {Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4].}
}

@inproceedings{Minor2010CaseBasedAdaptationWorkflows,
  title = {Towards {{Case-Based Adaptation}} of {{Workflows}}},
  booktitle = {Case-{{Based Reasoning}}. {{Research}} and {{Development}}},
  author = {Minor, Mirjam and Bergmann, Ralph and G{\"o}rg, Sebastian and Walter, Kirstin},
  editor = {Bichindaritz, Isabelle and Montani, Stefania},
  year = {2010},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {421--435},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-14274-1_31},
  abstract = {Creation and adaptation of workflows is a difficult and costly task that is currently performed by human workflow modeling experts. Our paper describes a new approach for the automatic adaptation of workflows, which makes use of a case base of former workflow adaptations. We propose a general framework for case-based adaptation of workflows and then focus on novel methods to represent and reuse previous adaptation episodes for workflows. An empirical evaluation demonstrates the feasibility of the approach and provides valuable insights for future research.},
  isbn = {978-3-642-14274-1},
  langid = {english}
}

@inproceedings{Minor2016TransferabilityProcessOrientedCases,
  title = {On the {{Transferability}} of {{Process-Oriented Cases}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Minor, Mirjam and Bergmann, Ralph and M{\"u}ller, Jan-Martin and Sp{\"a}t, Alexander},
  editor = {Goel, Ashok and {D{\'i}az-Agudo}, M Bel{\'e}n and {Roth-Berghofer}, Thomas},
  year = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {281--294},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-47096-2_19},
  abstract = {This paper studies the feasibility of using transfer learning for process-oriented case-based reasoning. The work introduces a novel approach to transfer workflow cases from a loosely related source domain to a target domain. The idea is to develop a representation mapper based on workflow generalization, workflow abstraction, and structural analogy between the domain vocabularies. The approach is illustrated by a pair of sample domains in two sub-fields of customer relationship management that have similar process objectives but different tasks and data to fulfill them. An experiment with expert ratings of transferred cases is conducted to test the feasibility of the approach with promising results for workflow modeling support.},
  isbn = {978-3-319-47096-2},
  langid = {english}
}

@inproceedings{Minor2024RetrievalAugmentedGeneration,
  title = {Retrieval {{Augmented Generation}} with~{{LLMs}} for~{{Explaining Business Process Models}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Minor, Mirjam and Kaucher, Eduard},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {175--190},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_12},
  abstract = {Large language models (LLMs) and retrieval augmented generation (RAG) are undergoing rapid development. Considering a case base as a memory in a RAG system provides novel opportunities for text generation. In this paper, we investigate the role Case-Based Reasoning (CBR) could play for supporting RAG systems in generating accessible explanations of business process models. We experiment with two different case bases in a RAG system. Case base a) is dedicated to support prompt chaining by reusing index knowledge on the cases with the aim to deal with large process models that do not fit into the context window size of a recent LLM. Second, case base b) contains model-text pairs to serve as in-context examples to enhance prompt templates. Approach b) aims to improve the quality of generated text explanations for process models of normal size. Our contribution opens a novel application area for process-oriented CBR. Further, our case-based RAG system provides a contemporary alternative to traditional Natural Language Processing pipelines. The experimental results contribute to gain some insights on an inherent capability threshold of GPT-4 at which the performance decreases much earlier than having reached the given context window size, on the number of retrieved cases a recent RAG system should use as in-context examples, and on suitable prompt templates.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@inproceedings{Mir2019EvaluatingStyleTransfer,
  title = {Evaluating {{Style Transfer}} for {{Text}}},
  booktitle = {Proceedings of the 2019 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}, {{Volume}} 1 ({{Long}} and {{Short Papers}})},
  author = {Mir, Remi and Felbo, Bjarke and Obradovich, Nick and Rahwan, Iyad},
  year = {2019},
  month = jun,
  pages = {495--504},
  publisher = {Association for Computational Linguistics},
  address = {Minneapolis, Minnesota},
  doi = {10.18653/v1/N19-1049},
  urldate = {2021-05-24},
  abstract = {Research in the area of style transfer for text is currently bottlenecked by a lack of standard evaluation practices. This paper aims to alleviate this issue by experimentally identifying best practices with a Yelp sentiment dataset. We specify three aspects of interest (style transfer intensity, content preservation, and naturalness) and show how to obtain more reliable measures of them from human evaluation than in previous work. We propose a set of metrics for automated evaluation and demonstrate that they are more strongly correlated and in agreement with human judgment: direction-corrected Earth Mover's Distance, Word Mover's Distance on style-masked texts, and adversarial classification for the respective aspects. We also show that the three examined models exhibit tradeoffs between aspects of interest, demonstrating the importance of evaluating style transfer models at specific points of their tradeoff plots. We release software with our evaluation metrics to facilitate research.}
}

@inproceedings{Mirzakhmedova2024AreLargeLanguage,
  title = {Are {{Large Language Models Reliable Argument Quality Annotators}}?},
  booktitle = {Robust {{Argumentation Machines}}},
  author = {Mirzakhmedova, Nailia and Gohsen, Marcel and Chang, Chia Hao and Stein, Benno},
  editor = {Cimiano, Philipp and Frank, Anette and Kohlhase, Michael and Stein, Benno},
  year = {2024},
  pages = {129--146},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63536-6_8},
  abstract = {Evaluating the quality of arguments is a crucial aspect of any system leveraging argument mining. However, it is a challenge to obtain reliable and consistent annotations regarding argument quality, as this usually requires domain-specific expertise of the annotators. Even among experts, the assessment of argument quality is often inconsistent due to the inherent subjectivity of this task. In this paper, we study the potential of using state-of-the-art large language models (LLMs) as proxies for argument quality annotators. To assess the capability of LLMs in this regard, we analyze the agreement between model, human expert, and human novice annotators based on an established taxonomy of argument quality dimensions. Our findings highlight that LLMs can produce consistent annotations, with a moderately high agreement with human experts across most of the quality dimensions. Moreover, we show that using LLMs as additional annotators can significantly improve the agreement between annotators. These results suggest that LLMs can serve as a valuable tool for automated argument quality assessment, thus streamlining and accelerating the evaluation of large argument datasets.},
  isbn = {978-3-031-63536-6},
  langid = {english}
}

@misc{Molnar2020LongitudinalEvaluationOpenSource,
  title = {Longitudinal {{Evaluation}} of {{Open-Source Software Maintainability}}},
  author = {Molnar, Arthur-Jozsef and Motogna, Simona},
  year = {2020},
  month = mar,
  number = {arXiv:2003.00447},
  eprint = {2003.00447},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2003.00447},
  urldate = {2023-10-05},
  abstract = {We present a longitudinal study on the long-term evolution of maintainability in open-source software. Quality assessment remains at the forefront of both software research and practice, with many models and assessment methodologies proposed and used over time. Some of them helped create and shape standards such as ISO 9126 and 25010, which are well established today. Both describe software quality in terms of characteristics such as reliability, security or maintainability. An important body of research exists linking these characteristics with software metrics, and proposing ways to automate quality assessment by aggregating software metric values into higher-level quality models. We employ the Maintainability Index, technical debt ratio and a maintainability model based on the ARiSA Compendium. Our study covers the entire 18 year development history and all released versions for three complex, open-source applications. We determine the maintainability for each version using the proposed models, we compare obtained results and use manual source code examination to put them into context. We examine the common development patterns of the target applications and study the relation between refactoring and maintainability. Finally, we study the strengths and weaknesses of each maintainability model using manual source code examination as the baseline.},
  archiveprefix = {arXiv}
}

@misc{Molnar2020StudyMaintainabilityEvolving,
  title = {A {{Study}} of {{Maintainability}} in {{Evolving Open-Source Software}}},
  author = {Molnar, Arthur-Jozsef and Motogna, Simona},
  year = {2020},
  month = sep,
  number = {arXiv:2009.00959},
  eprint = {2009.00959},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2009.00959},
  urldate = {2023-10-05},
  abstract = {Our study is focused on an evaluation of the maintainability characteristic in the context of the long-term evolution of open-source software. According to well established software quality models such as the ISO 9126 and the more recent ISO 25010, maintainability remains among key quality characteristics alongside performance, security and reliability. To achieve our objective, we selected three complex, widely used target applications for which access to their entire development history and source code was available. To enable cross-application comparison, we restricted our selection to GUI-driven software developed on the Java platform. We focused our examination on released versions, resulting in 111 software releases included in our case study. These covered more than 10 years of development for each of the applications. For each version, we determined its maintainability using three distinct quantitative models of varying complexity. We examined the relation between software size and maintainability and studied the main drivers of important changes to software maintainability. We contextualized our findings using manual source code examination. We also carried out a finer grained evaluation at package level to determine the distribution of maintainability issues within application source code. Finally, we provided a cross-application analysis in order to identify common as well as application-specific patterns.},
  archiveprefix = {arXiv}
}

@misc{Montani2023SpaCyIndustrialstrengthNatural,
  title = {{{spaCy}}: {{Industrial-strength Natural Language Processing}} ({{NLP}}) in {{Python}}},
  author = {Montani, Ines and Honnibal, Matthew and Boyd, Adriane and Landeghem, Sofie Van and Peters, Henning and McCann, Paul O'Leary and {geovedi}, jim and O'Regan, Jim and Samsonov, Maxim and {de Kok}, Dani{\"e}l and Orosz, Gy{\"o}rgy and Bl{\"a}ttermann, Marcus and Kannan, Madeesh and Altinok, Duygu and Mitsch, Raphael and Kristiansen, S{\o}ren Lind and {Edward} and Miranda, Lj and Baumgartner, Peter and Bournhonesque, Rapha{\"e}l and Hudson, Richard and Bot, Explosion and {Roman} and Fiedler, Leander and Daniels, Ryn and {kadarakos} and Phatthiyaphaibun, Wannaphong and {Schero1994}},
  year = {2023},
  month = oct,
  howpublished = {Zenodo}
}

@inproceedings{Moore1982RoleLogicKnowledge,
  title = {The Role of Logic in Knowledge Representation and Commonsense Reasoning},
  booktitle = {Proceedings of the {{Second AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Moore, Robert C.},
  year = {1982},
  month = aug,
  series = {{{AAAI}}'82},
  pages = {428--433},
  publisher = {AAAI Press},
  address = {Pittsburgh, Pennsylvania},
  urldate = {2020-06-07},
  abstract = {This paper examines the role that formal logic ought to play in representing and reasoning with commonsense knowledge. We take issue with the commonly held view (as expressed by Newell [1980]) that the use of representations based on formal logic is inappropriate in most applications of artificial intelligence. We argue to the contrary that there is an important set of issues, involving incomplete knowledge of a problem situation, that so far have been addressed only by systems based on formal logic and deductive inference, and that, in some sense, probably can be dealt with only by systems based on logic and deduction. We further argue that the experiments of the late 1960s on problem-solving by theorem-proving did not show that the use of logic and deduction in AI systems was necessarily inefficient, but rather that what was needed was better control of the deduction process, combined with more attention to the computational properties of axioms.}
}

@article{Mrksic2017SemanticSpecialisationDistributional,
  title = {Semantic {{Specialisation}} of {{Distributional Word Vector Spaces}} Using {{Monolingual}} and {{Cross-Lingual Constraints}}},
  author = {Mrk{\v s}i{\'c}, Nikola and Vuli{\'c}, Ivan and S{\'e}aghdha, Diarmuid {\'O} and Leviant, Ira and Reichart, Roi and Ga{\v s}i{\'c}, Milica and Korhonen, Anna and Young, Steve},
  year = {2017},
  month = jun,
  journal = {arXiv:1706.00374 [cs]},
  eprint = {1706.00374},
  primaryclass = {cs},
  abstract = {We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. Attract-Repel facilitates the use of constraints from mono- and cross-lingual resources, yielding semantically specialised cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct high-quality vector spaces for a plethora of different languages, facilitating semantic transfer from high- to lower-resource ones. The effectiveness of our approach is demonstrated with state-of-the-art results on semantic similarity datasets in six languages. We next show that Attract-Repel-specialised vectors boost performance in the downstream task of dialogue state tracking (DST) across multiple languages. Finally, we show that cross-lingual vector spaces produced by our algorithm facilitate the training of multilingual DST models, which brings further performance improvements.},
  archiveprefix = {arXiv}
}

@inproceedings{Muller2014WorkflowStreamsMeans,
  title = {Workflow {{Streams}}: {{A Means}} for {{Compositional Adaptation}} in {{Process-Oriented CBR}}},
  shorttitle = {Workflow {{Streams}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {M{\"u}ller, Gilbert and Bergmann, Ralph},
  editor = {Lamontagne, Luc and Plaza, Enric},
  year = {2014},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {315--329},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-11209-1_23},
  abstract = {This paper presents a novel approach to compositional adaptation of workflows, thus addressing the adaptation step in processoriented case-based reasoning. Unlike previous approaches to adaptation, the proposed approach does not require additional adaptation knowledge. Instead, the available case base of workflows is analyzed and each case is decomposed into meaningful subcomponents, called workflow streams. During adaptation, deficiencies in the retrieved case are incrementally compensated by replacing fragments of the retrieved case by appropriate workflow streams. An empirical evaluation in the domain of cooking workflows demonstrates the feasibility of the approach and shows that the quality of adapted cases is very close to the quality of the original cases in the case base.},
  isbn = {978-3-319-11209-1},
  langid = {english}
}

@inproceedings{Muller2015GeneralizationWorkflowsProcessOriented,
  title = {Generalization of {{Workflows}} in {{Process-Oriented Case-Based Reasoning}}},
  booktitle = {The {{Twenty-Eighth International Flairs Conference}}},
  author = {M{\"u}ller, Gilbert and Bergmann, Ralph},
  year = {2015},
  month = apr,
  urldate = {2020-09-25},
  abstract = {In this paper, we introduce the concept of generalized cases into process-oriented case-based reasoning. We present the formal foundations for the generalization of workflow cases as well as a new algorithm for generalizing semantic workflows, guided by ontological knowledge of the domain. Further, the specialization of workflows w.r.t. a current query is addressed. An experimental evaluation demonstrates the capability of the approach for workflow adaptation showing that the adapted workflows have a similar quality compared to that of original workflows. Furthermore, the retrieval performance can be improved by a reduction of the case-base size while the coverage of cases is significantly increased.},
  copyright = {Authors who publish a paper in this conference agree to the following terms:  1. Author(s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.  2. The author(s) warrants that they are the sole author and owner of the copyright in the above article/paper, except for those portions shown to be in quotations; that the article/paper is original throughout; and that the undersigned right to make the grants set forth above is complete and unencumbered.  3. The author(s) agree that if anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, the author(s) will hold harmless and indemnify AAAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense AAAI may make to such claim or action. Moreover, the undersigned agrees to cooperate in any claim or other action seeking to protect or enforce any right the undersigned has granted to AAAI in the article/paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, the undersigned agrees to reimburse whomever brings such claim or action for expenses and attorneys\&rsquo; fees incurred therein.  4. Author(s) retain all proprietary rights other than copyright (such as patent rights).  5. Author(s) may make personal reuse of all or portions of the above article/paper in other works of their own authorship.  6. Author(s) may reproduce, or have reproduced, their article/paper for the author\&rsquo;s personal use, or for company use provided that AAAI copyright and the source are indicated, and that the copies are not used in a way that implies AAAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the article/paper in electronic or digital form on any computer network, except by the author or the author\&rsquo;s employer, and then only on the author\&rsquo;s or the employer\&rsquo;s own web page or ftp site. Such web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the AAAI electronic server, and shall not post other AAAI copyrighted materials not of the author\&rsquo;s or the employer\&rsquo;s creation (including tables of contents with links to other papers) without AAAI\&rsquo;s written permission.  7. Author(s) may make limited distribution of all or portions of their article/paper prior to publication.  8. In the case of work performed under U.S. Government contract, AAAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above article/paper, and to authorize others to do so, for U.S. Government purposes.  9. In the event the above article/paper is not accepted and published by AAAI, or is withdrawn by the author(s) before acceptance by AAAI, this agreement becomes null and void.},
  langid = {english}
}

@inproceedings{Muller2015LearningApplyingAdaptation,
  title = {Learning and {{Applying Adaptation Operators}} in {{Process-Oriented Case-Based Reasoning}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {M{\"u}ller, Gilbert and Bergmann, Ralph},
  editor = {H{\"u}llermeier, Eyke and Minor, Mirjam},
  year = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {259--274},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-24586-7_18},
  abstract = {This paper presents a novel approach to the operator-based adaptation of workflows, which is a specific type of transformational adaptation. We introduce the notion of workflow adaptation operators which are partial functions transforming a workflow into a successor workflow, specified by workflow fractions to be inserted and/or deleted. The adaptation process itself chains adaptation operators during a local search process aiming at fulfilling the query as best as possible. Further, the paper presents an algorithm that learns workflow adaptation operators from the case base automatically, thereby addressing the common problem of adaptation knowledge acquisition. An empirical evaluation in the domain of cooking workflows was conducted which demonstrates convincing adaptation capabilities without a significant reduction of the workflows' quality.},
  isbn = {978-3-319-24586-7},
  langid = {english}
}

@article{Mumbaikar2013WebServicesBased,
  title = {Web Services Based on {{SOAP}} and {{REST}} Principles},
  author = {Mumbaikar, Snehal and Padiya, Puja},
  year = {2013},
  month = mar,
  journal = {International Journal of Scientific and Research Publications},
  volume = {3},
  number = {5},
  issn = {2250-3153},
  abstract = {Interest in Web services is rapidly increased from their start of use. To exchange information among the application in standard way is the main goal of web services. This communication between the applications is based on SOAP and REST principle. SOAP communications causes network traffic, higher latency and processing delays. To overcome this limitations the REST'ful architecture is used. REST is a lightweight, easy and better alternative for the SOAP. In this paper comparison on performance of SOAP based and REST'ful web services based on different metric for mobile environment and multimedia conference is taken into consideration.}
}

@incollection{Nesetril2012BoundedHeightTrees,
  title = {Bounded {{Height Trees}} and {{Tree-Depth}}},
  booktitle = {Sparsity: {{Graphs}}, {{Structures}}, and {{Algorithms}}},
  author = {Ne{\v s}et{\v r}il, Jaroslav and {de Mendez}, Patrice Ossona},
  editor = {Ne{\v s}et{\v r}il, Jaroslav and {Ossona de Mendez}, Patrice},
  year = {2012},
  series = {Algorithms and {{Combinatorics}}},
  pages = {115--144},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-27875-4_6},
  urldate = {2022-08-02},
  abstract = {After treating graph classes and class resolutions we return to the basics: the structure of finite trees as the true measure of our things.},
  isbn = {978-3-642-27875-4},
  langid = {english}
}

@book{Newman2015BuildingMicroservicesDesigning,
  title = {Building {{Microservices}}: {{Designing Fine-Grained Systems}}},
  shorttitle = {Building {{Microservices}}},
  author = {Newman, Sam},
  year = {2015},
  month = feb,
  publisher = {O'Reilly Media},
  abstract = {Distributed systems have become more fine-grained in the past 10 years, shifting from code-heavy monolithic applications to smaller, self-contained microservices. But developing these systems brings its own set of headaches. With lots of examples and practical advice, this book takes a holistic view of the topics that system architects and administrators must consider when building, managing, and evolving microservice architectures.Microservice technologies are moving quickly. Author Sam Newman provides you with a firm grounding in the concepts while diving into current solutions for modeling, integrating, testing, deploying, and monitoring your own autonomous services. You'll follow a fictional company throughout the book to learn how building a microservice architecture affects a single domain.Discover how microservices allow you to align your system design with your organization's goalsLearn options for integrating a service with the rest of your systemTake an incremental approach when splitting monolithic codebasesDeploy individual microservices through continuous integrationExamine the complexities of testing and monitoring distributed servicesManage security with user-to-service and service-to-service modelsUnderstand the challenges of scaling microservice architectures},
  googlebooks = {jjl4BgAAQBAJ},
  isbn = {978-1-4919-5033-3},
  langid = {english}
}

@inproceedings{Nguyen2018ArgumentMiningImproving,
  title = {Argument {{Mining}} for {{Improving}} the {{Automated Scoring}} of {{Persuasive Essays}}},
  booktitle = {Thirty-{{Second AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Nguyen, Huy V. and Litman, Diane J.},
  year = {2018},
  month = apr,
  urldate = {2020-06-04},
  abstract = {End-to-end argument mining has enabled the development of new automated essay scoring (AES) systems that use argumentative features (e.g., number of claims, number of support relations) in addition to traditional legacy features (e.g., grammar, discourse structure) when scoring persuasive essays. While prior research has proposed different argumentative features as well as empirically demonstrated their utility for AES, these studies have all had important limitations.  In this paper we identify a set of desiderata for evaluating the use of argument mining for AES, introduce an end-to-end argument mining system and associated argumentative feature sets, and present the results of several studies that both satisfy the desiderata and demonstrate the value-added of argument mining for scoring persuasive essays.},
  copyright = {Authors who publish a paper in this conference agree to the following terms:   Author(s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.  The author(s) warrants that they are the sole author and owner of the copyright in the above article/paper, except for those portions shown to be in quotations; that the article/paper is original throughout; and that the undersigned right to make the grants set forth above is complete and unencumbered.  The author(s) agree that if anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, the author(s) will hold harmless and indemnify AAAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense AAAI may make to such claim or action. Moreover, the undersigned agrees to cooperate in any claim or other action seeking to protect or enforce any right the undersigned has granted to AAAI in the article/paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, the undersigned agrees to reimburse whomever brings such claim or action for expenses and attorneys' fees incurred therein.  Author(s) retain all proprietary rights other than copyright (such as patent rights).  Author(s) may make personal reuse of all or portions of the above article/paper in other works of their own authorship.  Author(s) may reproduce, or have reproduced, their article/paper for the author's personal use, or for company use provided that AAAI copyright and the source are indicated, and that the copies are not used in a way that implies AAAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the article/paper in electronic or digital form on any computer network, except by the author or the author's employer, and then only on the author's or the employer's own web page or ftp site. Such web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the AAAI electronic server, and shall not post other AAAI copyrighted materials not of the author's or the employer's creation (including tables of contents with links to other papers) without AAAI's written permission.  Author(s) may make limited distribution of all or portions of their article/paper prior to publication.  In the case of work performed under U.S. Government contract, AAAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above article/paper, and to authorize others to do so, for U.S. Government purposes.  In the event the above article/paper is not accepted and published by AAAI, or is withdrawn by the author(s) before acceptance by AAAI, this agreement becomes null and void.},
  langid = {english}
}

@misc{NickBabich2020TipsImproveDiscoverability,
  title = {Tips to {{Improve Discoverability}} in {{UX}}},
  author = {{Nick Babich}},
  year = {2020},
  month = apr,
  journal = {Adobe XD Ideas},
  urldate = {2022-05-03},
  abstract = {Help users find important features when interacting with your product with these simple but effective techniques. Read more at Adobe XD Ideas.},
  chapter = {Information Architecture},
  langid = {american}
}

@book{Nielsen1994UsabilityEngineering,
  title = {Usability {{Engineering}}},
  author = {Nielsen, Jakob},
  year = {1994},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco, CA, USA},
  abstract = {Written by the author of the best-selling HyperText \& HyperMedia, this book is an excellent guide to the methods of usability engineering. The book provides the tools needed to avoid usability surprises and improve product quality. Step-by-step information on which method to use at various stages during the development lifecycle are included, along with detailed information on how to run a usability test and the unique issues relating to international usability. * Emphasizes cost-effective methods that developers can implement immediately * Instructs readers about which methods to use when, throughout the development lifecycle, which ultimately helps in cost-benefit analysis. * Shows readers how to avoid the four most frequently listed reasons for delay in software projects. * Includes detailed information on how to run a usability test. * Covers unique issues of international usability. * Features an extensive bibliography allowing readers to find additional information. * Written by an internationally renowned expert in the field and the author of the best-selling HyperText \& HyperMedia. Table of Contents Executive Summary. What is Usability Generations of User Interfaces. The Usability Engineering Lifecycle. Usability Heuristics. Usability Testing. Usability Assessment Methods Beyond Testing. Interface Standards. International User Interfaces. Future Developments. Appendix A: Exercises. Appendix B: Bibliography. Author Index. Subject Index.},
  isbn = {978-0-08-052029-2}
}

@inproceedings{Nikishina2024ExtendingComparativeArgumentative,
  title = {Extending the~{{Comparative Argumentative Machine}}: {{Multilingualism}} and~{{Stance Detection}}},
  shorttitle = {Extending the~{{Comparative Argumentative Machine}}},
  booktitle = {Robust {{Argumentation Machines}}},
  author = {Nikishina, Irina and Bondarenko, Alexander and Zaczek, Sebastian and Haag, Onno Lander and Hagen, Matthias and Biemann, Chris},
  editor = {Cimiano, Philipp and Frank, Anette and Kohlhase, Michael and Stein, Benno},
  year = {2024},
  pages = {317--334},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63536-6_19},
  abstract = {The comparative argumentative machine~CAM can retrieve arguments that answer comparative questions---questions that ask which of several to-be-compared options should be favored in some scenario. In this paper, we describe how we equipped~CAM with a better answer stance detection (i.e., a better detection of which option ``wins'' a comparison) and with system variants to support non-English requests. As for the improved answer stance detection, we develop RoBERTa-based approaches and experimentally show them to be more effective than previous feature-based and LLM-based stance detectors. As for the multilingualism, in a proof of concept, we compare two approaches to support Russian requests and answers: (1)~translating the original English CAM~data and (2)~using an existing replica of CAM on native Russian data. Comparing the translation-based and the replica-based CAM~variants in a user study shows that combining their answers seems to be the most promising. For individual questions, the retrieved arguments of the two variants are often different and of quite diverse relevance and quality. As a demonstrator, we deploy a first multilingual CAM~version that combines translation-based and replica-based outputs for English and Russian and that can easily be extended to further languages.},
  isbn = {978-3-031-63536-6},
  langid = {english}
}

@inproceedings{Nilles2021QuARkGUIQualityAware,
  title = {{{QuARk}}: {{A GUI}} for {{Quality-Aware Ranking}} of {{Arguments}}},
  shorttitle = {{{QuARk}}},
  booktitle = {Proceedings of the 44th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Nilles, Markus and Dumani, Lorik and Schenkel, Ralf},
  year = {2021},
  month = jul,
  series = {{{SIGIR}} '21},
  pages = {2546--2549},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3404835.3462795},
  urldate = {2022-09-26},
  abstract = {With the Web augmenting every day and computers increasingly getting more powerful, research in the field of computational argumentation becomes more and more important. One of its research branches is argument retrieval, which aims at finding and presenting users the best arguments for their queries. Several systems already exist for this purpose, all having the same goal but reaching it in different ways. In line with existing work, an argument consists of a claim supported or attacked by a premise. Now that argument retrieval has become a separate task in the CLEF lab Touch{\'e}, displaying the ranking is becoming increasingly important. In this paper we present QuARk, a GUI that allows users to retrieve arguments from a focused debate collection for their queries. Since we strictly distinguished between frontend and backend and kept the communication between them simple, QuARk can be extended to integrate various argument retrieval systems, assuming some modifications are made. In order to demonstrate the GUI, we show the integration of a complex retrieval algorithm that we also presented in the CLEF lab Touch{\'e}. Our retrieval process consists of two parts. In the first step, it finds the most similar claims to the query. Therefore, the user can select between different standard IR similarity methods. The second step ranks the premises directly related to the claims. Therefore, the user can choose to rank the arguments either by quantitative, qualitative, or a combined measure.},
  isbn = {978-1-4503-8037-9}
}

@inproceedings{Nilles2023TrustMeAm,
  title = {Trust Me, {{I}} Am an {{Expert}}: {{Predicting}} the {{Credibility}} of {{Experts}} for {{Statements}}},
  shorttitle = {Trust Me, {{I}} Am an {{Expert}}},
  booktitle = {Proceedings of the {{Workshops}} at the 31st {{International Conference}} on {{Case-Based Reasoning}} ({{ICCBR-WS}} 2023)},
  author = {Nilles, Markus and Dumani, Lorik and Metzler, Bj{\"o}rn and Schenkel, Ralf},
  editor = {Malburg, Lukas and Verma, Deepika},
  year = {2023},
  month = jul,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3438},
  pages = {114--128},
  publisher = {CEUR},
  address = {Aberdeen, Scotland},
  issn = {1613-0073},
  urldate = {2023-07-31},
  abstract = {Nowadays, information on any topic can be researched on the Internet. However, in addition to reputable news sources, there is also a great deal of fake news that is disseminated, e.g., via social media or in established newspapers. Thus, the veracity must be assessed for each piece of information. People, parties, and organizations want to push through their interests and sometimes do not hesitate to spread fake news. For some time now, one popular means has been to quote (supposed) experts in a field. For example, ---due to his authority--- Albert Einstein is often quoted by believers in God although he was primarily concerned with physics while his quotes on God are taken out of context. In this paper, we define a new task of expert suitability prediction and evaluate methods to assess the credibility of a person with reference to a statement and its context and compare it to state-of-the-art approaches applying transformer-based embeddings. In an R4 cycle in CBR this approach could be used for the ranking. In this pilot study, we restrict our experiments to researchers, which allows us to derive their expertise from their publications. Furthermore, we make a manually labeled dataset consisting of 1,700 (statement,expert) pairs where suitable experts were tediously searched out together with valuable context information (such as convincing text parts of the experts' contexts towards a statement) publicly available to stimulate further research in this very important, but up to now underrepresented area of fake news detection.},
  langid = {english}
}

@inproceedings{Nkisi-Orji2020CloodCBRMicroservices,
  title = {Clood {{CBR}}: {{Towards Microservices Oriented Case-Based Reasoning}}},
  shorttitle = {Clood {{CBR}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {{Nkisi-Orji}, Ikechukwu and Wiratunga, Nirmalie and Palihawadana, Chamath and {Recio-Garc{\'i}a}, Juan A. and Corsar, David},
  editor = {Watson, Ian and Weber, Rosina},
  year = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {129--143},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-58342-2_9},
  abstract = {CBR applications have been deployed in a wide range of sectors, from pharmaceuticals; to defence and aerospace to IoT and transportation, to poetry and music generation; for example. However, a majority of these have been built using monolithic architectures which impose size and complexity constraints. As such these applications have a barrier to adopting new technologies and remain prohibitively expensive in both time and cost because changes in frameworks or languages affect the application directly. To address this challenge, we introduce a distributed and highly scalable generic CBR system, Clood, which is based on a microservices architecture. This splits the application into a set of smaller, interconnected services that scale to meet varying demands. Experimental results show that our Clood implementation retrieves cases at a fairly consistent rate as the casebase grows by several orders of magnitude and was over 3,700 times faster than a comparable monolithic CBR system when retrieving from half a million cases. Microservices are cloud-native architectures and with the rapid increase in cloud-computing adoption, it is timely for the CBR community to have access to such a framework.},
  isbn = {978-3-030-58342-2},
  langid = {english}
}

@inproceedings{Nkisi-Orji2020CloodCBRMicroservicesa,
  title = {Clood {{CBR}}: {{Towards Microservices Oriented Case-Based Reasoning}}},
  shorttitle = {Clood {{CBR}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {{Nkisi-Orji}, Ikechukwu and Wiratunga, Nirmalie and Palihawadana, Chamath and {Recio-Garc{\'i}a}, Juan A. and Corsar, David},
  editor = {Watson, Ian and Weber, Rosina},
  year = {2020},
  pages = {129--143},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-58342-2_9},
  abstract = {CBR applications have been deployed in a wide range of sectors, from pharmaceuticals; to defence and aerospace to IoT and transportation, to poetry and music generation; for example. However, a majority of these have been built using monolithic architectures which impose size and complexity constraints. As such these applications have a barrier to adopting new technologies and remain prohibitively expensive in both time and cost because changes in frameworks or languages affect the application directly. To address this challenge, we introduce a distributed and highly scalable generic CBR system, Clood, which is based on a microservices architecture. This splits the application into a set of smaller, interconnected services that scale to meet varying demands. Experimental results show that our Clood implementation retrieves cases at a fairly consistent rate as the casebase grows by several orders of magnitude and was over 3,700 times faster than a comparable monolithic CBR system when retrieving from half a million cases. Microservices are cloud-native architectures and with the rapid increase in cloud-computing adoption, it is timely for the CBR community to have access to such a framework.},
  isbn = {978-3-030-58342-2},
  langid = {english}
}

@article{Ollinger2020SameSideStance,
  title = {Same {{Side Stance Classification Task}}: {{Facilitating Argument Stance Classification}} by {{Fine-tuning}} a {{BERT Model}}},
  shorttitle = {Same {{Side Stance Classification Task}}},
  author = {Ollinger, Stefan and Dumani, Lorik and Sahitaj, Premtim and Bergmann, Ralph and Schenkel, Ralf},
  year = {2020},
  month = apr,
  journal = {arXiv:2004.11163 [cs]},
  eprint = {2004.11163},
  primaryclass = {cs},
  urldate = {2020-04-27},
  abstract = {Research on computational argumentation is currently being intensively investigated. The goal of this community is to find the best pro and con arguments for a user given topic either to form an opinion for oneself, or to persuade others to adopt a certain standpoint. While existing argument mining methods can find appropriate arguments for a topic, a correct classification into pro and con is not yet reliable. The same side stance classification task provides a dataset of argument pairs classified by whether or not both arguments share the same stance and does not need to distinguish between topic-specific pro and con vocabulary but only the argument similarity within a stance needs to be assessed. The results of our contribution to the task are build on a setup based on the BERT architecture. We fine-tuned a pre-trained BERT model for three epochs and used the first 512 tokens of each argument to predict if two arguments share the same stance.},
  archiveprefix = {arXiv}
}

@misc{OpenAI2024GPT4TechnicalReport,
  title = {{{GPT-4 Technical Report}}},
  author = {OpenAI and Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and Avila, Red and Babuschkin, Igor and Balaji, Suchir and Balcom, Valerie and Baltescu, Paul and Bao, Haiming and Bavarian, Mohammad and Belgum, Jeff and Bello, Irwan and Berdine, Jake and {Bernadett-Shapiro}, Gabriel and Berner, Christopher and Bogdonoff, Lenny and Boiko, Oleg and Boyd, Madelaine and Brakman, Anna-Luisa and Brockman, Greg and Brooks, Tim and Brundage, Miles and Button, Kevin and Cai, Trevor and Campbell, Rosie and Cann, Andrew and Carey, Brittany and Carlson, Chelsea and Carmichael, Rory and Chan, Brooke and Chang, Che and Chantzis, Fotis and Chen, Derek and Chen, Sully and Chen, Ruby and Chen, Jason and Chen, Mark and Chess, Ben and Cho, Chester and Chu, Casey and Chung, Hyung Won and Cummings, Dave and Currier, Jeremiah and Dai, Yunxing and Decareaux, Cory and Degry, Thomas and Deutsch, Noah and Deville, Damien and Dhar, Arka and Dohan, David and Dowling, Steve and Dunning, Sheila and Ecoffet, Adrien and Eleti, Atty and Eloundou, Tyna and Farhi, David and Fedus, Liam and Felix, Niko and Fishman, Sim{\'o}n Posada and Forte, Juston and Fulford, Isabella and Gao, Leo and Georges, Elie and Gibson, Christian and Goel, Vik and Gogineni, Tarun and Goh, Gabriel and {Gontijo-Lopes}, Rapha and Gordon, Jonathan and Grafstein, Morgan and Gray, Scott and Greene, Ryan and Gross, Joshua and Gu, Shixiang Shane and Guo, Yufei and Hallacy, Chris and Han, Jesse and Harris, Jeff and He, Yuchen and Heaton, Mike and Heidecke, Johannes and Hesse, Chris and Hickey, Alan and Hickey, Wade and Hoeschele, Peter and Houghton, Brandon and Hsu, Kenny and Hu, Shengli and Hu, Xin and Huizinga, Joost and Jain, Shantanu and Jain, Shawn and Jang, Joanne and Jiang, Angela and Jiang, Roger and Jin, Haozhun and Jin, Denny and Jomoto, Shino and Jonn, Billie and Jun, Heewoo and Kaftan, Tomer and Kaiser, {\L}ukasz and Kamali, Ali and Kanitscheider, Ingmar and Keskar, Nitish Shirish and Khan, Tabarak and Kilpatrick, Logan and Kim, Jong Wook and Kim, Christina and Kim, Yongjik and Kirchner, Jan Hendrik and Kiros, Jamie and Knight, Matt and Kokotajlo, Daniel and Kondraciuk, {\L}ukasz and Kondrich, Andrew and Konstantinidis, Aris and Kosic, Kyle and Krueger, Gretchen and Kuo, Vishal and Lampe, Michael and Lan, Ikai and Lee, Teddy and Leike, Jan and Leung, Jade and Levy, Daniel and Li, Chak Ming and Lim, Rachel and Lin, Molly and Lin, Stephanie and Litwin, Mateusz and Lopez, Theresa and Lowe, Ryan and Lue, Patricia and Makanju, Anna and Malfacini, Kim and Manning, Sam and Markov, Todor and Markovski, Yaniv and Martin, Bianca and Mayer, Katie and Mayne, Andrew and McGrew, Bob and McKinney, Scott Mayer and McLeavey, Christine and McMillan, Paul and McNeil, Jake and Medina, David and Mehta, Aalok and Menick, Jacob and Metz, Luke and Mishchenko, Andrey and Mishkin, Pamela and Monaco, Vinnie and Morikawa, Evan and Mossing, Daniel and Mu, Tong and Murati, Mira and Murk, Oleg and M{\'e}ly, David and Nair, Ashvin and Nakano, Reiichiro and Nayak, Rajeev and Neelakantan, Arvind and Ngo, Richard and Noh, Hyeonwoo and Ouyang, Long and O'Keefe, Cullen and Pachocki, Jakub and Paino, Alex and Palermo, Joe and Pantuliano, Ashley and Parascandolo, Giambattista and Parish, Joel and Parparita, Emy and Passos, Alex and Pavlov, Mikhail and Peng, Andrew and Perelman, Adam and Peres, Filipe de Avila Belbute and Petrov, Michael and Pinto, Henrique Ponde de Oliveira and Michael and Pokorny and Pokrass, Michelle and Pong, Vitchyr H. and Powell, Tolly and Power, Alethea and Power, Boris and Proehl, Elizabeth and Puri, Raul and Radford, Alec and Rae, Jack and Ramesh, Aditya and Raymond, Cameron and Real, Francis and Rimbach, Kendra and Ross, Carl and Rotsted, Bob and Roussez, Henri and Ryder, Nick and Saltarelli, Mario and Sanders, Ted and Santurkar, Shibani and Sastry, Girish and Schmidt, Heather and Schnurr, David and Schulman, John and Selsam, Daniel and Sheppard, Kyla and Sherbakov, Toki and Shieh, Jessica and Shoker, Sarah and Shyam, Pranav and Sidor, Szymon and Sigler, Eric and Simens, Maddie and Sitkin, Jordan and Slama, Katarina and Sohl, Ian and Sokolowsky, Benjamin and Song, Yang and Staudacher, Natalie and Such, Felipe Petroski and Summers, Natalie and Sutskever, Ilya and Tang, Jie and Tezak, Nikolas and Thompson, Madeleine B. and Tillet, Phil and Tootoonchian, Amin and Tseng, Elizabeth and Tuggle, Preston and Turley, Nick and Tworek, Jerry and Uribe, Juan Felipe Cer{\'o}n and Vallone, Andrea and Vijayvergiya, Arun and Voss, Chelsea and Wainwright, Carroll and Wang, Justin Jay and Wang, Alvin and Wang, Ben and Ward, Jonathan and Wei, Jason and Weinmann, C. J. and Welihinda, Akila and Welinder, Peter and Weng, Jiayi and Weng, Lilian and Wiethoff, Matt and Willner, Dave and Winter, Clemens and Wolrich, Samuel and Wong, Hannah and Workman, Lauren and Wu, Sherwin and Wu, Jeff and Wu, Michael and Xiao, Kai and Xu, Tao and Yoo, Sarah and Yu, Kevin and Yuan, Qiming and Zaremba, Wojciech and Zellers, Rowan and Zhang, Chong and Zhang, Marvin and Zhao, Shengjia and Zheng, Tianhao and Zhuang, Juntang and Zhuk, William and Zoph, Barret},
  year = {2024},
  month = mar,
  number = {arXiv:2303.08774},
  eprint = {2303.08774},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.08774},
  urldate = {2024-06-24},
  abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
  archiveprefix = {arXiv}
}

@inproceedings{Opitz2019DissectingContentContext,
  title = {Dissecting {{Content}} and {{Context}} in {{Argumentative Relation Analysis}}},
  booktitle = {Proceedings of the 6th {{Workshop}} on {{Argument Mining}}},
  author = {Opitz, Juri and Frank, Anette},
  year = {2019},
  month = aug,
  pages = {25--34},
  publisher = {Association for Computational Linguistics},
  address = {Florence, Italy},
  doi = {10.18653/v1/W19-4503},
  urldate = {2020-05-24},
  abstract = {When assessing relations between argumentative units (e.g., support or attack), computational systems often exploit disclosing indicators or markers that are not part of elementary argumentative units (EAUs) themselves, but are gained from their context (position in paragraph, preceding tokens, etc.). We show that this dependency is much stronger than previously assumed. In fact, we show that by completely masking the EAU text spans and only feeding information from their context, a competitive system may function even better. We argue that an argument analysis system that relies more on discourse context than the argument's content is unsafe, since it can easily be tricked. To alleviate this issue, we separate argumentative units from their context such that the system is forced to model and rely on an EAU's content. We show that the resulting classification system is more robust, and argue that such models are better suited for predicting argumentative relations across documents.}
}

@inproceedings{Ottersen2024AutomaticAdjustingGlobal,
  title = {Automatic {{Adjusting Global Similarity Measures}} in~{{Learning CBR Systems}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Ottersen, Stuart G. and Bach, Kerstin},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {17--32},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_2},
  abstract = {This paper explores how learning case-based reasoning (CBR) systems are affected by updating similarity measures. We create CBR systems using the local-global principle and we investigate (1) how adding new cases changes the CBR system's performance and (2) how this drift can be mitigated through updating the similarity measure, especially adapting feature weights for weighted sums. We aim to provide transparent measures to show when the knowledge containers drift apart to indicate when an update is necessary. We, therefore, explore the effect feature weight has on predictive performance and the knowledge containers in online learning CBR systems. Following this, we present a method to minimize updating feature weights while the case base grows while maintaining performance. The performance is compared to two baselines: never updating and always updating. Our experiments with public datasets show that a smart updating strategy catches the drifting of case base content and similarity measures well.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@article{Ouertatani2021ParsingArguedOpinion,
  title = {Parsing Argued Opinion Structure in {{Twitter}} Content},
  author = {Ouertatani, Asma and Gasmi, Ghada and Latiri, Chiraz},
  year = {2021},
  month = apr,
  journal = {Journal of Intelligent Information Systems},
  volume = {56},
  number = {2},
  pages = {327--353},
  issn = {1573-7675},
  doi = {10.1007/s10844-020-00620-x},
  urldate = {2023-10-20},
  abstract = {In this paper, we address the opinion argumentation mining issue from Twitter data with the objective of further analyzing Twitter users' preferences and motivations. After introducing the argued opinion definition and its different elements, we propose an argued opinion mining system called TOMAS where we present an end-to-end approach to parse the structure of the argued opinion in order to identify its elements. Our suggested system consists of four consecutive sub-tasks, namely: (1) opinion-topic detection, (2) argumentative opinions identification, (3) argument components detection, and (4) argumentative relation recognition. The proposed system optimizes the argued opinion structure using different classification models. The experimental study is conducted on the MC2 Lab CLEF2017 tweets corpus while considering various comparative baselines. We highlight that our system significantly outperforms the majority baselines and significantly outperforms challenging existing approaches.},
  langid = {english}
}

@techreport{Page1999PageRankCitationRanking,
  type = {Technical {{Report}}},
  title = {The {{PageRank Citation Ranking}}: {{Bringing Order}} to the {{Web}}.},
  author = {Page, Lawrence and Brin, Sergey and Motwani, Rajeev and Winograd, Terry},
  year = {1999},
  month = nov,
  number = {1999-66},
  institution = {Stanford InfoLab / Stanford InfoLab},
  abstract = {The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said objectively about the relative importance of Web pages. This paper describes PageRank, a mathod for rating Web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random Web surfer. We show how to efficiently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation.}
}

@article{Pan2024UnifyingLargeLanguage,
  title = {Unifying {{Large Language Models}} and {{Knowledge Graphs}}: {{A Roadmap}}},
  shorttitle = {Unifying {{Large Language Models}} and {{Knowledge Graphs}}},
  author = {Pan, Shirui and Luo, Linhao and Wang, Yufei and Chen, Chen and Wang, Jiapu and Wu, Xindong},
  year = {2024},
  month = jul,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {36},
  number = {7},
  pages = {3580--3599},
  issn = {1041-4347, 1558-2191, 2326-3865},
  doi = {10.1109/TKDE.2024.3352100},
  urldate = {2024-09-16},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html}
}

@inproceedings{Parsodkar2025NavigatingLandscapeCase,
  title = {Navigating the~{{Landscape}} of~{{Case Fidelity}} and~{{Competence}} in~{{Case-Based Reasoning}}},
  booktitle = {Artificial {{Intelligence XLI}}},
  author = {Parsodkar, Adwait P. and P., Deepak and Chakraborti, Sutanu},
  editor = {Bramer, Max and Stahl, Frederic},
  year = {2025},
  pages = {235--249},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-77915-2_17},
  abstract = {In this paper, we survey measures aimed at quantifying the intrinsic quality of cases' contents, which we collectively refer to as case fidelity, and measures that capture their competence within the Case-Based Reasoning literature. We discuss how insights from the Truth Discovery and Item Response Theory literature can respectively inform advancements in estimating case fidelity and competence. Additionally, we highlight novel research directions that emerge from a deeper examination of case fidelity and competence.},
  isbn = {978-3-031-77915-2},
  langid = {english}
}

@inproceedings{Passonneau2006MeasuringAgreementSetvalued,
  title = {Measuring {{Agreement}} on {{Set-valued Items}} ({{MASI}}) for {{Semantic}} and {{Pragmatic Annotation}}},
  booktitle = {Proceedings of the {{Fifth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'06)},
  author = {Passonneau, Rebecca},
  year = {2006},
  month = may,
  publisher = {European Language Resources Association (ELRA)},
  address = {Genoa, Italy},
  urldate = {2021-03-07},
  abstract = {Annotation projects dealing with complex semantic or pragmatic phenomena face the dilemma of creating annotation schemes that oversimplify the phenomena, or that capture distinctions conventional reliability metrics cannot measure adequately. The solution to the dilemma is to develop metrics that quantify the decisions that annotators are asked to make. This paper discusses MASI, distance metric for comparing sets, and illustrates its use in quantifying the reliability of a specific dataset. Annotations of Summary Content Units (SCUs) generate models referred to as pyramids which can be used to evaluate unseen human summaries or machine summaries. The paper presents reliability results for five pairs of pyramids created for document sets from the 2003 Document Understanding Conference (DUC). The annotators worked independently of each other. Differences between application of MASI to pyramid annotation and its previous application to co-reference annotation are discussed. In addition, it is argued that a paradigmatic reliability study should relate measures of inter-annotator agreement to independent assessments, such as significance tests of the annotated variables with respect to other phenomena. In effect, what counts as sufficiently reliable intera-annotator agreement depends on the use the annotated data will be put to.}
}

@inproceedings{Paul2020ArgumentativeRelationClassification,
  title = {Argumentative {{Relation Classification}} with {{Background Knowledge}}},
  booktitle = {Proceedings of the 8th {{International Conference}} on {{Computational Models}} of {{Argument}}},
  author = {Paul, Debjit and Opitz, Juri and Becker, Maria and Kobbe, Jonathan and Hirst, Graeme and Frank, Anette},
  editor = {Prakken, Henry and Bistarelli, Stefano and Santini, Francesco and Taticchi, Carlo},
  year = {2020},
  series = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  volume = {326},
  pages = {319--330},
  publisher = {IOS Press},
  address = {Perugia, Italy},
  doi = {10.3233/FAIA200515},
  abstract = {A common conception is that the understanding of relations that hold between argument units requires knowledge beyond the text. But to date, argument analysis systems that leverage knowledge resources are still very rare. In this paper, we propose an unsupervised graph-based ranking method that extracts relevant multi-hop knowledge from a background knowledge resource. This knowledge is integrated into a neural argumentative relation classifier via an attention-based gating mechanism. In contrast to prior work we emphasize the selection of relevant multi-hop knowledge, and apply methods to automatically enrich the knowledge resource with missing knowledge. We assess model performance on two datasets, showing considerable improvement over strong baselines.}
}

@misc{Paun2020DesigningEfficiencyHow,
  title = {Designing {{With Efficiency}}: {{How Familiarity Can Enhance Experiences}}},
  author = {Paun, Goran},
  year = {2020},
  month = oct,
  journal = {Forbes},
  urldate = {2022-05-03},
  abstract = {Our society is continually inspired by innovation. As creatives, it can consequently be tempting to shift from established design conventions in pursuit of originality.},
  howpublished = {https://www.forbes.com/sites/forbesagencycouncil/2020/10/02/designing-with-efficiency-how-familiarity-can-enhance-experiences/},
  langid = {english}
}

@article{Peldszus2013ArgumentDiagramsArgumentation,
  title = {From {{Argument Diagrams}} to {{Argumentation Mining}} in {{Texts}} - {{A Survey}}.},
  author = {Peldszus, Andreas and Stede, Manfred},
  year = {2013},
  month = jan,
  journal = {IJCINI},
  volume = {7},
  number = {1},
  pages = {1--31},
  doi = {10.4018/jcini.2013010101},
  urldate = {2018-09-01}
}

@inproceedings{Peldszus2016AnnotatedCorpusArgumentative,
  title = {An {{Annotated Corpus}} of {{Argumentative Microtexts}}},
  booktitle = {Argumentation and {{Reasoned Action}}: {{Proceedings}} of the 1st {{European Conference}} on {{Argumentation}}},
  author = {Peldszus, Andreas and Stede, Manfred},
  year = {2016},
  volume = {2},
  pages = {801--816},
  publisher = {College Publications},
  address = {Lisbon, Portugal},
  abstract = {We present a freely available corpus of argumentative "microtexts", featuring short and dense authentic arguments, annotated according to a scheme for representing text-level argumentation structure. The corpus consists of 112 German texts plus professional English translations that preserve linearization and argumentative structure. We provide statistics of the variety and the linguistic realization of argumentation structure in the corpus. We hope the data release serves the needs of data-driven approaches to argument mining and qualitative analysis alike.}
}

@inproceedings{Pennington2014GloveGlobalVectors,
  title = {Glove: {{Global Vectors}} for {{Word Representation}}},
  shorttitle = {Glove},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  year = {2014},
  month = oct,
  pages = {1532--1543},
  publisher = {Association for Computational Linguistics},
  address = {Doha, Qatar},
  urldate = {2018-09-04}
}

@inproceedings{Persing2010ModelingOrganizationStudent,
  title = {Modeling {{Organization}} in {{Student Essays}}},
  booktitle = {Proceedings of the 2010 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Persing, Isaac and Davis, Alan and Ng, Vincent},
  year = {2010},
  month = oct,
  pages = {229--239},
  publisher = {Association for Computational Linguistics},
  address = {Cambridge, MA},
  urldate = {2019-11-18}
}

@inproceedings{Persing2015ModelingArgumentStrength,
  title = {Modeling {{Argument Strength}} in {{Student Essays}}},
  booktitle = {Proceedings of the 53rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 7th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  author = {Persing, Isaac and Ng, Vincent},
  year = {2015},
  month = jul,
  pages = {543--552},
  publisher = {Association for Computational Linguistics},
  address = {Beijing, China},
  doi = {10.3115/v1/P15-1053},
  urldate = {2019-11-18}
}

@inproceedings{Petrov2012UniversalPartofSpeechTagset,
  title = {A {{Universal Part-of-Speech Tagset}}},
  booktitle = {Proceedings of the {{Eighth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'12)},
  author = {Petrov, Slav and Das, Dipanjan and McDonald, Ryan},
  year = {2012},
  month = may,
  pages = {2089--2096},
  publisher = {European Language Resources Association (ELRA)},
  address = {Istanbul, Turkey},
  urldate = {2021-02-09},
  abstract = {To facilitate future research in unsupervised induction of syntactic structure and to standardize best-practices, we propose a tagset that consists of twelve universal part-of-speech categories. In addition to the tagset, we develop a mapping from 25 different treebank tagsets to this universal set. As a result, when combined with the original treebank data, this universal tagset and mapping produce a dataset consisting of common parts-of-speech for 22 different languages. We highlight the use of this resource via three experiments, that (1) compare tagging accuracies across languages, (2) present an unsupervised grammar induction approach that does not use gold standard part-of-speech tags, and (3) use the universal tags to transfer dependency parsers between languages, achieving state-of-the-art results.}
}

@mastersthesis{Pfister2017SimilaritybasedRetrievalNatural,
  title = {Similarity-Based {{Retrieval}} of {{Natural Language Argumentation Graphs}}},
  author = {Pfister, Maximiliam},
  year = {2017},
  month = jun,
  abstract = {The retrieval process is usually the first phase in case-based reasoning (CBR) ap- plications and thus represents the basis for subsequent CBR phases such as reuse, revision and retainment. Key tasks to enable the automatic retrieval of cases being similar to a query include the definition of case representations, similarity measures as well as similarity computation and retrieval algorithms suitable for a application domain. In this thesis a concept for the similarity-based retrieval of natural language argumentation graphs is presented, with the overall goal to support users during the deliberation and synthesis of arguments. In particular, graph-based case representa- tions, similarity assessment concepts and retrieval approaches from process-oriented case-based reasoning (POCBR) are transferred to argumentation graphs. A lo- cal similarity measure based on word embeddings is introduced which allows for a similarity assessment independent of the domain of the topic of cases and queries. Furthermore, a two-staged retrieval model is presented which increases both the accuracy and the execution time of the retrieval.},
  school = {University of Trier}
}

@book{Pilehvar2021EmbeddingsNaturalLanguage,
  title = {Embeddings in {{Natural Language Processing}}},
  author = {Pilehvar, Mohammad Taher and {Camacho-Collados}, Jose},
  year = {2021},
  series = {Synthesis {{Lectures}} on {{Human Language Technologies}}},
  edition = {1},
  publisher = {Springer International Publishing},
  urldate = {2022-08-05},
  abstract = {Embeddings have undoubtedly been one of the most influential research areas in Natural Language Processing (NLP). Encoding information into a low-dimensional vector representation, which is easily integrable in modern machine learning models, has played a central role in the development of NLP. Embedding techniques initially focused on words, but the attention soon started to shift to other forms: from graph structures, such as knowledge bases, to other types of textual content, such as sentences and documents. This book provides a high-level synthesis of the main embedding techniques in NLP, in the broad sense. The book starts by explaining conventional word vector space models and word embeddings (e.g., Word2Vec and GloVe) and then moves to other types of embeddings, such as word sense, sentence and document, and graph embeddings. The book also provides an overview of recent developments in contextualized representations (e.g., ELMo and BERT) and explains their potential in NLP. Throughout the book, the reader can find both essential information for understanding a certain topic from scratch and a broad overview of the most successful techniques developed in the literature.},
  isbn = {978-3-031-02177-0},
  langid = {english}
}

@article{Pirro2019BuildingRelatednessExplanations,
  title = {Building Relatedness Explanations from Knowledge Graphs},
  author = {Pirr{\`o}, Giuseppe},
  year = {2019},
  month = jan,
  journal = {Semantic Web},
  volume = {10},
  number = {6},
  pages = {963--990},
  publisher = {IOS Press},
  issn = {1570-0844},
  doi = {10.3233/SW-190348},
  urldate = {2020-08-03},
  abstract = {Knowledge graphs (KGs) are a key ingredient to complement search results, discover entities and their relations and support several knowledge discovery tasks. We face the problem of building relatedness explanations, that is, graphs that can explain},
  langid = {english}
}

@inproceedings{Plenz2024PAKTPerspectivizedArgumentation,
  title = {{{PAKT}}: {{Perspectivized Argumentation Knowledge Graph}} and~{{Tool}} for~{{Deliberation Analysis}}},
  shorttitle = {{{PAKT}}},
  booktitle = {Robust {{Argumentation Machines}}},
  author = {Plenz, Moritz and Heinisch, Philipp and Frank, Anette and Cimiano, Philipp},
  editor = {Cimiano, Philipp and Frank, Anette and Kohlhase, Michael and Stein, Benno},
  year = {2024},
  pages = {89--107},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63536-6_6},
  abstract = {Deliberative processes play a vital role in shaping opinions, decisions and policies in our society. In contrast to persuasive debates, deliberation aims to foster understanding of conflicting perspectives among interested parties. The exchange of arguments in deliberation serves to elucidate viewpoints, to raise awareness of conflicting interests, and to finally converge on a resolution. To better understand and analyze the underlying processes of deliberation, we propose PAKT, a Perspectivized Argumentation Knowledge Graph and Tool. The graph structures the argumentative space across diverse topics, where arguments i) are divided into premises and conclusions, ii) are annotated for stances, framings and their underlying values and iii) are connected to background knowledge. We show how to construct PAKT and conduct case studies on the obtained multifaceted argumentation graph. Our findings show the analytical potential offered by our framework, highlighting the capability to go beyond individual arguments and to reveal structural patterns in the way participants and stakeholders argue in a debate. The overarching goal of our work is to facilitate constructive discourse and informed decision making as a special form of argumentation. We offer public access to PAKT and its rich capabilities to support analytics, visualization, navigation and efficient search, for diverse forms of argumentation (GitHub: www.github.com/Heidelberg-NLP/PAKTWebsite: www.webtentacle1.techfak.uni-bielefeld.de/accept/).},
  isbn = {978-3-031-63536-6},
  langid = {english}
}

@inproceedings{Plisson2004RuleBasedApproach,
  title = {A Rule Based Approach to Word Lemmatization},
  booktitle = {Proceedings of {{IS}}},
  author = {Plisson, Jo{\"e}l and Lavrac, Nada and Mladenic, Dunja},
  year = {2004},
  volume = {3},
  pages = {83--86}
}

@inproceedings{Pojoni2023ArgumentMiningPodcastsUsing,
  title = {Argument-{{Mining}} from {{Podcasts Using ChatGPT}}},
  booktitle = {Proceedings of the {{Workshops}} at the 31st {{International Conference}} on {{Case-Based Reasoning}} ({{ICCBR-WS}} 2023)},
  author = {Pojoni, Mircea-Luchian and Dumani, Lorik and Schenkel, Ralf},
  editor = {Malburg, Lukas and Verma, Deepika},
  year = {2023},
  month = jul,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3438},
  pages = {129--144},
  publisher = {CEUR},
  address = {Aberdeen, Scotland},
  issn = {1613-0073},
  urldate = {2023-07-31},
  abstract = {Podcasts have emerged as a significant platform for the exchange of ideas, opinions, and knowledge on a variety of topics. At the same time, the extraction of arguments (called: argument mining) has received great attention. However, to the best of our knowledge, there exist no work that investigates the extraction of arguments from podcasts. One reason can be that podcasts often involve unpredictable and complex argument structures, and extracting valuable insights from them is challenging. In this work, we present the novel approach of extracting two different types of argumentative structures from podcast after transcribing them, i.e., (1) a simple but often used variant describing arguments as consisting of only a claim and a premise, where the claim describes the standpoint and the premise the reason to support or attack that claim and (2) an extended variant where an argument comprises premises, a main claim, counterarguments, and rebuttals. For this purpose, we utilize two specially designed prompts and OpenAI's GPT-4 language model. For our test data, we chose three podcasts considering current computational constraints and the need for diversity in topics and discussion styles. Our evaluation shows the high feasibility of extracting arguments from podcasts using ChatGPT. We publish the podcasts' transcripts as well as the extracted arguments.},
  langid = {english}
}

@article{Popel2018TrainingTipsTransformer,
  title = {Training {{Tips}} for the {{Transformer Model}}},
  author = {Popel, Martin and Bojar, Ond{\v r}ej},
  year = {2018},
  month = apr,
  journal = {The Prague Bulletin of Mathematical Linguistics},
  volume = {110},
  number = {1},
  pages = {43--70},
  issn = {1804-0462},
  doi = {10.2478/pralin-2018-0002},
  urldate = {2022-01-28},
  abstract = {Abstract             This article describes our experiments in neural machine translation using the recent Tensor2Tensor framework and the Transformer sequence-to-sequence model (Vaswani et al., 2017). We examine some of the critical parameters that affect the final translation quality, memory usage, training stability and training time, concluding each experiment with a set of recommendations for fellow researchers. In addition to confirming the general mantra ``more data and larger models'', we address scaling to multiple GPUs and provide practical tips for improved training regarding batch size, learning rate, warmup steps, maximum sentence length and checkpoint averaging. We hope that our observations will allow others to get better results given their particular hardware and data constraints.}
}

@inproceedings{Popic2016PerformanceEvaluationUsing,
  title = {Performance Evaluation of Using {{Protocol Buffers}} in the {{Internet}} of {{Things}} Communication},
  booktitle = {2016 {{International Conference}} on {{Smart Systems}} and {{Technologies}} ({{SST}})},
  author = {Popi{\'c}, Sr{\dj}an and Pezer, Dra{\v z}en and Mrazovac, Bojan and Tesli{\'c}, Nikola},
  year = {2016},
  month = oct,
  pages = {261--265},
  doi = {10.1109/SST.2016.7765670},
  abstract = {Things connected to the internet may not be connected only to servers on the cloud. Its usefulness can be unleashed only if they are interconnected as well. This interconnection is recognized as communication between services of the Internet of Things. Due to the nature of the things on the web, spatial overhead for any data exchanged needs to be kept to a minimum. JSON is recognized as a most efficient way to transfer various data in domain of distributed embedded systems. JSON's binary representation, BSON is even more preferable. This paper explores the possibilities and critically examines and evaluates the effectiveness of using Google's Protocol Buffer as a processing protocol and communication standard in transportation domain of the Internet of Things.}
}

@misc{Porter2001SnowballLanguageStemming,
  title = {Snowball: {{A}} Language for Stemming Algorithms},
  author = {Porter, Michael},
  year = {2001},
  month = jan,
  urldate = {2018-09-01},
  abstract = {Algorithmic stemmers continue to have great utility in IR, despite the promise of out- performance by dictionary-based stemmers. Nevertheless, there are few algorithmic descriptions of stemmers, and even when they exist they are liable to misinterpretation. Here we look at the ideas underlying stemming, and on this website define a language, Snowball, in which stemmers can be exactly defined, and from which fast stemmer programs in ANSI C or Java can be generated. A range of stemmers is presented in parallel algorithmic and~{\dots}}
}

@inproceedings{Portinale2024IntegratingKNNRetrieval,
  title = {Integrating {{kNN Retrieval}} with~{{Inference}} on~{{Graphical Models}} in~{{Case-Based Reasoning}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Portinale, Luigi},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {1--16},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_1},
  abstract = {In Case-Based Reasoning, when the similarity assumption does not hold, knowledge about the adaptability of solutions has to be exploited, in order to retrieve cases with adaptable solutions. We propose a novel approach to address this issue, where kNN retrieval is integrated with inference on a metric Markov Random Field (MRF). Nodes of the MRF represent cases and edges connect nodes whose solutions are close in the solution space. States of the nodes represent different adaptation levels with respect to the potential query. Metric-based potentials enforce connected nodes to share the same state, since cases having similar solutions should share the same adaptability effort with respect to the query. The goal is to enlarge the set of potentially adaptable cases that are retrieved, by controlling precision and accuracy of retrieval. We experiment on a retrieval architecture where a simple kNN retrieval (on the problem description) is followed by a further retrieval step based on MRF inference, and we discuss the promising results we have obtained in two different setting: using manually-engineered adaptation rules and adopting an automatic learning strategies for such rules.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@incollection{Portoraro2019AutomatedReasoning,
  title = {Automated {{Reasoning}}},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  author = {Portoraro, Frederic},
  editor = {Zalta, Edward N.},
  year = {2019},
  edition = {Spring 2019},
  publisher = {Metaphysics Research Lab, Stanford University},
  urldate = {2021-01-31},
  abstract = {Reasoning is the ability to make inferences, and automated reasoningis concerned with the building of computing systems that automate thisprocess. Although the overall goal is to mechanize different forms ofreasoning, the term has largely been identified with valid deductivereasoning as practiced in mathematics and formal logic. In thisrespect, automated reasoning is akin to mechanical theorem proving.Building an automated reasoning program means providing an algorithmicdescription to a formal calculus so that it can be implemented on acomputer to prove theorems of the calculus in an efficient manner.Important aspects of this exercise involve defining the class ofproblems the program will be required to solve, deciding what languagewill be used by the program to represent the information given to itas well as new information inferred by the program, specifying themechanism that the program will use to conduct deductive inferences,and figuring out how to perform all these computations efficiently.While basic research work continues in order to provide the necessarytheoretical framework, the field has reached a point where automatedreasoning programs are being used by researchers to attack openquestions in mathematics and logic, provide important applications incomputing science, solve problems in engineering, and find novelapproaches to questions in exact philosophy.}
}

@inproceedings{Potthast2019ArgumentSearchAssessing,
  title = {Argument {{Search}}: {{Assessing Argument Relevance}}},
  shorttitle = {Argument {{Search}}},
  booktitle = {Proceedings of the {{42Nd International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Potthast, Martin and Gienapp, Lukas and Euchner, Florian and Heilenk{\"o}tter, Nick and Weidmann, Nico and Wachsmuth, Henning and Stein, Benno and Hagen, Matthias},
  year = {2019},
  series = {{{SIGIR}}'19},
  pages = {1117--1120},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/3331184.3331327},
  urldate = {2019-09-04},
  abstract = {We report on the first user study on assessing argument relevance. Based on a search among more than 300,000 arguments, four standard retrieval models are compared on 40 topics for 20 controversial issues: every issue has one topic with a biased stance and another neutral one. Following TREC, the top results of the different models on a topic were pooled and relevance-judged by one assessor per topic. The assessors also judged the arguments' rhetorical, logical, and dialectical quality, the results of which were cross-referenced with the relevance judgments. Furthermore, the assessors were asked for their personal opinion, and whether it matched the predefined stance of a topic. Among other results, we find that Terrier's implementations of DirichletLM and DPH are on par, significantly outperforming TFIDF and BM25. The judgments of relevance and quality hardly correlate, giving rise to a more diverse set of ranking criteria than relevance alone. We did not measure a significant bias of assessors when their stance is at odds with a topic's stance.},
  isbn = {978-1-4503-6172-9}
}

@inproceedings{Prade2017AnalogicalProportionsAnalogical,
  title = {Analogical {{Proportions}} and {{Analogical Reasoning}} - {{An Introduction}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Prade, Henri and Richard, Gilles},
  editor = {Aha, David W. and Lieber, Jean},
  year = {2017},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {16--32},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-61030-6_2},
  abstract = {Analogical proportions are statements of the form ``a is to b as c is to d''. For more than a decade now, their formalization and use have raised the interest of a number of researchers. In this talk we shall primarily focus on their modeling in logical settings, both in the Boolean and in the multiple-valued cases. This logical view makes clear that analogy is as much a matter of dissimilarity as a matter of similarity. Moreover analogical proportions emerge as being especially remarkable in the framework of logical proportions. The analogical proportion and seven other code independent logical proportions can be shown as being of particular interest. Besides, analogical proportions are at the basis of an inference mechanism which enables us to complete or create a fourth item from three other items. The relation with case-based reasoning and case-based decision is emphasized. Potential applications and current developments are also discussed.},
  isbn = {978-3-319-61030-6},
  langid = {english}
}

@article{Pradeep2024PracticalExplorationConvergence,
  title = {A Practical Exploration of the Convergence of {{Case-Based Reasoning}} and {{Explainable Artificial Intelligence}}},
  author = {Pradeep, Preeja and {Caro-Mart{\'i}nez}, Marta and Wijekoon, Anjana},
  year = {2024},
  month = dec,
  journal = {Expert Systems with Applications},
  volume = {255},
  pages = {124733},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2024.124733},
  urldate = {2024-09-16},
  abstract = {As Artificial Intelligence (AI) systems become increasingly complex, ensuring their decisions are transparent and understandable to users has become paramount. This paper explores the integration of Case-Based Reasoning (CBR) with Explainable Artificial Intelligence (XAI) through a real-world example, which presents an innovative CBR-driven XAI platform. This study investigates how CBR, a method that solves new problems based on the solutions of similar past problems, can be harnessed to enhance the explainability of AI systems. Though the literature has few works on the synergy between CBR and XAI, exploring the principles for developing a CBR-driven XAI platform is necessary. This exploration outlines the key features and functionalities, examines the alignment of CBR principles with XAI goals to make AI reasoning more transparent to users, and discusses methodological strategies for integrating CBR into XAI frameworks. Through a case study of our CBR-driven XAI platform, iSee: Intelligent Sharing of Explanation Experience, we demonstrate the practical application of these principles, highlighting the enhancement of system transparency and user trust. The platform elucidates the decision-making processes of AI models and adapts to provide explanations tailored to diverse user needs. Our findings emphasize the importance of interdisciplinary approaches in AI research and the significant role CBR can play in advancing the goals of XAI.}
}

@article{Prakken2010AbstractFrameworkArgumentation,
  title = {An Abstract Framework for Argumentation with Structured Arguments},
  author = {Prakken, Henry},
  year = {2010},
  month = jun,
  journal = {Argument \& Computation},
  volume = {1},
  number = {2},
  pages = {93--124},
  publisher = {Taylor \& Francis},
  issn = {1946-2166},
  doi = {10.1080/19462160903564592},
  urldate = {2021-02-14},
  abstract = {An abstract framework for structured arguments is presented, which instantiates Dung's (`On the Acceptability of Arguments and its Fundamental Role in Nonmonotonic Reasoning, Logic Programming, and n-Person Games', Artificial Intelligence, 77, 321--357) abstract argumentation frameworks. Arguments are defined as inference trees formed by applying two kinds of inference rules: strict and defeasible rules. This naturally leads to three ways of attacking an argument: attacking a premise, attacking a conclusion and attacking an inference. To resolve such attacks, preferences may be used, which leads to three corresponding kinds of defeat: undermining, rebutting and undercutting defeats. The nature of the inference rules, the structure of the logical language on which they operate and the origin of the preferences are, apart from some basic assumptions, left unspecified. The resulting framework integrates work of Pollock, Vreeswijk and others on the structure of arguments and the nature of defeat and extends it in several respects. Various rationality postulates are proved to be satisfied by the framework, and several existing approaches are proved to be a special case of the framework, including assumption-based argumentation and DefLog.}
}

@article{Prakken2015FormalizationArgumentationSchemes,
  title = {A Formalization of Argumentation Schemes for Legal Case-Based Reasoning in {{ASPIC}}+},
  author = {Prakken, Henry and Wyner, Adam and {Bench-Capon}, Trevor and Atkinson, Katie},
  year = {2015},
  month = oct,
  journal = {Journal of Logic and Computation},
  volume = {25},
  number = {5},
  pages = {1141--1166},
  publisher = {Oxford Academic},
  issn = {0955-792X},
  doi = {10.1093/logcom/ext010},
  urldate = {2020-09-02},
  abstract = {Abstract.  In this article we offer a formal account of reasoning with legal cases in terms of argumentation schemes. These schemes, and undercutting attacks as},
  langid = {english}
}

@misc{PrincetonUniversity2021Morphy,
  title = {Morphy},
  author = {{Princeton University}},
  year = {2021},
  journal = {WordNet Documentation},
  urldate = {2021-03-08},
  howpublished = {https://wordnet.princeton.edu/documentation/morphy7wn}
}

@misc{PrincetonUniversity2021WordNetDatabaseFormat,
  title = {{{WordNet Database Format}}},
  author = {{Princeton University}},
  year = {2021},
  urldate = {2021-02-11},
  howpublished = {https://wordnet.princeton.edu/documentation/wndb5wn}
}

@misc{PrincetonUniversity2021WordNetGlossary,
  title = {{{WordNet Glossary}}},
  author = {{Princeton University}},
  year = {2021},
  urldate = {2021-02-11},
  howpublished = {https://wordnet.princeton.edu/documentation/wngloss7wn}
}

@misc{PrincetonUniversity2021WordNetStatistics,
  title = {{{WordNet Statistics}}},
  author = {{Princeton University}},
  year = {2021},
  journal = {WordNet Documentation},
  urldate = {2021-03-09},
  howpublished = {https://wordnet.princeton.edu/documentation/wnstats7wn}
}

@inproceedings{Qiao2023ReasoningLanguageModel,
  title = {Reasoning with {{Language Model Prompting}}: {{A Survey}}},
  shorttitle = {Reasoning with {{Language Model Prompting}}},
  booktitle = {Proceedings of the 61st {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Qiao, Shuofei and Ou, Yixin and Zhang, Ningyu and Chen, Xiang and Yao, Yunzhi and Deng, Shumin and Tan, Chuanqi and Huang, Fei and Chen, Huajun},
  editor = {Rogers, Anna and {Boyd-Graber}, Jordan and Okazaki, Naoaki},
  year = {2023},
  month = jul,
  pages = {5368--5393},
  publisher = {Association for Computational Linguistics},
  address = {Toronto, Canada},
  doi = {10.18653/v1/2023.acl-long.294},
  urldate = {2024-09-16},
  abstract = {Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically).}
}

@inproceedings{R2021TextDocumentSummarization,
  title = {Text {{Document Summarization Using POS}} Tagging for {{Kannada Text Documents}}},
  booktitle = {2021 11th {{International Conference}} on {{Cloud Computing}}, {{Data Science}} \& {{Engineering}} ({{Confluence}})},
  author = {R, Jayashree and Anami, Basavaraj S and K, Poornima B},
  year = {2021},
  month = jan,
  pages = {423--426},
  doi = {10.1109/Confluence51648.2021.9377106},
  urldate = {2023-10-26},
  abstract = {Humongous amount of data available on the world wide web has been a constant issue pertaining to better Information Retrieval (IR) techniques. Text document summarization is there around for the past several decades, but providing a succinct summary has been challenging as ever. This work focuses on extractive summarization techniques using POS tagging, where the goal is to tag individual words with its parts of speech in a document and do the extractive summarization with more grammatical meaning. The Hidden Markov Model (HMM) is used for tagging the dataset. The idea is to use sentence ranking to produce the summary of a given document. This method of summarization uses the key phrase extraction, where the goal is to select individual words or sentences to tag a document to create text document summary.}
}

@misc{Radensky2024ScideatorHumanLLMScientific,
  title = {Scideator: {{Human-LLM Scientific Idea Generation Grounded}} in {{Research-Paper Facet Recombination}}},
  shorttitle = {Scideator},
  author = {Radensky, Marissa and Shahid, Simra and Fok, Raymond and Siangliulue, Pao and Hope, Tom and Weld, Daniel S.},
  year = {2024},
  month = sep,
  number = {arXiv:2409.14634},
  eprint = {2409.14634},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.14634},
  urldate = {2024-10-19},
  abstract = {The scientific ideation process often involves blending salient aspects of existing papers to create new ideas. To see if large language models (LLMs) can assist this process, we contribute Scideator, a novel mixed-initiative tool for scientific ideation. Starting from a user-provided set of papers, Scideator extracts key facets (purposes, mechanisms, and evaluations) from these and relevant papers, allowing users to explore the idea space by interactively recombining facets to synthesize inventive ideas. Scideator also helps users to gauge idea novelty by searching the literature for potential overlaps and showing automated novelty assessments and explanations. To support these tasks, Scideator introduces four LLM-powered retrieval-augmented generation (RAG) modules: Analogous Paper Facet Finder, Faceted Idea Generator, Idea Novelty Checker, and Idea Novelty Iterator. In a within-subjects user study, 19 computer-science researchers identified significantly more interesting ideas using Scideator compared to a strong baseline combining a scientific search engine with LLM interaction.},
  archiveprefix = {arXiv}
}

@misc{Radford2018ImprovingLanguageUnderstanding,
  title = {Improving Language Understanding by Generative Pre-Training},
  author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year = {2018},
  publisher = {OpenAI},
  abstract = {Natural language understanding comprises a wide range of diverse tasks suchas textual entailment, question answering, semantic similarity assessment, anddocument classification.   Although  large unlabeled  text  corpora are abundant,labeled data for learning these specific tasks is scarce, making it challenging fordiscriminatively trained models to perform adequately. We demonstrate that largegains on these tasks can be realized bygenerative pre-trainingof a language modelon a diverse corpus of unlabeled text, followed bydiscriminative fine-tuningon eachspecific task. In contrast to previous approaches, we make use of task-aware inputtransformations during fine-tuning to achieve effective transfer while requiringminimal changes to the model architecture. We demonstrate the effectiveness ofour approach on a wide range of benchmarks for natural language understanding.Our general task-agnostic model outperforms discriminatively trained models thatuse architectures specifically crafted for each task, significantly improving upon thestate of the art in 9 out of the 12 tasks studied. For instance, we achieve absoluteimprovements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% onquestion answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
  archiveprefix = {OpenAI}
}

@misc{Radford2019LanguageModelsAre,
  title = {Language {{Models}} Are {{Unsupervised Multitask Learners}}},
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year = {2019},
  abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
  langid = {english}
}

@inproceedings{Rahimi2015IncorporatingCoherenceTopics,
  title = {Incorporating {{Coherence}} of {{Topics}} as a {{Criterion}} in {{Automatic Response-to-Text Assessment}} of the {{Organization}} of {{Writing}}},
  booktitle = {Proceedings of the {{Tenth Workshop}} on {{Innovative Use}} of {{NLP}} for {{Building Educational Applications}}},
  author = {Rahimi, Zahra and Litman, Diane and Wang, Elaine and Correnti, Richard},
  year = {2015},
  month = jun,
  pages = {20--30},
  publisher = {Association for Computational Linguistics},
  address = {Denver, Colorado},
  doi = {10.3115/v1/W15-0603},
  urldate = {2019-11-18}
}

@article{Rahwan2007LayingFoundationsWorld,
  title = {Laying the Foundations for a {{World Wide Argument Web}}},
  author = {Rahwan, Iyad and Zablith, Fouad and Reed, Chris},
  year = {2007},
  month = jul,
  journal = {Artificial Intelligence},
  volume = {171},
  number = {10-15},
  pages = {897--921},
  doi = {10.1016/j.artint.2007.04.015},
  urldate = {2018-09-01}
}

@article{Ramos2003UsingTfidfDetermine,
  title = {Using Tf-Idf to Determine Word Relevance in Document Queries},
  author = {Ramos, Juan},
  year = {2003},
  month = jan,
  journal = {cs.rutgers.edu},
  urldate = {2018-09-01},
  abstract = {In this paper, we examine the results of applying Term Frequency Inverse Document Frequency (TF-IDF) to determine what words in a corpus of documents might be more favorable to use in a query. As the term implies, TF-IDF calculates values for each word in a document through an inverse proportion of the frequency of the word in a particular document to the percentage of documents the word appears in. Words with high TF-IDF numbers imply a strong relationship with the document they appear in, suggesting that if that~{\dots}}
}

@inproceedings{Raphael2006DerivationalAnalogyChallenges,
  title = {Derivational {{Analogy}}: {{Challenges}} and {{Opportunities}}},
  shorttitle = {Derivational {{Analogy}}},
  booktitle = {Intelligent {{Computing}} in {{Engineering}} and {{Architecture}}},
  author = {Raphael, B.},
  editor = {Smith, Ian F. C.},
  year = {2006},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {545--553},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11888598_49},
  abstract = {Transformational analogy is currently more widely employed than derivational analogy in CBR applications, even though the latter has significant advantages over the former. The main reason for the reluctance to use derivational analogy is the complexity of representation. Other factors include issues related to retrieval and difficulties in system validation. Means of addressing these issues are described in this paper. Unique opportunities offered by the approach are illustrated with examples.},
  isbn = {978-3-540-46247-7},
  langid = {english}
}

@mastersthesis{Ravindran2024TextGenerationArgument,
  title = {Text {{Generation}} from {{Argument Graphs}} with {{User-Generated Content}}},
  author = {Ravindran, Nila},
  year = {2024},
  month = may,
  address = {Trier, Germany},
  abstract = {This thesis addresses the challenge of converting user-generated arguments into coherent textual representations. While traditional sources like newspaper articles or scientific journals have a plain text representation, user-generated content lacks such textual counterparts, posing a challenge for generating and assessing textual representations. For this purpose, our approach delves into unsupervised summarization, exploring both extractive and abstractive methods. Our goal is to create concise yet comprehensive summaries of user-generated arguments. Specifically, we concentrate on arguments sourced from the Kialo platform, which hosts debates structured hierarchically---a specialized form of argument graphs. Our research investigates various methods for conveying the structural information inherent in these argument graphs, leveraging pre-trained language models to generate summaries. Through human evaluation, we found a notable preference for abstractive summaries, with gpt-4 Turbo model exhibiting promising performance. Furthermore, we found that representing argument graphs using structured formats such as JSON yields better results compared to alternative strategies.},
  langid = {english},
  school = {Trier University}
}

@inproceedings{Recio-Garcia2021CaseBasedApproachSelection,
  title = {A {{Case-Based Approach}} for the {{Selection}} of {{Explanation Algorithms}} in {{Image Classification}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {{Recio-Garc{\'i}a}, Juan A. and {Parejas-Llanovarced}, Humberto and {Orozco-del-Castillo}, Mauricio G. and {Brito-Borges}, Esteban E.},
  editor = {{S{\'a}nchez-Ruiz}, Antonio A. and Floyd, Michael W.},
  year = {2021},
  pages = {186--200},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-86957-1_13},
  abstract = {Research on eXplainable AI (XAI) is continuously proposing novel approaches for the explanation of image classification models, where we can find both model-dependent and model-independent strategies. However, it is unclear how to choose the best explanation approach for a given image, as these novel XAI approaches are radically different. In this paper, we propose a CBR solution to the problem of choosing the best alternative for the explanation of an image classifier. The case base reflects the human perception of the quality of the explanations generated with different image explanation methods. Then, this experience is reused to select the best explanation approach for a given image.},
  isbn = {978-3-030-86957-1},
  langid = {english}
}

@book{Recio-Garcia2024CaseBasedReasoningResearch,
  title = {Case-{{Based Reasoning Research}} and {{Development}}: 32nd {{International Conference}}, {{ICCBR}} 2024, {{Merida}}, {{Mexico}}, {{July}} 1--4, 2024, {{Proceedings}}},
  shorttitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {14775},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2},
  urldate = {2024-06-26},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-031-63645-5 978-3-031-63646-2},
  langid = {english}
}

@inproceedings{Reed1996ArchitectureArgumentativeDialogue,
  title = {An Architecture for Argumentative Dialogue Planning},
  booktitle = {Practical {{Reasoning}}},
  author = {Reed, Chris and Long, Derek and Fox, Maria},
  editor = {Gabbay, Dov M. and Ohlbach, Hans J{\"u}rgen},
  year = {1996},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {555--566},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-61313-7_100},
  abstract = {Argument represents an opportunity for a system to convince a possibly sceptical or resistant audience of the veracity of its own beliefs. This ability is a vital component of rich communication, facilitating explanation, instruction, cooperation and conflict resolution. In this paper, a proposal is presented for the architecture of a system capable of constructing arguments. The design of the architecture has made use of the wealth of naturally occurring argument, which, unlike much natural language, is particularly suited to analysis due to its clear aims and structure. The proposed framework is based upon a core hierarchical planner conceptually split into four levels of processing, the highest being responsible for abstract, intentional and pragmatic guidance, and the lowest handling realisation into natural language. The higher levels will have control over not just the logical form of the argument, but also over matters of style and rhetoric, in order to produce as cogent and convincing an argument as possible.},
  isbn = {978-3-540-68454-1},
  langid = {english}
}

@article{Reed2001ApplicationsArgumentationSchemes,
  title = {Applications of {{Argumentation Schemes}}},
  author = {Reed, Chris and Walton, Doug},
  year = {2001},
  month = may,
  journal = {OSSA Conference Archive}
}

@article{Reed2004AraucariaSoftwareArgument,
  title = {Araucaria: Software for Argument Analysis, Diagramming and Representation},
  shorttitle = {Araucaria},
  author = {Reed, Chris and Rowe, Glenn},
  year = {2004},
  month = dec,
  journal = {International Journal on Artificial Intelligence Tools},
  volume = {13},
  number = {04},
  pages = {961--979},
  publisher = {World Scientific Publishing Co.},
  issn = {0218-2130},
  doi = {10.1142/S0218213004001922},
  urldate = {2022-04-21},
  abstract = {Argumentation theory involves the analysis of naturally occurring argument, and one key tool employed to this end both in the academic community and in teaching critical thinking skills to undergraduates is argument diagramming. By identifying the structure of an argument in terms of its constituents and the relationships between them, it becomes easier to critically evaluate each part of an argument in turn. The task of analysis and diagramming, however, is labor intensive and often idiosyncratic, which can make academic exchange difficult. The Araucaria system provides an interface which supports the diagramming process, and then saves the result using AML, an open standard, designed in XML, for describing argument structure. Araucaria aims to be of use not only in pedagogical situations, but also in support of research activity. As a result, it has been designed from the outset to handle more advanced argumentation theoretic concepts such as schemes, which capture stereotypical patterns of reasoning. The software is also designed to be compatible with a number of applications under development, including dialogic interaction and online corpus provision. Together, these features, combined with its platform independence and ease of use, have the potential to make Araucaria a valuable resource for the academic community.}
}

@book{Reed2004ArgumentationMachines,
  title = {Argumentation {{Machines}}},
  editor = {Reed, Chris and Norman, Timothy J. and {van Eemeren}, Frans H. and Jacobs, Scott and Krabbe, Erik C. W. and Woods, John},
  year = {2004},
  series = {Argumentation {{Library}}},
  volume = {9},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-017-0431-1},
  urldate = {2019-09-14},
  isbn = {978-94-017-0431-1}
}

@incollection{Reed2004RoadmapResearchArgument,
  title = {A {{Roadmap}} of {{Research}} in {{Argument}} and {{Computation}}},
  booktitle = {Argumentation {{Machines}}: {{New Frontiers}} in {{Argument}} and {{Computation}}},
  author = {Reed, Chris and Norman, Timothy J.},
  editor = {Reed, Chris and Norman, Timothy J.},
  year = {2004},
  series = {Argumentation {{Library}}},
  pages = {1--13},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-017-0431-1_1},
  urldate = {2023-11-22},
  abstract = {The aim of this chapter is to lay out a roadmap of artificial intelligence and argumentation research, summarising the key points in the development of the interdisciplinary field. By showing where such collaboration has been successful, it becomes easier to see the points at which renewed interaction between the fields might yield substantial gains. These points of potential growth are then briefly discussed to motivate and position the work described in the subsequent chapters.},
  isbn = {978-94-017-0431-1},
  langid = {english}
}

@inproceedings{Reed2006PreliminaryResultsArgument,
  title = {Preliminary Results from an Argument Corpus},
  booktitle = {In {{Elo{\'i}na Miyares Berm{\'u}dez}} \& {{Leonel Ruiz Miyares}} ({{Eds}}), {{Linguistics}} in the Twenty-First Century},
  author = {Reed, Chris},
  year = {2006},
  pages = {185--196},
  publisher = {Scholars Press},
  abstract = {Abstract. As reported in (Katzav et al., 2003), the University of Dundee has been developing a small corpus of examples of argumentation from a variety of domains (newspaper editorials, advertising, parliamentary records,}
}

@inproceedings{Reed2008AIFDialogueArgument,
  title = {{{AIF}}+: Dialogue in the Argument Interchange Format},
  shorttitle = {{{AIF}}+},
  booktitle = {Computational {{Models}} of {{Argument}}: {{Proceedings}} of {{COMMA}} 2008},
  author = {Reed, Chris and Wells, Simon and Devereux, Joseph and Rowe, Glenn},
  editor = {Besnard, Philippe and Doutre, Sylvie and Hunter, Anthony},
  year = {2008},
  series = {Frontiers in Artificial Intelligence and Applications},
  pages = {311--323},
  publisher = {IOS Press},
  address = {Amsterdam},
  urldate = {2022-04-22},
  abstract = {This paper extends the Argument Interchange Format to enable it to represent dialogic argumentation. One of the challenges is to tie together the rules expressed in dialogue protocols with the inferential relations between premises and conclusions. The extensions are founded upon two important analogies which minimise the extra ontological machinery required. First, locutions in a dialogue are analogous to AIF I-nodes which capture propositional data. Second, steps between locutions are analogous to AIF S-nodes which capture inferential movement. This paper shows how these two analogies combine to allow both dialogue protocols and dialogue histories to be represented alongside monologic arguments in a single coherent system.}
}

@inproceedings{Reed2012HowDialoguesCreate,
  title = {How Dialogues Create Arguments},
  booktitle = {Proceedings of the 7th {{Conference}} of the {{International Society}} for the {{Study}} of {{Argumentation}} ({{ISSA}} 2010)},
  author = {Reed, C and Budzynska, Katarzyna},
  editor = {{van Eemeren}, F H},
  year = {2012},
  address = {Amsterdam},
  langid = {english}
}

@misc{Reed2016IATAnnotationGuidelines,
  title = {{{IAT}} Annotation Guidelines for {{US2016}}},
  author = {Reed, Chris and Budzynska, Katarzyna and Visser, Jacky},
  year = {2016},
  month = sep,
  urldate = {2024-09-16},
  langid = {english}
}

@article{Reed2017ArgumentWebOnline,
  title = {The {{Argument Web}}: An {{Online Ecosystem}} of {{Tools}}, {{Systems}} and {{Services}} for {{Argumentation}}},
  author = {Reed, Chris and Budzynska, Katarzyna and Duthie, Rory and Janier, Mathilde and Konat, Barbara and Lawrence, John and Pease, Alison and Snaith, Mark},
  year = {2017},
  month = jan,
  journal = {Philosophy \& Technology},
  volume = {30},
  number = {2},
  pages = {137--160},
  doi = {10.1007/s13347-017-0260-8},
  urldate = {2018-09-01},
  abstract = {The Argument Web is maturing as both a platform built upon a synthesis of many contemporary theories of argumentation in philosophy and also as an ecosystem in which various applications and...}
}

@inproceedings{Reimers2019ClassificationClusteringArguments,
  title = {Classification and {{Clustering}} of {{Arguments}} with {{Contextualized Word Embeddings}}},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Reimers, Nils and Schiller, Benjamin and Beck, Tilman and Daxenberger, Johannes and Stab, Christian and Gurevych, Iryna},
  year = {2019},
  month = jul,
  pages = {567--578},
  publisher = {Association for Computational Linguistics},
  address = {Florence, Italy},
  doi = {10.18653/v1/P19-1054},
  urldate = {2020-09-02},
  abstract = {We experiment with two recent contextualized word embedding methods (ELMo and BERT) in the context of open-domain argument search. For the first time, we show how to leverage the power of contextualized word embeddings to classify and cluster topic-dependent arguments, achieving impressive results on both tasks and across multiple datasets. For argument classification, we improve the state-of-the-art for the UKP Sentential Argument Mining Corpus by 20.8 percentage points and for the IBM Debater - Evidence Sentences dataset by 7.4 percentage points. For the understudied task of argument clustering, we propose a pre-training step which improves by 7.8 percentage points over strong baselines on a novel dataset, and by 12.3 percentage points for the Argument Facet Similarity (AFS) Corpus.}
}

@inproceedings{Reimers2019SentenceBERTSentenceEmbeddings,
  title = {Sentence-{{BERT}}: {{Sentence Embeddings}} Using {{Siamese BERT-Networks}}},
  shorttitle = {Sentence-{{BERT}}},
  booktitle = {Proceedings of the 2019 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} and the 9th {{International Joint Conference}} on {{Natural Language Processing}} ({{EMNLP-IJCNLP}})},
  author = {Reimers, Nils and Gurevych, Iryna},
  year = {2019},
  month = nov,
  pages = {3982--3992},
  publisher = {Association for Computational Linguistics},
  address = {Hong Kong, China},
  doi = {10.18653/v1/D19-1410},
  urldate = {2020-05-15},
  abstract = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textbackslash}textasciitilde65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.}
}

@article{Reimers2020MakingMonolingualSentence,
  title = {Making {{Monolingual Sentence Embeddings Multilingual}} Using {{Knowledge Distillation}}},
  author = {Reimers, Nils and Gurevych, Iryna},
  year = {2020},
  month = apr,
  journal = {arXiv:2004.09813 [cs]},
  eprint = {2004.09813},
  primaryclass = {cs},
  urldate = {2020-05-15},
  abstract = {We present an easy and efficient method to extend existing sentence embedding models to new languages. This allows to create multilingual versions from previously monolingual models. The training is based on the idea that a translated sentence should be mapped to the same location in the vector space as the original sentence. We use the original (monolingual) model to generate sentence embeddings for the source language and then train a new system on translated sentences to mimic the original model. Compared to other methods for training multilingual sentence embeddings, this approach has several advantages: It is easy to extend existing models with relatively few samples to new languages, it is easier to ensure desired properties for the vector space, and the hardware requirements for training is lower. We demonstrate the effectiveness of our approach for 10 languages from various language families. Code to extend sentence embeddings models to more than 400 languages is publicly available.},
  archiveprefix = {arXiv}
}

@inproceedings{Ren2024SurveyLargeLanguage,
  title = {A {{Survey}} of {{Large Language Models}} for {{Graphs}}},
  booktitle = {Proceedings of the 30th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ren, Xubin and Tang, Jiabin and Yin, Dawei and Chawla, Nitesh and Huang, Chao},
  year = {2024},
  month = aug,
  series = {{{KDD}} '24},
  pages = {6616--6626},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3637528.3671460},
  urldate = {2024-09-16},
  abstract = {Graphs are an essential data structure utilized to represent relationships in real-world scenarios. Prior research has established that Graph Neural Networks (GNNs) deliver impressive outcomes in graph-centric tasks, such as link prediction and node classification. Despite these advancements, challenges like data sparsity and limited generalization capabilities continue to persist. Recently, Large Language Models (LLMs) have gained attention in natural language processing. They excel in language comprehension and summarization. Integrating LLMs with graph learning techniques has attracted interest as a way to enhance performance in graph learning tasks. In this survey, we conduct an in-depth review of the latest state-of-the-art LLMs applied in graph learning and introduce a novel taxonomy to categorize existing methods based on their framework design. We detail four unique designs: i) GNNs as Prefix, ii) LLMs as Prefix, iii) LLMs-Graphs Integration, and iv) LLMs-Only, highlighting key methodologies within each category. We explore the strengths and limitations of each framework, and emphasize potential avenues for future research, including overcoming current integration challenges between LLMs and graph learning techniques, and venturing into new application areas. This survey aims to serve as a valuable resource for researchers and practitioners eager to leverage large language models in graph learning, and to inspire continued progress in this dynamic field. We consistently maintain the related open-source materials at https://github.com/HKUDS/Awesome-LLM4Graph-Papers.},
  isbn = {979-8-4007-0490-1}
}

@misc{Rescala2024CanLanguageModels,
  title = {Can {{Language Models Recognize Convincing Arguments}}?},
  author = {Rescala, Paula and Ribeiro, Manoel Horta and Hu, Tiancheng and West, Robert},
  year = {2024},
  month = mar,
  number = {arXiv:2404.00750},
  eprint = {2404.00750},
  primaryclass = {cs},
  urldate = {2024-04-02},
  abstract = {The remarkable and ever-increasing capabilities of Large Language Models (LLMs) have raised concerns about their potential misuse for creating personalized, convincing misinformation and propaganda. To gain insights into LLMs' persuasive capabilities without directly engaging in experimentation with humans, we propose studying their performance on the related task of detecting convincing arguments. We extend a dataset by Durmus \& Cardie (2018) with debates, votes, and user traits and propose tasks measuring LLMs' ability to (1) distinguish between strong and weak arguments, (2) predict stances based on beliefs and demographic characteristics, and (3) determine the appeal of an argument to an individual based on their traits. We show that LLMs perform on par with humans in these tasks and that combining predictions from different LLMs yields significant performance gains, even surpassing human performance. The data and code released with this paper contribute to the crucial ongoing effort of continuously evaluating and monitoring the rapidly evolving capabilities and potential impact of LLMs.},
  archiveprefix = {arXiv}
}

@misc{Rescala2024CanLanguageModelsa,
  title = {Can {{Language Models Recognize Convincing Arguments}}?},
  author = {Rescala, Paula and Ribeiro, Manoel Horta and Hu, Tiancheng and West, Robert},
  year = {2024},
  month = mar,
  number = {arXiv:2404.00750},
  eprint = {2404.00750},
  primaryclass = {cs},
  doi = {10.48550/arXiv.2404.00750},
  urldate = {2024-09-23},
  abstract = {The remarkable and ever-increasing capabilities of Large Language Models (LLMs) have raised concerns about their potential misuse for creating personalized, convincing misinformation and propaganda. To gain insights into LLMs' persuasive capabilities without directly engaging in experimentation with humans, we propose studying their performance on the related task of detecting convincing arguments. We extend a dataset by Durmus \& Cardie (2018) with debates, votes, and user traits and propose tasks measuring LLMs' ability to (1) distinguish between strong and weak arguments, (2) predict stances based on beliefs and demographic characteristics, and (3) determine the appeal of an argument to an individual based on their traits. We show that LLMs perform on par with humans in these tasks and that combining predictions from different LLMs yields significant performance gains, even surpassing human performance. The data and code released with this paper contribute to the crucial ongoing effort of continuously evaluating and monitoring the rapidly evolving capabilities and potential impact of LLMs.},
  archiveprefix = {arXiv}
}

@article{Resnik1995UsingInformationContent,
  title = {Using {{Information Content}} to {{Evaluate Semantic Similarity}} in a {{Taxonomy}}},
  author = {Resnik, Philip},
  year = {1995},
  month = nov,
  journal = {arXiv:cmp-lg/9511007},
  eprint = {cmp-lg/9511007},
  abstract = {This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66).},
  archiveprefix = {arXiv}
}

@article{Ribeiro2020InvestigatingPretrainedLanguage,
  title = {Investigating {{Pretrained Language Models}} for {{Graph-to-Text Generation}}},
  author = {Ribeiro, Leonardo F. R. and Schmitt, Martin and Sch{\"u}tze, Hinrich and Gurevych, Iryna},
  year = {2020},
  month = jul,
  journal = {arXiv:2007.08426 [cs]},
  eprint = {2007.08426},
  primaryclass = {cs},
  urldate = {2020-10-16},
  abstract = {Graph-to-text generation, a subtask of data-to-text generation, aims to generate fluent texts from graph-based data. Many graph-to-text models have shown strong performance in this task employing specialized graph encoders. However, recent approaches employ large pretrained language models (PLMs) achieving state-of-the-art results in data-to-text generation. In this paper, we aim to investigate the impact of large PLMs in graph-to-text generation. We present a study across three graph domains: meaning representations, Wikipedia knowledge graphs (KGs) and scientific KGs. Our analysis shows that PLMs such as BART and T5 achieve state-of-the-art results in graph-to-text benchmarks without explicitly encoding the graph structure. We also demonstrate that task-adaptive pretraining strategies are beneficial to the target task, improving even further the state of the art in two benchmarks for graph-to-text generation. In a final analysis, we investigate possible reasons for the PLMs' success on graph-to-text tasks. We find evidence that their knowledge about the world gives them a big advantage, especially when generating texts from KGs.},
  archiveprefix = {arXiv}
}

@inproceedings{Ribeiro2022FactGraphEvaluatingFactuality,
  title = {{{FactGraph}}: {{Evaluating Factuality}} in {{Summarization}} with {{Semantic Graph Representations}}},
  shorttitle = {{{FactGraph}}},
  booktitle = {Proceedings of the 2022 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  author = {Ribeiro, Leonardo F. R. and Liu, Mengwen and Gurevych, Iryna and Dreyer, Markus and Bansal, Mohit},
  editor = {Carpuat, Marine and {de Marneffe}, Marie-Catherine and Meza Ruiz, Ivan Vladimir},
  year = {2022},
  month = jul,
  pages = {3238--3253},
  publisher = {Association for Computational Linguistics},
  address = {Seattle, United States},
  doi = {10.18653/v1/2022.naacl-main.236},
  urldate = {2024-10-31},
  abstract = {Despite recent improvements in abstractive summarization, most current approaches generate summaries that are not factually consistent with the source document, severely restricting their trust and usage in real-world applications. Recent works have shown promising improvements in factuality error identification using text or dependency arc entailments; however, they do not consider the entire semantic graph simultaneously. To this end, we propose FactGraph, a method that decomposes the document and the summary into structured meaning representations (MR), which are more suitable for factuality evaluation. MRs describe core semantic concepts and their relations, aggregating the main content in both document and summary in a canonical form, and reducing data sparsity. FactGraph encodes such graphs using a graph encoder augmented with structure-aware adapters to capture interactions among the concepts based on the graph connectivity, along with text representations using an adapter-based text encoder. Experiments on different benchmarks for evaluating factuality show that FactGraph outperforms previous approaches by up to 15\%. Furthermore, FactGraph improves performance on identifying content verifiability errors and better captures subsentence-level factual inconsistencies.}
}

@book{Richter2013CaseBasedReasoningTextbook,
  title = {Case-{{Based Reasoning}}: {{A Textbook}}},
  shorttitle = {Case-{{Based Reasoning}}},
  author = {Richter, Michael M. and Weber, Rosina},
  year = {2013},
  publisher = {Springer-Verlag},
  address = {Berlin Heidelberg},
  doi = {10.1007/978-3-642-40167-1},
  urldate = {2020-09-02},
  abstract = {While it is relatively easy to record billions of experiences in a database, the wisdom of a system is not measured by the number of its experiences but rather by its ability to make use of them. Case-based rea\-soning (CBR) can be viewed as experience mining, with analogical reasoning applied to problem--solution pairs. As cases are typically not identical, simple storage and recall of experiences is not sufficient, we must define and analyze similarity and adaptation. The fundamentals of the approach are now well-established, and there are many successful commercial applications in diverse fields, attracting interest from researchers across various disciplines. This textbook presents case-based reasoning in a systematic approach with two goals: to present rigorous and formally valid structures for precise reasoning, and to demonstrate the range of techniques, methods, and tools available for many applications. In the chapters in Part I the authors present the basic elements of CBR without assuming prior reader knowledge; Part II explains the core methods, in particu\-lar case representations, similarity topics, retrieval, adaptation, evaluation, revisions, learning, develop\-ment, and maintenance; Part III offers advanced views of these topics, additionally covering uncertainty and probabilities; and Part IV shows the range of knowledge sources, with chapters on textual CBR, im\-ages, sensor data and speech, conversational CBR, and knowledge management. The book concludes with appendices that offer short descriptions of the basic formal definitions and methods, and comparisons be\-tween CBR and other techniques. The authors draw on years of teaching and training experience in academic and business environments, and they employ chapter summaries, background notes, and exercises throughout the book. It's suitable for advanced undergraduate and graduate students of computer science, management, and related disciplines, and it's also a practical introduction and guide for industrial researchers and practitioners engaged with knowledge engineering systems.},
  isbn = {978-3-642-40166-4},
  langid = {english}
}

@article{Riesen2009ApproximateGraphEdit,
  title = {Approximate Graph Edit Distance Computation by Means of Bipartite Graph Matching},
  author = {Riesen, Kaspar and Bunke, Horst},
  year = {2009},
  month = jun,
  journal = {Image and Vision Computing},
  series = {7th {{IAPR-TC15 Workshop}} on {{Graph-based Representations}} ({{GbR}} 2007)},
  volume = {27},
  number = {7},
  pages = {950--959},
  issn = {0262-8856},
  doi = {10.1016/j.imavis.2008.04.004},
  urldate = {2022-05-05},
  abstract = {In recent years, the use of graph based object representation has gained popularity. Simultaneously, graph edit distance emerged as a powerful and flexible graph matching paradigm that can be used to address different tasks in pattern recognition, machine learning, and data mining. The key advantages of graph edit distance are its high degree of flexibility, which makes it applicable to any type of graph, and the fact that one can integrate domain specific knowledge about object similarity by means of specific edit cost functions. Its computational complexity, however, is exponential in the number of nodes of the involved graphs. Consequently, exact graph edit distance is feasible for graphs of rather small size only. In the present paper we introduce a novel algorithm which allows us to approximately, or suboptimally, compute edit distance in a substantially faster way. The proposed algorithm considers only local, rather than global, edge structure during the optimization process. In experiments on different datasets we demonstrate a substantial speed-up of our proposed method over two reference systems. Moreover, it is emprically verified that the accuracy of the suboptimal distance remains sufficiently accurate for various pattern recognition applications.},
  langid = {english}
}

@book{Rijsbergen1979InformationRetrieval,
  title = {Information {{Retrieval}}},
  author = {Rijsbergen, C. J. Van},
  year = {1979},
  edition = {2nd},
  publisher = {Butterworth-Heinemann},
  address = {USA},
  isbn = {978-0-408-70929-3}
}

@article{Rissland2005CasebasedReasoningLaw,
  title = {Case-Based Reasoning and Law},
  author = {Rissland, Edwina L. and Ashley, Kevin D. and Branting, L. Karl},
  year = {2005},
  month = sep,
  journal = {The Knowledge Engineering Review},
  volume = {20},
  number = {3},
  pages = {293--298},
  publisher = {Cambridge University Press},
  issn = {1469-8005, 0269-8889},
  doi = {10.1017/S0269888906000701},
  urldate = {2020-09-02},
  abstract = {A primary research stream that contributed to the birth of case-based reasoning (CBR) was Artificial Intelligence and Law. Since law is largely about cases, it is a particularly interesting domain for CBR researchers. This article surveys some of the historically significant systems and developments in this field.},
  langid = {english}
}

@inproceedings{Ristoski2016RDF2VecRDFGraph,
  title = {{{RDF2Vec}}: {{RDF Graph Embeddings}} for {{Data Mining}}},
  shorttitle = {{{RDF2Vec}}},
  booktitle = {The {{Semantic Web}} -- {{ISWC}} 2016},
  author = {Ristoski, Petar and Paulheim, Heiko},
  editor = {Groth, Paul and Simperl, Elena and Gray, Alasdair and Sabou, Marta and Kr{\"o}tzsch, Markus and Lecue, Freddy and Fl{\"o}ck, Fabian and Gil, Yolanda},
  year = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {498--514},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-46523-4_30},
  abstract = {Linked Open Data has been recognized as a valuable source for background information in data mining. However, most data mining tools require features in propositional form, i.e., a vector of nominal or numerical features associated with an instance, while Linked Open Data sources are graphs by nature. In this paper, we present RDF2Vec, an approach that uses language modeling approaches for unsupervised feature extraction from sequences of words, and adapts them to RDF graphs. We generate sequences by leveraging local information from graph sub-structures, harvested by Weisfeiler-Lehman Subtree RDF Graph Kernels and graph walks, and learn latent numerical representations of entities in RDF graphs. Our evaluation shows that such vector representations outperform existing techniques for the propositionalization of RDF graphs on a variety of different predictive machine learning tasks, and that feature vector representations of general knowledge graphs such as DBpedia and Wikidata can be easily reused for different tasks.},
  isbn = {978-3-319-46523-4},
  langid = {english}
}

@article{Robertson1994OkapiTREC3,
  title = {Okapi at {{TREC-3}}},
  author = {Robertson, Stephen E.},
  year = {1994},
  pages = {109--126}
}

@inproceedings{Rocha2023AssessingGoodBad,
  title = {Assessing {{Good}}, {{Bad}} and {{Ugly Arguments Generated}} by {{ChatGPT}}: A {{New Dataset}}, Its {{Methodology}} and {{Associated Tasks}}},
  shorttitle = {Assessing {{Good}}, {{Bad}} and {{Ugly Arguments Generated}} by {{ChatGPT}}},
  booktitle = {Progress in {{Artificial Intelligence}}},
  author = {Rocha, Victor Hugo Nascimento and Silveira, Igor Cataneo and Pirozelli, Paulo and Mau{\'a}, Denis Deratani and Cozman, Fabio Gagliardi},
  editor = {Moniz, Nuno and Vale, Zita and Cascalho, Jos{\'e} and Silva, Catarina and Sebasti{\~a}o, Raquel},
  year = {2023},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {428--440},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-49008-8_34},
  abstract = {The recent success of Large Language Models (LLMs) has sparked concerns about their potential to spread misinformation. As a result, there is a pressing need for tools to identify ``fake arguments'' generated by such models. To create these tools, examples of texts generated by LLMs are needed. This paper introduces a methodology to obtain good, bad and ugly arguments from argumentative essays produced by ChatGPT, OpenAI's LLM. We then describe a novel dataset containing a set of diverse arguments, ArGPT. We assess the effectiveness of our dataset and establish baselines for several argumentation-related tasks. Finally, we show that the artificially generated data relates well to human argumentation and thus is useful as a tool to train and test systems for the defined tasks.},
  isbn = {978-3-031-49008-8},
  langid = {english}
}

@article{Rocha2024CrossgenreArgumentMining,
  title = {Cross-Genre Argument Mining: {{Can}} Language Models Automatically Fill in Missing Discourse Markers?},
  shorttitle = {Cross-Genre Argument Mining},
  author = {Rocha, Gil and Lopes Cardoso, Henrique and Belouadi, Jonas and Eger, Steffen},
  year = {2024},
  month = jan,
  journal = {Argument \& Computation},
  volume = {Preprint},
  number = {Preprint},
  pages = {1--41},
  publisher = {IOS Press},
  issn = {1946-2166},
  doi = {10.3233/AAC-230008},
  urldate = {2024-06-21},
  abstract = {Available corpora for Argument Mining differ along several axes, and one of the key differences is the presence (or absence) of discourse markers to signal argumentative content. Exploring effective ways to use discourse markers has received wide att},
  langid = {english}
}

@inproceedings{Romberg2022YourPerspectiveAlso,
  title = {Is {{Your Perspective Also My Perspective}}? {{Enriching Prediction}} with {{Subjectivity}}},
  shorttitle = {Is {{Your Perspective Also My Perspective}}?},
  booktitle = {Proceedings of the 9th {{Workshop}} on {{Argument Mining}}},
  author = {Romberg, Julia},
  editor = {Lapesa, Gabriella and Schneider, Jodi and Jo, Yohan and Saha, Sougata},
  year = {2022},
  month = oct,
  pages = {115--125},
  publisher = {International Conference on Computational Linguistics},
  address = {Gyeongju, Republic of Korea},
  urldate = {2024-04-09},
  abstract = {Although argumentation can be highly subjective, the common practice with supervised machine learning is to construct and learn from an aggregated ground truth formed from individual judgments by majority voting, averaging, or adjudication. This approach leads to a neglect of individual, but potentially important perspectives and in many cases cannot do justice to the subjective character of the tasks. One solution to this shortcoming are multi-perspective approaches, which have received very little attention in the field of argument mining so far. In this work we present PerspectifyMe, a method to incorporate perspectivism by enriching a task with subjectivity information from the data annotation process. We exemplify our approach with the use case of classifying argument concreteness, and provide first promising results for the recently published CIMT PartEval Argument Concreteness Corpus.}
}

@incollection{Rose2010AutomaticKeywordExtraction,
  title = {Automatic {{Keyword Extraction}} from {{Individual Documents}}},
  booktitle = {Text {{Mining}}},
  author = {Rose, Stuart and Engel, Dave and Cramer, Nick and Cowley, Wendy},
  editor = {Berry, Michael W. and Kogan, Jacob},
  year = {2010},
  month = mar,
  pages = {1--20},
  publisher = {John Wiley \& Sons, Ltd},
  address = {Chichester, UK},
  doi = {10.1002/9780470689646.ch1},
  urldate = {2021-02-07},
  isbn = {978-0-470-68964-6},
  langid = {english}
}

@article{Rosenblatt1958PerceptronProbabilisticModel,
  title = {The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain},
  author = {Rosenblatt, F},
  year = {1958},
  month = nov,
  journal = {Psychological review},
  volume = {65},
  number = {6},
  pages = {386--408},
  issn = {0033-295X},
  doi = {10.1037/h0042519},
  langid = {english},
  pmid = {13602029}
}

@phdthesis{Roth2003CasebasedReasoningLaw,
  title = {Case-Based Reasoning in the Law : A Formal Theory of Reasoning by Case Comparison},
  shorttitle = {Case-Based Reasoning in the Law},
  author = {Roth, A. C.},
  year = {2003},
  month = jan,
  urldate = {2019-10-28},
  langid = {english},
  school = {Universiteit Maastricht}
}

@inproceedings{Roush2020DebateSumLargescaleArgument,
  title = {{{DebateSum}}: {{A}} Large-Scale Argument Mining and Summarization Dataset},
  shorttitle = {{{DebateSum}}},
  booktitle = {Proceedings of the 7th {{Workshop}} on {{Argument Mining}}},
  author = {Roush, Allen and Balaji, Arvind},
  year = {2020},
  month = dec,
  pages = {1--7},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  urldate = {2022-01-13},
  abstract = {Prior work in Argument Mining frequently alludes to its potential applications in automatic debating systems. Despite this focus, almost no datasets or models exist which apply natural language processing techniques to problems found within competitive formal debate. To remedy this, we present the DebateSum dataset. DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum was made using data compiled by competitors within the National Speech and Debate Association over a 7year period. We train several transformer summarization models to benchmark summarization performance on DebateSum. We also introduce a set of fasttext word-vectors trained on DebateSum called debate2vec. Finally, we present a search engine for this dataset which is utilized extensively by members of the National Speech and Debate Association today. The DebateSum search engine is available to the public here: http://www.debate.cards}
}

@article{Rousseeuw1987SilhouettesGraphicalAid,
  title = {Silhouettes: {{A}} Graphical Aid to the Interpretation and Validation of Cluster Analysis},
  shorttitle = {Silhouettes},
  author = {Rousseeuw, Peter J.},
  year = {1987},
  month = nov,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {20},
  pages = {53--65},
  issn = {0377-0427},
  doi = {10.1016/0377-0427(87)90125-7},
  urldate = {2022-08-02},
  abstract = {A new graphical display is proposed for partitioning techniques. Each cluster is represented by a so-called silhouette, which is based on the comparison of its tightness and separation. This silhouette shows which objects lie well within their cluster, and which ones are merely somewhere in between clusters. The entire clustering is displayed by combining the silhouettes into a single plot, allowing an appreciation of the relative quality of the clusters and an overview of the data configuration. The average silhouette width provides an evaluation of clustering validity, and might be used to select an `appropriate' number of clusters.},
  langid = {english}
}

@inproceedings{Ruckdeschel2024ArgumentMiningAttack,
  title = {Argument {{Mining}} of~{{Attack}} and~{{Support Patterns}} in~{{Dialogical Conversations}} with~{{Sequential Pattern Mining}}},
  booktitle = {Robust {{Argumentation Machines}}},
  author = {Ruckdeschel, Mattes and Baumann, Ringo and Wiedemann, Gregor},
  editor = {Cimiano, Philipp and Frank, Anette and Kohlhase, Michael and Stein, Benno},
  year = {2024},
  pages = {39--56},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63536-6_3},
  abstract = {Argument mining usually operates on short, decontextualized argumentative units such as main and subordinate clauses, or full sentences as proxies for arguments. Argumentation in digital media environments, however, is embedded in larger contexts. Especially on social media platforms, argumentation unfolds in dialog threads or tree structures where users interact with each other. To reveal patterns of such interactions, we transform 2.5 million tweets from 38k German Twitter conversations concerning nuclear energy from 2017, 2019, and 2021 into an abstract representation encoding their stance, and aspects. We then apply Sequential Pattern Mining, a common method for finding patterns in large databases, and explore its capabilities to investigate typical argumentation schemes in user debates. The approach reveals distinct patterns of support and attack relations between pro and contra arguments about nuclear energy in conversational threads when comparing different time slices of our corpus. For example, we are seeing an increasing relevance of the climate aspect in attacks on anti-nuclear arguments. However, the pro arguments are increasingly being countered by cost aspects. Analyzing this diachronic change of patterns allows us to describe the discursive processes of argumentation on a macro level that drive the slow but steady transformation of a society's social and political convictions.},
  isbn = {978-3-031-63536-6},
  langid = {english}
}

@article{Ruckle2018ConcatenatedPowerMean,
  title = {Concatenated {{Power Mean Word Embeddings}} as {{Universal Cross-Lingual Sentence Representations}}},
  author = {R{\"u}ckl{\'e}, Andreas and Eger, Steffen and Peyrard, Maxime and Gurevych, Iryna},
  year = {2018},
  month = sep,
  journal = {arXiv:1803.01400 [cs]},
  eprint = {1803.01400},
  primaryclass = {cs},
  urldate = {2020-10-20},
  abstract = {Average word embeddings are a common baseline for more sophisticated sentence embedding techniques. However, they typically fall short of the performances of more complex models such as InferSent. Here, we generalize the concept of average word embeddings to power mean word embeddings. We show that the concatenation of different types of power mean word embeddings considerably closes the gap to state-of-the-art methods monolingually and substantially outperforms these more complex techniques cross-lingually. In addition, our proposed method outperforms different recently proposed baselines such as SIF and Sent2Vec by a solid margin, thus constituting a much harder-to-beat monolingual baseline. Our data and code are publicly available.},
  archiveprefix = {arXiv}
}

@article{Ruiz-Dolz2021VivesDebateNewAnnotated,
  title = {{{VivesDebate}}: {{A New Annotated Multilingual Corpus}} of {{Argumentation}} in a {{Debate Tournament}}},
  shorttitle = {{{VivesDebate}}},
  author = {{Ruiz-Dolz}, Ramon and Nofre, Montserrat and Taul{\'e}, Mariona and Heras, Stella and {Garc{\'i}a-Fornes}, Ana},
  year = {2021},
  month = jan,
  journal = {Applied Sciences},
  volume = {11},
  number = {15},
  pages = {7160},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app11157160},
  urldate = {2023-07-26},
  abstract = {The application of the latest Natural Language Processing breakthroughs in computational argumentation has shown promising results, which have raised the interest in this area of research. However, the available corpora with argumentative annotations are often limited to a very specific purpose or are not of adequate size to take advantage of state-of-the-art deep learning techniques (e.g., deep neural networks). In this paper, we present VivesDebate, a large, richly annotated and versatile professional debate corpus for computational argumentation research. The corpus has been created from 29 transcripts of a debate tournament in Catalan and has been machine-translated into Spanish and English. The annotation contains argumentative propositions, argumentative relations, debate interactions and professional evaluations of the arguments and argumentation. The presented corpus can be useful for research on a heterogeneous set of computational argumentation underlying tasks such as Argument Mining, Argument Analysis, Argument Evaluation or Argument Generation, among others. All this makes VivesDebate a valuable resource for computational argumentation research within the context of massive corpora aimed at Natural Language Processing tasks.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english}
}

@mastersthesis{Sahitaj2022InvestigatingExplainableArtificial,
  title = {Investigating {{Explainable Artificial Intelligence}} and {{Interaction}} for a {{Novel Argument Graph Mining System}}},
  author = {Sahitaj, Premtim},
  year = {2022},
  month = aug,
  address = {Trier, Germany},
  abstract = {Humans search for arguments to discuss ideas, influence others, or recommend adequate actions with the goal of persuasion. Current Web search engines primarily operate on the textual level and only retrieve individual facts which must be tediously assembled into a structured argument by hand. Anticipated argumentation machines (AM) execute queries on the additional structured level and retrieve argument structures assembled into graphs [8, 89]. Argument mining or the annotation of argument graph structures is a necessary preceding step towards the realization of AMs. Manual annotation is expensive, while automated annotation is error-prone. Current automated argument mining systems do not perform well [56, 103], do not allow user intervention, and lack transparency. The complexity of mining natural language arguments and the scarcity of information about the end-to-end mining process, necessitate an interactive hybrid approach that is faster than manual curation and more accurate than automated curation [122]. An interactive argument mining system requires informed user decisions which can only be based on explanations about the argument mining process and the intermediate results. With this thesis we target the conceptualization of an interactive and explainable argument mining system for the purpose of improving automated annotation results. We identify three aspects to this problem setting. First, we formulate the argument mining process tasks to integrate novel machine learning solution approaches while considering recent progress in the field of argument mining. Our learning-based approaches for the tasks of argument extraction, relation classification, and major claim detection suggest a significant improvement in the field of argument mining, which demonstrates the importance of our selected strategies. Then, we describe an interactive argument mining system that encapsulates the tasks of the argument mining process for the integration of users as a final control authority. Relevant explanation characteristics are captured and utilized in an target audience interview to elicit trends about explanations requirements from the participants. Based on these user insights we conceptualize task-specific and model-agnostic explanations which are primarily build upon the categories of explanation by visualization, local change, example, simplification, and feature relevance. Finally, the target audience feedback is collected and evaluated against our proposed explanation concept where we identify encouraging support for the majority of our ideas.},
  langid = {english},
  school = {Trier University}
}

@mastersthesis{Sahitaj2022InvestigatingExplainableArtificiala,
  title = {Investigating {{Explainable Artificial Intelligence}} and {{Interaction}} for a {{Novel Argument Graph Mining System}}},
  author = {Sahitaj, Premtim},
  year = {2022},
  month = aug,
  address = {Trier},
  abstract = {Humans search for arguments to discuss ideas, influence others, or recommend adequate actions with the goal of persuasion. Current Web search engines primarily operate on the textual level and only retrieve individual facts which must be tediously assembled into a structured argument by hand. Anticipated argumentation machines (AM) execute queries on the additional structured level and retrieve argument structures assembled into graphs [8, 89]. Argument mining or the annotation of argument graph structures is a necessary preceding step towards the realization of AMs. Manual annotation is expensive, while automated annotation is error-prone. Current automated argument mining systems do not perform well [56, 103], do not allow user intervention, and lack transparency. The complexity of mining natural language arguments and the scarcity of information about the end-to-end mining process, necessitate an interactive hybrid approach that is faster than manual curation and more accurate than automated curation [122]. An interactive argument mining system requires informed user decisions which can only be based on explanations about the argument mining process and the intermediate results. With this thesis we target the conceptualization of an interactive and explainable argument mining system for the purpose of improving automated annotation results. We identify three aspects to this problem setting. First, we formulate the argument mining process tasks to integrate novel machine learning solution approaches while considering recent progress in the field of argument mining. Our learning-based approaches for the tasks of argument extraction, relation classification, and major claim detection suggest a significant improvement in the field of argument mining, which demonstrates the importance of our selected strategies. Then, we describe an interactive argument mining system that encapsulates the tasks of the argument mining process for the integration of users as a final control authority. Relevant explanation characteristics are captured and utilized in an target audience interview to elicit trends about explanations requirements from the participants. Based on these user insights we conceptualize task-specific and model-agnostic explanations which are primarily build upon the categories of explanation by visualization, local change, example, simplification, and feature relevance. Finally, the target audience feedback is collected and evaluated against our proposed explanation concept where we identify encouraging support for the majority of our ideas.},
  langid = {english},
  school = {Trier University}
}

@article{Salton1988TermweightingApproachesAutomatic,
  title = {Term-Weighting Approaches in Automatic Text Retrieval},
  author = {Salton, Gerard and Buckley, Christopher},
  year = {1988},
  month = jan,
  journal = {Information Processing \& Management},
  volume = {24},
  number = {5},
  pages = {513--523},
  issn = {0306-4573},
  doi = {10.1016/0306-4573(88)90021-0},
  urldate = {2018-09-01},
  abstract = {The experimental evidence accumulated over the past 20 years indicates that text indexing systems based on the assignment of appropriately weighted single terms produce retrieval results that are superior to those obtainable with other more elaborate text representations. These results depend crucially on the choice of effective termweighting systems. This article summarizes the insights gained in automatic term weighting, and provides baseline single-term-indexing models with which other more elaborate content analysis procedures can be compared.}
}

@inproceedings{Samoladas2008SQOOSSQualityModel,
  title = {The {{SQO-OSS Quality Model}}: {{Measurement Based Open Source Software Evaluation}}},
  shorttitle = {The {{SQO-OSS Quality Model}}},
  booktitle = {Open {{Source Development}}, {{Communities}} and {{Quality}}},
  author = {Samoladas, Ioannis and Gousios, Georgios and Spinellis, Diomidis and Stamelos, Ioannis},
  editor = {Russo, Barbara and Damiani, Ernesto and Hissam, Scott and Lundell, Bj{\"o}rn and Succi, Giancarlo},
  year = {2008},
  series = {{{IFIP}} -- {{The International Federation}} for {{Information Processing}}},
  pages = {237--248},
  publisher = {Springer US},
  address = {Boston, MA},
  doi = {10.1007/978-0-387-09684-1_19},
  abstract = {Software quality evaluation has always been an important part of software business. The quality evaluation process is usually based on hierarchical quality models that measure various aspects of software quality and deduce a characterization of the product quality being evaluated. The particular nature of open source software has rendered existing models inappropriate for detailed quality evaluations. In this paper, we present a hierarchical quality model that evaluates source code and community processes, based on automatic calculation of metric values and their correlation to a set of predefined quality profiles.1},
  isbn = {978-0-387-09684-1},
  langid = {english}
}

@inproceedings{Saracevic1995EvaluationEvaluationInformation,
  title = {Evaluation of Evaluation in Information Retrieval},
  booktitle = {Proceedings of the 18th Annual International {{ACM SIGIR}} Conference on {{Research}} and Development in Information Retrieval},
  author = {Saracevic, Tefko},
  year = {1995},
  month = jul,
  series = {{{SIGIR}} '95},
  pages = {138--146},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/215206.215351},
  urldate = {2021-03-13},
  isbn = {978-0-89791-714-8}
}

@article{Sauer2020UsabilityUserExperience,
  title = {Usability, User Experience and Accessibility: Towards an Integrative Model},
  shorttitle = {Usability, User Experience and Accessibility},
  author = {Sauer, Juergen and Sonderegger, Andreas and Schmutz, Sven},
  year = {2020},
  month = oct,
  journal = {Ergonomics},
  volume = {63},
  number = {10},
  pages = {1207--1220},
  publisher = {Taylor \& Francis},
  issn = {0014-0139},
  doi = {10.1080/00140139.2020.1774080},
  urldate = {2022-05-03},
  abstract = {Within the field of ergonomics, the concepts of usability, user experience and accessibility have played an increasingly important role. The present paper examined the meaning of these concepts and their relationship to each other, which included an analysis of the definitions, methods, and typical outcome measures employed. Despite some concerns in the literature about the utility of usability, user experience and accessibility as umbrella terms, we provide arguments for their continued use. The article proposes how the three concepts and their different perspectives can be integrated. We propose the term `interaction experience' (IX) as a higher-level concept. Due to the multi-facetted nature of umbrella concepts, we suggest using spider charts as a means to report the results of evaluating artefacts with regard to usability, user experience and accessibility. Practitioner Summary: A better integration of the concepts of usability, user experience and accessibility is expected to provide some benefits to practitioners. We propose employing spider charts for reporting the outcome of artefact evaluations regarding the three concepts. This may help practitioners interpret the characteristics of a device at a glance. Abbreviations: IX: interaction experience; UX: user experience; ISO: International Standard Organisation},
  pmid = {32450782}
}

@inproceedings{Schaefer2020AnnotationDetectionArguments,
  title = {Annotation and {{Detection}} of {{Arguments}} in {{Tweets}}},
  booktitle = {Proceedings of the 7th {{Workshop}} on {{Argument Mining}}},
  author = {Schaefer, Robin and Stede, Manfred},
  year = {2020},
  month = dec,
  pages = {53--58},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  urldate = {2022-01-13},
  abstract = {Notwithstanding the increasing role Twitter plays in modern political and social discourse, resources built for conducting argument mining on tweets remain limited. In this paper, we present a new corpus of German tweets annotated for argument components. To the best of our knowledge, this is the first corpus containing not only annotated full tweets but also argumentative spans within tweets. We further report first promising results using supervised classification (F1: 0.82) and sequence labeling (F1: 0.72) approaches.}
}

@article{Schaefer2021ArgumentMiningTwitter,
  title = {Argument {{Mining}} on {{Twitter}}: {{A}} Survey},
  shorttitle = {Argument {{Mining}} on {{Twitter}}},
  author = {Schaefer, Robin and Stede, Manfred},
  year = {2021},
  month = feb,
  journal = {it - Information Technology},
  volume = {63},
  number = {1},
  pages = {45--58},
  publisher = {De Gruyter Oldenbourg},
  issn = {2196-7032},
  doi = {10.1515/itit-2020-0053},
  urldate = {2021-10-07},
  abstract = {In the last decade, the field of argument mining has grown notably. However, only relatively few studies have investigated argumentation in social media and specifically on Twitter. Here, we provide the, to our knowledge, first critical in-depth survey of the state of the art in tweet-based argument mining. We discuss approaches to modelling the structure of arguments in the context of tweet corpus annotation, and we review current progress in the task of detecting argument components and their relations in tweets. We also survey the intersection of argument mining and stance detection, before we conclude with an outlook.},
  langid = {english}
}

@article{Scheuer2010ComputersupportedArgumentationReview,
  title = {Computer-Supported Argumentation: {{A}} Review of the State of the Art},
  shorttitle = {Computer-Supported Argumentation},
  author = {Scheuer, Oliver and Loll, Frank and Pinkwart, Niels and McLaren, Bruce M.},
  year = {2010},
  month = mar,
  journal = {International Journal of Computer-Supported Collaborative Learning},
  volume = {5},
  number = {1},
  pages = {43--102},
  issn = {1556-1615},
  doi = {10.1007/s11412-009-9080-x},
  urldate = {2022-04-21},
  abstract = {Argumentation is an important skill to learn. It is valuable not only in many professional contexts, such as the law, science, politics, and business, but also in everyday life. However, not many people are good arguers. In response to this, researchers and practitioners over the past 15--20~years have developed software tools both to support and teach argumentation. Some of these tools are used in individual fashion, to present students with the ``rules'' of argumentation in a particular domain and give them an opportunity to practice, while other tools are used in collaborative fashion, to facilitate communication and argumentation between multiple, and perhaps distant, participants. In this paper, we review the extensive literature on argumentation systems, both individual and collaborative, and both supportive and educational, with an eye toward particular aspects of the past work. More specifically, we review the types of argument representations that have been used, the various types of interaction design and ontologies that have been employed, and the system architecture issues that have been addressed. In addition, we discuss intelligent and automated features that have been imbued in past systems, such as automatically analyzing the quality of arguments and providing intelligent feedback to support and/or tutor argumentation. We also discuss a variety of empirical studies that have been done with argumentation systems, including, among other aspects, studies that have evaluated the effect of argument diagrams (e.g., textual versus graphical), different representations, and adaptive feedback on learning argumentation. Finally, we conclude by summarizing the ``lessons learned'' from this large and impressive body of work, particularly focusing on lessons for the CSCL research community and its ongoing efforts to develop computer-mediated collaborative argumentation systems.},
  langid = {english}
}

@inproceedings{Schuler2023SemisupervisedSimilarityLearning,
  title = {Semi-Supervised {{Similarity Learning}} in~{{Process-Oriented Case-Based Reasoning}}},
  booktitle = {Artificial {{Intelligence XL}}},
  author = {Schuler, Nicolas and Hoffmann, Maximilian and Beise, Hans-Peter and Bergmann, Ralph},
  editor = {Bramer, Max and Stahl, Frederic},
  year = {2023},
  pages = {159--173},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-47994-6_12},
  abstract = {Supervised learning is typically challenging with insufficient amounts of labeled training data and high costs for label acquisition, creating a demand for unsupervised learning methods. In the research area of Process-Oriented Case-Based Reasoning (POCBR), this demand is created by training data that is manually-modeled and computationally-expensive labeling methods. In this paper, we propose a semi-supervised transfer learning method for learning similarities between pairs of semantic graphs in POCBR with Graph Neural Networks (GNNs). The method aims to replace the fully supervised learning procedure from previous work with an unsupervised and a supervised training phase. In the first phase, the GNNs are pretrained with a triplet learning procedure that utilizes graph augmentation and random selection to enable unsupervised training. This phase is followed by a supervised one where the pretrained model is trained on the original labeled training data. The experimental evaluation examines the quality of the semi-supervised models compared to the supervised models from previous work for three semantic graph domains with different properties. The results indicate the potential of the proposed approach for improving retrieval quality.},
  isbn = {978-3-031-47994-6},
  langid = {english}
}

@misc{Schulhoff2024PromptReportSystematic,
  title = {The {{Prompt Report}}: {{A Systematic Survey}} of {{Prompting Techniques}}},
  shorttitle = {The {{Prompt Report}}},
  author = {Schulhoff, Sander and Ilie, Michael and Balepur, Nishant and Kahadze, Konstantine and Liu, Amanda and Si, Chenglei and Li, Yinheng and Gupta, Aayush and Han, HyoJung and Schulhoff, Sevien and Dulepet, Pranav Sandeep and Vidyadhara, Saurav and Ki, Dayeon and Agrawal, Sweta and Pham, Chau and Kroiz, Gerson and Li, Feileen and Tao, Hudson and Srivastava, Ashay and Costa, Hevander Da and Gupta, Saloni and Rogers, Megan L. and Goncearenco, Inna and Sarli, Giuseppe and Galynker, Igor and Peskoff, Denis and Carpuat, Marine and White, Jules and Anadkat, Shyamal and Hoyle, Alexander and Resnik, Philip},
  year = {2024},
  month = jul,
  number = {arXiv:2406.06608},
  eprint = {2406.06608},
  publisher = {arXiv},
  urldate = {2024-11-06},
  abstract = {Generative Artificial Intelligence (GenAI) systems are being increasingly deployed across all parts of industry and research settings. Developers and end users interact with these systems through the use of prompting or prompt engineering. While prompting is a widespread and highly researched concept, there exists conflicting terminology and a poor ontological understanding of what constitutes a prompt due to the area's nascency. This paper establishes a structured understanding of prompts, by assembling a taxonomy of prompting techniques and analyzing their use. We present a comprehensive vocabulary of 33 vocabulary terms, a taxonomy of 58 text-only prompting techniques, and 40 techniques for other modalities. We further present a meta-analysis of the entire literature on natural language prefix-prompting.},
  archiveprefix = {arXiv}
}

@misc{Schuller2022ComposingComplexHybrid,
  title = {Composing {{Complex}} and {{Hybrid AI Solutions}}},
  author = {Sch{\"u}ller, Peter and Costeira, Jo{\~a}o Paolo and Crowley, James and Grosinger, Jasmin and Ingrand, F{\'e}lix and K{\"o}ckemann, Uwe and Saffiotti, Alessandro and Welss, Martin},
  year = {2022},
  month = feb,
  number = {arXiv:2202.12566},
  eprint = {2202.12566},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2202.12566},
  urldate = {2023-11-20},
  abstract = {Progress in several areas of computer science has been enabled by comfortable and efficient means of experimentation, clear interfaces, and interchangable components, for example using OpenCV for computer vision or ROS for robotics. We describe an extension of the Acumos system towards enabling the above features for general AI applications. Originally, Acumos was created for telecommunication purposes, mainly for creating linear pipelines of machine learning components. Our extensions include support for more generic components with gRPC/Protobuf interfaces, automatic orchestration of graphically assembled solutions including control loops, sub-component topologies, and event-based communication,and provisions for assembling solutions which contain user interfaces and shared storage areas. We provide examples of deployable solutions and their interfaces. The framework is deployed at http://aiexp.ai4europe.eu/ and its source code is managed as an open source Eclipse project.},
  archiveprefix = {arXiv}
}

@mastersthesis{Schultheis2022ErklaerungAehnlichkeitenIm,
  title = {{Erkl{\"a}rung von {\"A}hnlichkeiten im Prozessorientierten Fallbasierten Schlie{\ss}en durch Visualisierungen}},
  author = {Schultheis, Alexander},
  year = {2022},
  month = sep,
  address = {Trier, Germany},
  langid = {ngerman},
  school = {Trier University}
}

@inproceedings{Schultheis2023ExplanationSimilaritiesProcessOriented,
  title = {Explanation of~{{Similarities}} in~{{Process-Oriented Case-Based Reasoning}} by~{{Visualization}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Schultheis, Alexander and Hoffmann, Maximilian and Malburg, Lukas and Bergmann, Ralph},
  editor = {Massie, Stewart and Chakraborti, Sutanu},
  year = {2023},
  pages = {53--68},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-40177-0_4},
  abstract = {Modeling similarity measures in Case-Based Reasoning is a knowledge-intensive, demanding, and error-prone task even for domain experts. Visualizations offer support for users, but are currently only available for certain subdomains and case representations. Currently, there are only visualizations that can be used for local attributes or specific case representations. However, there is no possibility to visualize similarities between complete processes accordingly so far, although complex domains may be present. Therefore, an extension of existing approaches or the design of new suitable concepts for this application domain is necessary. The contribution of this work is to enable a more profound understanding of similarity for knowledge engineers who create a similarity model and support them in this task by using visualization methods in Process-Oriented Case-Based Reasoning (POCBR). For this purpose, we present related approaches and evaluate them against derived requirements for visualizations in POCBR. On this basis, suitable visualizations are further developed as well as new approaches designed. Three such visualizations are created: (1) a graph mapping approach, (2) a merge graph, and (3)~a visualization based on heatmaps. An evaluation of these approaches has been performed based on the requirements in which the domain experts determine the graph-mapping visualization as best-suited for engineering of similarity models.},
  isbn = {978-3-031-40177-0},
  langid = {english}
}

@inproceedings{Schultheis2023OverviewComparisonCaseBased,
  title = {An {{Overview}} and~{{Comparison}} of~{{Case-Based Reasoning Frameworks}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Schultheis, Alexander and Zeyen, Christian and Bergmann, Ralph},
  editor = {Massie, Stewart and Chakraborti, Sutanu},
  year = {2023},
  pages = {327--343},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-40177-0_21},
  abstract = {Case-Based Reasoning (CBR) is a methodology with many applications in industrial and scientific domains. Over the past decades, various frameworks have been developed to facilitate the development of CBR applications. For practitioners and researchers, it is challenging to overview the landscape of existing frameworks with their specific scope and features. This makes it difficult to choose the most suitable framework for specific requirements. To address this issue, this work provides an overview and comparison of CBR frameworks, focusing on five recent, open-source CBR frameworks: CloodCBR, eXiT*CBR, jColibri, myCBR, and ProCAKE. They are compared by supported CBR types, knowledge containers, CBR phases, interfaces, and special features.},
  isbn = {978-3-031-40177-0},
  langid = {english}
}

@article{Scott1955ReliabilityContentAnalysis,
  title = {Reliability of {{Content Analysis}}:{{The Case}} of {{Nominal Scale Coding}}},
  shorttitle = {Reliability of {{Content Analysis}}},
  author = {Scott, William A.},
  year = {1955},
  month = jan,
  journal = {Public Opinion Quarterly},
  volume = {19},
  number = {3},
  pages = {321--325},
  issn = {0033-362X},
  doi = {10.1086/266577},
  urldate = {2021-03-07}
}

@article{Seiger2022IntegratingProcessManagement,
  title = {Integrating Process Management and Event Processing in Smart Factories: {{A}} Systems Architecture and Use Cases},
  shorttitle = {Integrating Process Management and Event Processing in Smart Factories},
  author = {Seiger, Ronny and Malburg, Lukas and Weber, Barbara and Bergmann, Ralph},
  year = {2022},
  month = apr,
  journal = {Journal of Manufacturing Systems},
  volume = {63},
  pages = {575--592},
  issn = {0278-6125},
  doi = {10.1016/j.jmsy.2022.05.012},
  urldate = {2024-03-20},
  abstract = {The developments of new concepts for an increased digitization of manufacturing industries in the context of Industry 4.0 have brought about novel system architectures and frameworks for smart production systems. These range from generic frameworks for Industry 4.0 to domain-specific architectures for Industrial Internet of Things (IIoT). While most of the approaches include a service-based architecture for selective integration with enterprise systems, a close two-way integration of the production control systems and IIoT sensors and actuators with Process-Aware Information Systems (PAIS) on the management level for automation and mining of production processes is rarely discussed. This fusion of Business Process Management (BPM) with IIoT can be mutually beneficial for both research areas, but is still in its infancy. We propose a systems architecture for IIoT that shows how to integrate the low-level hardware components--sensors and actuators--of a smart factory with BPM systems. We discuss the software components and their interactions to address challenges of device encapsulation, integration of sensor events, and interaction with existing BPM systems. This integration is demonstrated within several use cases regarding process modeling, automation and mining for a smart factory model, showing benefits of using BPM technologies to analyze, control, and adapt discrete production processes in IIoT.}
}

@inproceedings{Sen2024CounterfactualBasedSyntheticCase,
  title = {Counterfactual-{{Based Synthetic Case Generation}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Sen, Anik and Mainali, Mallika and Rauch, Christopher B. and Addison, Ursula and Floyd, Michael W. and Goel, Prateek and Karneeb, Justin and Kulhanek, Ray and Larue, Othalia and M{\'e}nager, David and Molineaux, Matthew and Turner, {\relax JT} and Weber, Rosina O.},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {388--403},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_25},
  abstract = {Case augmentation is often desirable when applying case-based reasoning to real-world problems. Initially explored for explainability, counterfactuals were recently recommended as a strategy to augment data. In this work, we implement an existing approach for generating counterfactuals, propose one variant of the original approach, and propose a third approach based on the literature on algorithmic recourse. We apply these three approaches to two datasets in military medical triage. To assess generalization, we also examine one of our approaches on three publicly available datasets. We compare the approaches based on the number of counterfactuals they produce, their resulting accuracy, overlapping counterfactuals, and domain knowledge. Experimental results are encouraging for the proposed approaches and bring up opportunities for future research.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@article{Shazeer2016SwivelImprovingEmbeddings,
  title = {Swivel: {{Improving Embeddings}} by {{Noticing What}}'s {{Missing}}},
  shorttitle = {Swivel},
  author = {Shazeer, Noam and Doherty, Ryan and Evans, Colin and Waterson, Chris},
  year = {2016},
  month = feb,
  journal = {arXiv:1602.02215 [cs]},
  eprint = {1602.02215},
  primaryclass = {cs},
  abstract = {We present Submatrix-wise Vector Embedding Learner (Swivel), a method for generating low-dimensional feature embeddings from a feature co-occurrence matrix. Swivel performs approximate factorization of the point-wise mutual information matrix via stochastic gradient descent. It uses a piecewise loss with special handling for unobserved co-occurrences, and thus makes use of all the information in the matrix. While this requires computation proportional to the size of the entire matrix, we make use of vectorized multiplication to process thousands of rows and columns at once to compute millions of predicted values. Furthermore, we partition the matrix into shards in order to parallelize the computation across many nodes. This approach results in more accurate embeddings than can be achieved with methods that consider only observed co-occurrences, and can scale to much larger corpora than can be handled with sampling methods.},
  archiveprefix = {arXiv}
}

@article{Shevtsov2020AnalysisTwitterYouTube,
  title = {Analysis of {{Twitter}} and {{YouTube}} during {{USelections}} 2020},
  author = {Shevtsov, Alexander and Oikonomidou, Maria and Antonakaki, Despoina and Pratikakis, Polyvios and Ioannidis, Sotiris},
  year = {2020},
  month = nov,
  journal = {arXiv:2010.08183 [cs]},
  eprint = {2010.08183},
  primaryclass = {cs},
  urldate = {2022-02-06},
  abstract = {The presidential elections in the United States on 3 November 2020 have caused extensive discussions on social media. A part of the content on US elections is organic, coming from users discussing their opinions of the candidates, political positions, or relevant content presented on television. Another significant part of the content generated originates from organized campaigns, both official and by astroturfing. In this study, we obtain approximately 17.5M tweets containing 3M users, based on prevalent hashtags related to US election 2020, as well as the related YouTube links, contained in the Twitter dataset, likes, dislikes and comments of the videos and conduct volume, sentiment and graph analysis on the communities formed. Particularly, we study the daily traffic per prevalent hashtags, plot the retweet graph from July to September 2020, show how its main connected component becomes denser in the period closer to the elections and highlight the two main entities ('Biden' and 'Trump'). Additionally, we gather the related YouTube links contained in the previous dataset and perform sentiment analysis. The results on sentiment analysis on the Twitter corpus and the YouTube metadata gathered, show the positive and negative sentiment for the two entities throughout this period. The results of sentiment analysis indicate that 45.7\% express positive sentiment towards Trump in Twitter and 33.8\% positive sentiment towards Biden, while 14.55\% of users express positive sentiment in YouTube metadata gathered towards Trump and 8.7\% positive sentiment towards Biden. Our analysis fill the gap between the connection of offline events and their consequences in social media by monitoring important events in real world and measuring public volume and sentiment before and after the event in social media.},
  archiveprefix = {arXiv}
}

@article{Simpson2018FindingConvincingArguments,
  title = {Finding {{Convincing Arguments Using Scalable Bayesian Preference Learning}}},
  author = {Simpson, Edwin and Gurevych, Iryna},
  year = {2018},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {6},
  pages = {357--371},
  doi = {10.1162/tacl_a_00026},
  urldate = {2019-11-21},
  abstract = {We introduce a scalable Bayesian preference learning method for identifying convincing arguments in the absence of gold-standard ratings or rankings. In contrast to previous work, we avoid the need for separate methods to perform quality control on training data, predict rankings and perform pairwise classification. Bayesian approaches are an effective solution when faced with sparse or noisy training data, but have not previously been used to identify convincing arguments. One issue is scalability, which we address by developing a stochastic variational inference method for Gaussian process (GP) preference learning. We show how our method can be applied to predict argument convincingness from crowdsourced data, outperforming the previous state-of-the-art, particularly when trained with small amounts of unreliable data. We demonstrate how the Bayesian approach enables more effective active learning, thereby reducing the amount of data required to identify convincing arguments for new users and domains. While word embeddings are principally used with neural networks, our results show that word embeddings in combination with linguistic features also benefit GPs when predicting argument convincingness.}
}

@inproceedings{Singh2002OpenMindCommon,
  title = {Open {{Mind Common Sense}}: {{Knowledge Acquisition}} from the {{General Public}}},
  shorttitle = {Open {{Mind Common Sense}}},
  booktitle = {On the {{Move}} to {{Meaningful Internet Systems}} 2002: {{CoopIS}}, {{DOA}}, and {{ODBASE}}},
  author = {Singh, Push and Lin, Thomas and Mueller, Erik T. and Lim, Grace and Perkins, Travell and Li Zhu, Wan},
  editor = {Meersman, Robert and Tari, Zahir},
  year = {2002},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {1223--1237},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-36124-3_77},
  abstract = {Open Mind Common Sense is a knowledge acquisition system designed to acquire commonsense knowledge from the general public over the web. We describe and evaluate our first fielded system, which enabled the construction of a 450,000 assertion commonsense knowledge base. We then discuss how our second-generation system addresses weaknesses discovered in the first. The new system acquires facts, descriptions, and stories by allowing participants to construct and fill in natural language templates. It employs word-sense disambiguation and methods of clarifying entered knowledge, analogical inference to provide feedback, and allows participants to validate knowledge and in turn each other.},
  isbn = {978-3-540-36124-4},
  langid = {english}
}

@inproceedings{Singh2002PublicAcquisitionCommonsense,
  title = {The Public Acquisition of Commonsense Knowledge},
  booktitle = {Proceedings of {{AAAI Spring Symposium}}: {{Acquiring}} (and {{Using}}) {{Linguistic}} (and {{World}}) {{Knowledge}} for {{Information Access}}},
  author = {Singh, Push},
  year = {2002},
  abstract = {The Open Mind Common Sense project is an attempt to construct a database of commonsense knowledge through the collaboration of a distributed community of thousands of non-expert netizens. We give an overview of the project, describe our knowledge acquisition and representation strategy of using natural language rather than formal logic, and demonstrate this strategy with a search engine application that employs simple commonsense reasoning to reformulate problem queries into more effective solution queries.}
}

@incollection{Sizov2014AcquisitionReuseReasoning,
  title = {Acquisition and {{Reuse}} of {{Reasoning Knowledge}} from {{Textual Cases}} for {{Automated Analysis}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Sizov, Gleb and {\"O}zt{\"u}rk, Pinar and {\v S}tyr{\'a}k, Jozef},
  editor = {Lamontagne, Luc and Plaza, Enric},
  year = {2014},
  volume = {8765},
  pages = {465--479},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-11209-1_33},
  urldate = {2019-08-20},
  abstract = {Analysis is essential for solving complex problems such as diagnosing a patient, investigating an accident or predicting the outcome of a legal case. It is a non-trivial process even for human experts. To assist experts in this process we propose a CBR-based approach for automated problem analysis. In this approach a new problem is analysed by reusing reasoning knowledge from the analysis of a similar problem. To avoid the laborious process of manual case acquisition, the reasoning knowledge is extracted automatically from text and captured in a graph-based representation, which we dubbed Text Reasoning Graph (TRG), that consists of causal, entailment and paraphrase relations. The reuse procedure involves adaptation of a similar past analysis to a new problem by finding paths in TRG that connect the evidence in the new problem to conclusions of the past analysis. The objective is to generate the best explanation of how the new evidence connects to the conclusion. For evaluation, we built a system for analysing aircraft accidents based on the collection of aviation investigation reports. The evaluation results show that our reuse method increases the precision of the retrieved conclusions.},
  isbn = {978-3-319-11208-4 978-3-319-11209-1},
  langid = {english}
}

@inproceedings{Sizov2016CompositionalAdaptationExplanations,
  title = {Compositional {{Adaptation}} of {{Explanations}} in {{Textual Case-Based Reasoning}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Sizov, Gleb and {\"O}zt{\"u}rk, Pinar and Marsi, Erwin},
  editor = {Goel, Ashok and {D{\'i}az-Agudo}, M Bel{\'e}n and {Roth-Berghofer}, Thomas},
  year = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {387--401},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-47096-2_26},
  abstract = {When problem solving systems are deployed in real life, it is usually not enough to provide only a solution without any explanation. Users need an explanation in order to trust the system's decisions. At the same time, explanations may also function internally in the system's own reasoning process. One way to come up with an explanation for a new problem is to adapt an explanation from a similar problem encountered earlier, which is the idea behind the case-based explanation approach introduced by [29]. The original approach relies on manual construction of cases with explanations, which is difficult to scale up. In earlier work, therefore, we developed a system for automatic acquisition of cases with explanations from textual reports, including retrieval and adaptation of such cases [32, 33]. In this paper, we improve the adaptation method by combining explanations from more than one case, which we call compositional adaptation. The method is evaluated on an incident analysis task where the goal is to identify the root causes of a transportation incident, explaining it in terms of the information contained in the incident description. The evaluation results show that the proposed approach increases both the recall and the precision of the system.},
  isbn = {978-3-319-47096-2},
  langid = {english}
}

@inproceedings{Slonim2018ProjectDebater,
  title = {Project {{Debater}}},
  booktitle = {Proceedings of {{Computational Models}} of {{Argument}}},
  author = {Slonim, Noam},
  year = {2018},
  series = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  volume = {305},
  pages = {4},
  publisher = {IOS Press},
  address = {Warsaw, Poland},
  doi = {10.3233/978-1-61499-906-5-4},
  abstract = {Project Debater is the first AI system that was shown to debate humans in a meaningful manner in a full live debate. Developing this system started in 2012, as the next AI Grand Challenge pursued by IBM Research, following the demonstration of Deep Blue in Chess in 1997, and Watson in Jeopardy! In 2011. The Project Debater system was demonstrated for the first time in San Francisco in June 2018, in two full live debates vs. expert human debaters, and correspondingly received massive media attention. This talk will present the challenges in developing this system, its current capabilities and present limitations, as well as how we envision its future.}
}

@article{Slonim2021AutonomousDebatingSystem,
  title = {An Autonomous Debating System},
  author = {Slonim, Noam and Bilu, Yonatan and Alzate, Carlos and {Bar-Haim}, Roy and Bogin, Ben and Bonin, Francesca and Choshen, Leshem and {Cohen-Karlik}, Edo and Dankin, Lena and Edelstein, Lilach and {Ein-Dor}, Liat and {Friedman-Melamed}, Roni and Gavron, Assaf and Gera, Ariel and Gleize, Martin and Gretz, Shai and Gutfreund, Dan and Halfon, Alon and Hershcovich, Daniel and Hoory, Ron and Hou, Yufang and Hummel, Shay and Jacovi, Michal and Jochim, Charles and Kantor, Yoav and Katz, Yoav and Konopnicki, David and Kons, Zvi and Kotlerman, Lili and Krieger, Dalia and Lahav, Dan and Lavee, Tamar and Levy, Ran and Liberman, Naftali and Mass, Yosi and Menczel, Amir and Mirkin, Shachar and Moshkowich, Guy and {Ofek-Koifman}, Shila and Orbach, Matan and Rabinovich, Ella and Rinott, Ruty and Shechtman, Slava and Sheinwald, Dafna and Shnarch, Eyal and Shnayderman, Ilya and Soffer, Aya and Spector, Artem and Sznajder, Benjamin and Toledo, Assaf and {Toledo-Ronen}, Orith and Venezian, Elad and Aharonov, Ranit},
  year = {2021},
  month = mar,
  journal = {Nature},
  volume = {591},
  number = {7850},
  pages = {379--384},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-021-03215-w},
  urldate = {2023-11-24},
  abstract = {Artificial intelligence (AI) is defined as the ability of machines to perform tasks that are usually associated with intelligent beings. Argument and debate are fundamental capabilities of human intelligence, essential for a wide range of human activities, and common to all human societies. The development of computational argumentation technologies is therefore an important emerging discipline in AI research1. Here we present Project Debater, an autonomous debating system that can engage in a competitive debate with humans. We provide a complete description of the system's architecture, a thorough and systematic evaluation of its operation across a wide range of debate topics, and a detailed account of the system's performance in its public debut against three expert human debaters. We also highlight the fundamental differences between debating with humans as opposed to challenging humans in game competitions, the latter being the focus of classical `grand challenges' pursued by the AI research community over the past few decades. We suggest that such challenges lie in the `comfort zone' of AI, whereas debating with humans lies in a different territory, in which humans still prevail, and for which novel paradigms are required to make substantial progress.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english}
}

@article{Smith1985DesignDivideConquer,
  title = {The Design of Divide and Conquer Algorithms},
  author = {Smith, Douglas R.},
  year = {1985},
  month = jan,
  journal = {Science of Computer Programming},
  volume = {5},
  pages = {37--58},
  issn = {0167-6423},
  doi = {10.1016/0167-6423(85)90003-6},
  urldate = {2022-08-02},
  abstract = {The structure common to a class of divide and conquer algorithms is represented by a program scheme. A theorem is presented which relates the functionality of a divide and conquer algorithm to its structure and the functionalities of its subalgorithms. Several strategies for designing divide and conquer algorithms arise from this theorem and they are used to formally derive algorithms for sorting a list of numbers, forming the cartesian product of two sets, and finding the convex hull of a set of planar points.},
  langid = {english}
}

@inproceedings{Sobhani2015ArgumentationMiningStance,
  title = {From {{Argumentation Mining}} to {{Stance Classification}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Argumentation Mining}}},
  author = {Sobhani, Parinaz and Inkpen, Diana and Matwin, Stan},
  year = {2015},
  month = jun,
  pages = {67--77},
  publisher = {Association for Computational Linguistics},
  address = {Denver, CO},
  doi = {10.3115/v1/W15-0509},
  urldate = {2020-10-21}
}

@inproceedings{Sokolova2006AccuracyFScoreROC,
  title = {Beyond {{Accuracy}}, {{F-Score}} and {{ROC}}: {{A Family}} of {{Discriminant Measures}} for {{Performance Evaluation}}},
  shorttitle = {Beyond {{Accuracy}}, {{F-Score}} and {{ROC}}},
  booktitle = {{{AI}} 2006: {{Advances}} in {{Artificial Intelligence}}},
  author = {Sokolova, Marina and Japkowicz, Nathalie and Szpakowicz, Stan},
  year = {2006},
  month = dec,
  pages = {1015--1021},
  publisher = {Springer, Berlin, Heidelberg},
  doi = {10.1007/11941439_114},
  urldate = {2021-03-13},
  abstract = {Different evaluation measures assess different characteristics of machine learning algorithms. The empirical evaluation of algorithms and classifiers is a matter of on-going debate among researchers....},
  langid = {english}
}

@inproceedings{Soleimani2020BERTEvidenceRetrieval,
  title = {{{BERT}} for {{Evidence Retrieval}} and {{Claim Verification}}},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {Soleimani, Amir and Monz, Christof and Worring, Marcel},
  editor = {Jose, Joemon M. and Yilmaz, Emine and Magalh{\~a}es, Jo{\~a}o and Castells, Pablo and Ferro, Nicola and Silva, M{\'a}rio J. and Martins, Fl{\'a}vio},
  year = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {359--366},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-45442-5_45},
  abstract = {We investigate BERT in an evidence retrieval and claim verification pipeline for the task of evidence-based claim verification. To this end, we propose to use two BERT models, one for retrieving evidence sentences supporting or rejecting claims, and another for verifying claims based on the retrieved evidence sentences. To train the BERT retrieval system, we use pointwise and pairwise loss functions and examine the effect of hard negative mining. Our system achieves a new state of the art recall of 87.1 for retrieving evidence sentences out of the FEVER dataset 50K Wikipedia pages, and scores second in the leaderboard with the FEVER score of 69.7.},
  isbn = {978-3-030-45442-5},
  langid = {english}
}

@inproceedings{Song2020StructuralInformationPreserving,
  title = {Structural {{Information Preserving}} for {{Graph-to-Text Generation}}},
  booktitle = {Proceedings of the 58th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Song, Linfeng and Wang, Ante and Su, Jinsong and Zhang, Yue and Xu, Kun and Ge, Yubin and Yu, Dong},
  year = {2020},
  month = jul,
  pages = {7987--7998},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  doi = {10.18653/v1/2020.acl-main.712},
  urldate = {2020-10-16},
  abstract = {The task of graph-to-text generation aims at producing sentences that preserve the meaning of input graphs. As a crucial defect, the current state-of-the-art models may mess up or even drop the core structural information of input graphs when generating outputs. We propose to tackle this problem by leveraging richer training signals that can guide our model for preserving input information. In particular, we introduce two types of autoencoding losses, each individually focusing on different aspects (a.k.a. views) of input graphs. The losses are then back-propagated to better calibrate our model via multi-task training. Experiments on two benchmarks for graph-to-text generation show the effectiveness of our approach over a state-of-the-art baseline.}
}

@inproceedings{Sourati2023CaseBasedReasoningLanguage,
  title = {Case-{{Based Reasoning}} with {{Language Models}} for {{Classification}} of {{Logical Fallacies}}},
  booktitle = {Proceedings of the {{Thirty-Second International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Sourati, Zhivar and Ilievski, Filip and Sandlin, H{\^o}ng-{\^A}n and Mermoud, Alain},
  year = {2023},
  month = aug,
  pages = {5188--5196},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  address = {Macau, SAR China},
  doi = {10.24963/ijcai.2023/576},
  urldate = {2024-09-16},
  abstract = {The ease and speed of spreading misinformation and propaganda on the Web motivate the need to develop trustworthy technology for detecting fallacies in natural language arguments. However, state-of-the-art language modeling methods exhibit a lack of robustness on tasks like logical fallacy classification that require complex reasoning. In this paper, we propose a Case-Based Reasoning method that classifies new cases of logical fallacy by language-modeling-driven retrieval and adaptation of historical cases. We design four complementary strategies to enrich input representation for our model, based on external information about goals, explanations, counterarguments, and argument structure. Our experiments in in-domain and out-of-domain settings indicate that Case-Based Reasoning improves the accuracy and generalizability of language models. Our ablation studies suggest that representations of similar cases have a strong impact on the model performance, that models perform well with fewer retrieved cases, and that the size of the case database has a negligible effect on the performance. Finally, we dive deeper into the relationship between the properties of the retrieved cases and the model performance.},
  isbn = {978-1-956792-03-4},
  langid = {english}
}

@inproceedings{Spagnola2011EdgeDependentPathway,
  title = {Edge Dependent Pathway Scoring for Calculating Semantic Similarity in {{ConceptNet}}},
  booktitle = {Proceedings of the {{Ninth International Conference}} on {{Computational Semantics}} ({{IWCS}} 2011)},
  author = {Spagnola, Steve and Lagoze, Carl},
  year = {2011},
  urldate = {2020-05-02},
  abstract = {Most techniques that calculate the relatedness between two concepts use a semantic network, such as Wikipedia, WordNet, or ConceptNet, to find the shortest intermediate pathway between two nodes. These techniques assume that a low number of edges on the shortest pathway indicates conceptual similarity. Although this technique has proven valid in conforming to psychological data, we test the usefulness of additional pathway variables in ConceptNet, such as edge type and user-rated score. Our results show strong evidence for the application of additional pathway variables in calculating semantic similarity.}
}

@inproceedings{Spanoudakis2020ArgumentationAll,
  title = {Argumentation for All},
  booktitle = {Proceedings of the 35th {{Annual ACM Symposium}} on {{Applied Computing}}},
  author = {Spanoudakis, Nikolaos and Kostis, Konstantinos and Mania, Katerina},
  year = {2020},
  month = mar,
  pages = {980--982},
  publisher = {ACM},
  address = {Brno Czech Republic},
  doi = {10.1145/3341105.3374122},
  urldate = {2023-10-25},
  isbn = {978-1-4503-6866-7},
  langid = {english}
}

@inproceedings{Speer2017ConceptNetOpenMultilingual,
  title = {{{ConceptNet}} 5.5: An Open Multilingual Graph of General Knowledge},
  shorttitle = {{{ConceptNet}} 5.5},
  booktitle = {Proceedings of the {{Thirty-First AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Speer, Robyn and Chin, Joshua and Havasi, Catherine},
  year = {2017},
  month = feb,
  series = {{{AAAI}}'17},
  pages = {4444--4451},
  publisher = {AAAI Press},
  address = {San Francisco, California, USA},
  urldate = {2020-04-27},
  abstract = {Machine learning about language can be improved by supplying it with specific knowledge and sources of external information. We present here a new version of the linked open data resource ConceptNet that is particularly well suited to be used with modern NLP techniques such as word embeddings. ConceptNet is a knowledge graph that connects words and phrases of natural language with labeled edges. Its knowledge is collected from many sources that include expert-created resources, crowd-sourcing, and games with a purpose. It is designed to represent the general knowledge involved in understanding language, improving natural language applications by allowing the application to better understand the meanings behind the words people use. When ConceptNet is combined with word embeddings acquired from distributional semantics (such as word2vec), it provides applications with understanding that they would not acquire from distributional semantics alone, nor from narrower resources such as WordNet or DBPedia. We demonstrate this with state-of-the-art results on intrinsic evaluations of word relatedness that translate into improvements on applications of word vectors, including solving SAT-style analogies.}
}

@misc{Sperrle2019VIANAVisualInteractive,
  title = {{{VIANA}}: {{Visual Interactive Annotation}} of {{Argumentation}}},
  shorttitle = {{{VIANA}}},
  author = {Sperrle, Fabian and Sevastjanova, Rita and Kehlbeck, Rebecca and {El-Assady}, Mennatallah},
  year = {2019},
  month = jul,
  number = {arXiv:1907.12413},
  eprint = {1907.12413},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1907.12413},
  urldate = {2023-10-18},
  abstract = {Argumentation Mining addresses the challenging tasks of identifying boundaries of argumentative text fragments and extracting their relationships. Fully automated solutions do not reach satisfactory accuracy due to their insufficient incorporation of semantics and domain knowledge. Therefore, experts currently rely on time-consuming manual annotations. In this paper, we present a visual analytics system that augments the manual annotation process by automatically suggesting which text fragments to annotate next. The accuracy of those suggestions is improved over time by incorporating linguistic knowledge and language modeling to learn a measure of argument similarity from user interactions. Based on a long-term collaboration with domain experts, we identify and model five high-level analysis tasks. We enable close reading and note-taking, annotation of arguments, argument reconstruction, extraction of argument relations, and exploration of argument graphs. To avoid context switches, we transition between all views through seamless morphing, visually anchoring all text- and graph-based layers. We evaluate our system with a two-stage expert user study based on a corpus of presidential debates. The results show that experts prefer our system over existing solutions due to the speedup provided by the automatic suggestions and the tight integration between text and graph views.},
  archiveprefix = {arXiv}
}

@misc{SPICEAPIsSpecificationDeployment,
  title = {{{APIs Specification}} and {{Deployment}}},
  author = {{SPICE}},
  urldate = {2025-02-05}
}

@incollection{Sriram1997AnalogicalCaseBasedReasoning,
  title = {Analogical and {{Case-Based Reasoning}}},
  booktitle = {Intelligent {{Systems}} for {{Engineering}}: {{A Knowledge-based Approach}}},
  author = {Sriram, Ram D.},
  editor = {Sriram, Ram D.},
  year = {1997},
  pages = {285--334},
  publisher = {Springer},
  address = {London},
  doi = {10.1007/978-1-4471-0631-9_6},
  urldate = {2021-02-13},
  abstract = {Analogical Reasoning (AR) involves the use of past experiences to solve problems that are similar to problems solved before. This kind of reasoning is pervasive in engineering disciplines, particularly design. As there are no established, widely accepted, theories and methods for engineering design, practitioners often rely on prior design cases to exploit past successes and to avoid repeating the same mistakes. Research in analogical problem solving concentrates on the process of similarity recognition, mapping of past cases to current situation, and modification of past cases to suit a given task. An important aspect of this research is the development of representations that accurately capture prior experiences, conditions, and explanations. The experiences (cases) are represented and stored in knowledge-bases called case memories. As case memories grow in size, issues relating to indexing and retrieval become important. This aspect of analogical reasoning is called case- based reasoning (CBR). The primary emphasis of case-based reasoning is on the organization, hierarchy indexing and retrieval of case memory, while the main emphasis of analogical reasoning is on the process of modifying, adapting and verifying past derivations (cases) [5]. However, our treatment of case-based reasoning will also include elements of analogical reasoning.},
  isbn = {978-1-4471-0631-9},
  langid = {english}
}

@inproceedings{Stab2014AnnotatingArgumentComponents,
  title = {Annotating {{Argument Components}} and {{Relations}} in {{Persuasive Essays}}},
  booktitle = {Proceedings of {{COLING}} 2014, the 25th {{International Conference}} on {{Computational Linguistics}}: {{Technical Papers}}},
  author = {Stab, Christian and Gurevych, Iryna},
  year = {2014},
  month = aug,
  pages = {1501--1510},
  publisher = {{Dublin City University and Association for Computational Linguistics}},
  address = {Dublin, Ireland},
  urldate = {2023-10-20}
}

@inproceedings{Stab2014IdentifyingArgumentativeDiscourse,
  title = {Identifying {{Argumentative Discourse Structures}} in {{Persuasive Essays}}},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Stab, Christian and Gurevych, Iryna},
  year = {2014},
  month = oct,
  pages = {46--56},
  publisher = {Association for Computational Linguistics},
  address = {Doha, Qatar},
  doi = {10.3115/v1/D14-1006},
  urldate = {2020-06-11}
}

@article{Stab2017ParsingArgumentationStructures,
  title = {Parsing {{Argumentation Structures}} in {{Persuasive Essays}}},
  author = {Stab, Christian and Gurevych, Iryna},
  year = {2017},
  month = sep,
  journal = {Computational Linguistics},
  volume = {43},
  number = {3},
  pages = {619--659},
  doi = {10.1162/COLI_a_00295},
  urldate = {2020-09-14},
  abstract = {In this article, we present a novel approach for parsing argumentation structures. We identify argument components using sequence labeling at the token level and apply a new joint model for detecting argumentation structures. The proposed model globally optimizes argument component types and argumentative relations using Integer Linear Programming. We show that our model significantly outperforms challenging heuristic baselines on two different types of discourse. Moreover, we introduce a novel corpus of persuasive essays annotated with argumentation structures. We show that our annotation scheme and annotation guidelines successfully guide human annotators to substantial agreement.}
}

@inproceedings{Stab2018ArgumenTextSearchingArguments,
  title = {{{ArgumenText}}: {{Searching}} for {{Arguments}} in {{Heterogeneous Sources}}},
  shorttitle = {{{ArgumenText}}},
  booktitle = {Proceedings of the 2018 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Demonstrations}}},
  author = {Stab, Christian and Daxenberger, Johannes and Stahlhut, Chris and Miller, Tristan and Schiller, Benjamin and Tauchmann, Christopher and Eger, Steffen and Gurevych, Iryna},
  year = {2018},
  month = jun,
  pages = {21--25},
  publisher = {Association for Computational Linguistics},
  address = {New Orleans, Louisiana},
  doi = {10.18653/v1/N18-5005},
  urldate = {2020-09-02},
  abstract = {Argument mining is a core technology for enabling argument search in large corpora. However, most current approaches fall short when applied to heterogeneous texts. In this paper, we present an argument retrieval system capable of retrieving sentential arguments for any given controversial topic. By analyzing the highest-ranked results extracted from Web sources, we found that our system covers 89\% of arguments found in expert-curated lists of arguments from an online debate portal, and also identifies additional valid arguments.}
}

@article{Stab2018CrosstopicArgumentMining,
  title = {Cross-Topic {{Argument Mining}} from {{Heterogeneous Sources Using Attention-based Neural Networks}}},
  author = {Stab, Christian and Miller, Tristan and Gurevych, Iryna},
  year = {2018},
  month = feb,
  journal = {arXiv:1802.05758 [cs]},
  eprint = {1802.05758},
  primaryclass = {cs},
  urldate = {2018-10-17},
  abstract = {Argument mining is a core technology for automating argument search in large document collections. Despite its usefulness for this task, most current approaches to argument mining are designed for use only with specific text types and fall short when applied to heterogeneous texts. In this paper, we propose a new sentential annotation scheme that is reliably applicable by crowd workers to arbitrary Web texts. We source annotations for over 25,000 instances covering eight controversial topics. The results of cross-topic experiments show that our attention-based neural network generalizes best to unseen topics and outperforms vanilla BiLSTM models by 6\% in accuracy and 11\% in F-score.},
  archiveprefix = {arXiv}
}

@phdthesis{Stahl2004LearningKnowledgeintensiveSimilarity,
  title = {Learning of Knowledge-Intensive Similarity Measures in Case-Based Reasoning},
  author = {Stahl, Armin},
  year = {2004},
  address = {Kaiserslautern},
  isbn = {9783898258869},
  langid = {english},
  school = {University of Kaiserslautern}
}

@inproceedings{Stahl2005LearningSimilarityMeasures,
  title = {Learning {{Similarity Measures}}: {{A Formal View Based}} on a {{Generalized CBR Model}}},
  shorttitle = {Learning {{Similarity Measures}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Stahl, Armin},
  editor = {{Mu{\~n}oz-{\'A}vila}, H{\'e}ctor and Ricci, Francesco},
  year = {2005},
  pages = {507--521},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11536406_39},
  abstract = {Although similarity measures play a crucial role in CBR applications, clear methodologies for defining them have not been developed yet. One approach to simplify the definition of similarity measures involves the use of machine learning techniques. In this paper we investigate important aspects of these approaches in order to support a more goal-directed choice and application of existing approaches and to initiate the development of new techniques. This investigation is based on a novel formal generalization of the classic CBR cycle, which allows a more suitable analysis of the requirements, goals, assumptions and restrictions that are relevant for learning similarity measures.},
  isbn = {978-3-540-31855-2},
  langid = {english}
}

@misc{Stechly2024SelfVerificationLimitationsLarge,
  title = {On the {{Self-Verification Limitations}} of {{Large Language Models}} on {{Reasoning}} and {{Planning Tasks}}},
  author = {Stechly, Kaya and Valmeekam, Karthik and Kambhampati, Subbarao},
  year = {2024},
  month = feb,
  number = {arXiv:2402.08115},
  eprint = {2402.08115},
  primaryclass = {cs},
  doi = {10.48550/arXiv.2402.08115},
  urldate = {2024-03-28},
  abstract = {There has been considerable divergence of opinion on the reasoning abilities of Large Language Models (LLMs). While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion. This belief seemingly rests on the assumption that verification of correctness should be easier than generation--a rather classical argument from computational complexity--which should be irrelevant to LLMs to the extent that what they are doing is approximate retrieval. In this paper, we set out to systematically investigate the effectiveness of iterative prompting in the context of reasoning and planning. We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24, Graph Coloring, and STRIPS planning. We experiment both with the model critiquing its own answers and with an external correct reasoner verifying proposed solutions. In each case, we analyze whether the content of criticisms actually affects bottom line performance, and whether we can ablate elements of the augmented system without losing performance. We observe significant performance collapse with self-critique, significant performance gains with sound external verification, but that the content of critique doesn't matter to the performance of the system. In fact, merely re-prompting with a sound verifier maintains most of the benefits of more involved setups.},
  archiveprefix = {arXiv}
}

@misc{Steck2024CosineSimilarityEmbeddingsReally,
  title = {Is {{Cosine-Similarity}} of {{Embeddings Really About Similarity}}?},
  author = {Steck, Harald and Ekanadham, Chaitanya and Kallus, Nathan},
  year = {2024},
  month = mar,
  eprint = {2403.05440},
  primaryclass = {cs},
  doi = {10.1145/3589335.3651526},
  urldate = {2024-03-28},
  abstract = {Cosine-similarity is the cosine of the angle between two vectors, or equivalently the dot product between their normalizations. A popular application is to quantify semantic similarity between high-dimensional objects by applying cosine-similarity to a learned low-dimensional feature embedding. This can work better but sometimes also worse than the unnormalized dot-product between embedded vectors in practice. To gain insight into this empirical observation, we study embeddings derived from regularized linear models, where closed-form solutions facilitate analytical insights. We derive analytically how cosine-similarity can yield arbitrary and therefore meaningless `similarities.' For some linear models the similarities are not even unique, while for others they are implicitly controlled by the regularization. We discuss implications beyond linear models: a combination of different regularizations are employed when learning deep models; these have implicit and unintended effects when taking cosine-similarities of the resulting embeddings, rendering results opaque and possibly arbitrary. Based on these insights, we caution against blindly using cosine-similarity and outline alternatives.},
  archiveprefix = {arXiv}
}

@inproceedings{Stenetorp2012BratWebbasedTool,
  title = {Brat: A {{Web-based Tool}} for {{NLP-Assisted Text Annotation}}},
  shorttitle = {Brat},
  booktitle = {Proceedings of the {{Demonstrations}} at the 13th {{Conference}} of the {{European Chapter}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Stenetorp, Pontus and Pyysalo, Sampo and Topi{\'c}, Goran and Ohta, Tomoko and Ananiadou, Sophia and Tsujii, Jun'ichi},
  year = {2012},
  month = apr,
  pages = {102--107},
  publisher = {Association for Computational Linguistics},
  address = {Avignon, France},
  urldate = {2020-10-20}
}

@article{Storks2020RecentAdvancesNatural,
  title = {Recent {{Advances}} in {{Natural Language Inference}}: {{A Survey}} of {{Benchmarks}}, {{Resources}}, and {{Approaches}}},
  shorttitle = {Recent {{Advances}} in {{Natural Language Inference}}},
  author = {Storks, Shane and Gao, Qiaozi and Chai, Joyce Y.},
  year = {2020},
  month = feb,
  journal = {arXiv:1904.01172 [cs]},
  eprint = {1904.01172},
  primaryclass = {cs},
  urldate = {2020-09-02},
  abstract = {In the NLP community, recent years have seen a surge of research activities that address machines' ability to perform deep language understanding which goes beyond what is explicitly stated in text, rather relying on reasoning and knowledge of the world. Many benchmark tasks and datasets have been created to support the development and evaluation of such natural language inference ability. As these benchmarks become instrumental and a driving force for the NLP research community, this paper aims to provide an overview of recent benchmarks, relevant knowledge resources, and state-of-the-art learning and inference approaches in order to support a better understanding of this growing field.},
  archiveprefix = {arXiv}
}

@mastersthesis{Stricker2022VergleichGraphMatchingAlgorithmen,
  title = {{Vergleich von Graph-Matching Algorithmen im Rahmen des Case-Based Retrieval von Argumenten}},
  author = {Stricker, Nikita},
  year = {2022},
  month = dec,
  address = {Trier, Germany},
  langid = {ngerman},
  school = {Trier University}
}

@incollection{Stump2005WordFormationInflectionalMorphology,
  title = {Word-{{Formation}} and {{Inflectional Morphology}}},
  booktitle = {Handbook of {{Word-Formation}}},
  author = {Stump, Gregory T.},
  editor = {{\v S}tekauer, Pavol and Lieber, Rochelle},
  year = {2005},
  series = {Studies in {{Natural Language}} and {{Linguistic Theory}}},
  pages = {49--71},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/1-4020-3596-9_3},
  urldate = {2021-03-08},
  isbn = {978-1-4020-3596-8},
  langid = {english}
}

@inproceedings{Sukprapa2021TextSummarizationUsing,
  title = {Text {{Summarization}} Using {{Formal Argumentation}}},
  booktitle = {2021 16th {{International Joint Symposium}} on {{Artificial Intelligence}} and {{Natural Language Processing}} ({{iSAI-NLP}})},
  author = {Sukprapa, Isada and Hung, Nguyen Duy and Supnithi, Thepchai},
  year = {2021},
  month = dec,
  pages = {1--6},
  doi = {10.1109/iSAI-NLP54397.2021.9678183},
  urldate = {2023-10-26},
  abstract = {Current approaches to text summarization are not genuinely interested in how competent readers perform the task often by re-constructing the arguments in the text then arriving at the summary from conclusions of acceptable arguments. This paper aims to mimic this natural path using formal argumentation techniques. Assuming the availability Argumentative Discourse Unit (ADU) graph of the given text, we build structured argumentation frameworks called S-ASPIC+ and ABA representing the text. Then we use ABA proof procedures to re-construct arguments in the text and evaluate their acceptabilities. Finally, we aggregate the conclusions of acceptable arguments. We demonstrate our approach using a dataset of argumentative micro-texts and report the results, describing comparisons to other methods.}
}

@inproceedings{Sulea2017RecognizingTextualEntailment,
  title = {Recognizing {{Textual Entailment}} in {{Twitter Using Word Embeddings}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Evaluating Vector Space Representations}} for {{NLP}}},
  author = {{\c S}ulea, Octavia-Maria},
  year = {2017},
  month = sep,
  pages = {31--35},
  publisher = {Association for Computational Linguistics},
  address = {Copenhagen, Denmark},
  doi = {10.18653/v1/W17-5306},
  urldate = {2022-01-03},
  abstract = {In this paper, we investigate the application of machine learning techniques and word embeddings to the task of Recognizing Textual Entailment (RTE) in Social Media. We look at a manually labeled dataset consisting of user generated short texts posted on Twitter (tweets) and related to four recent media events (the Charlie Hebdo shooting, the Ottawa shooting, the Sydney Siege, and the German Wings crash) and test to what extent neural techniques and embeddings are able to distinguish between tweets that entail or contradict each other or that claim unrelated things. We obtain comparable results to the state of the art in a train-test setting, but we show that, due to the noisy aspect of the data, results plummet in an evaluation strategy crafted to better simulate a real-life train-test scenario.}
}

@inproceedings{Summers-Stay2017DeductiveAnalogicalReasoning,
  title = {Deductive and {{Analogical Reasoning}} on a {{Semantically Embedded Knowledge Graph}}},
  booktitle = {Artificial {{General Intelligence}}},
  author = {{Summers-Stay}, Douglas},
  editor = {Everitt, Tom and Goertzel, Ben and Potapov, Alexey},
  year = {2017},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {112--122},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-63703-7_11},
  abstract = {Representing knowledge as high-dimensional vectors in a continuous semantic vector space can help overcome the brittleness and incompleteness of traditional knowledge bases. We present a method for performing deductive reasoning directly in such a vector space, combining analogy, association, and deduction in a straightforward way at each step in a chain of reasoning, drawing on knowledge from diverse sources and ontologies.},
  isbn = {978-3-319-63703-7},
  langid = {english}
}

@inproceedings{Summers-Stay2020PropositionalDeductiveInference,
  title = {Propositional {{Deductive Inference}} by {{Semantic Vectors}}},
  booktitle = {Intelligent {{Systems}} and {{Applications}}},
  author = {{Summers-Stay}, Douglas},
  editor = {Bi, Yaxin and Bhatia, Rahul and Kapoor, Supriya},
  year = {2020},
  series = {Advances in {{Intelligent Systems}} and {{Computing}}},
  pages = {810--820},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-29516-5_61},
  abstract = {Representing symbols by high-dimensional vectors makes it easier to perform analogical and associational reasoning, but performing multi-step deductive reasoning typically requires a discrete knowledge base. In this paper, we show a method by which deductive inference can be performed directly on high-dimensional semantic vectors, and characterize some limitations and advantages of this approach. We provide a method for taking a set of semantic vectors representing propositions and encoding a knowledge base telling how those propositions are logically related.},
  isbn = {978-3-030-29516-5},
  langid = {english}
}

@article{Swets1963InformationRetrievalSystems,
  title = {Information {{Retrieval Systems}}},
  author = {Swets, John A.},
  year = {1963},
  journal = {Science},
  volume = {141},
  number = {3577},
  eprint = {1710636},
  eprinttype = {jstor},
  pages = {245--250},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075},
  urldate = {2021-03-13}
}

@article{Syed2021GeneratingInformativeConclusions,
  title = {Generating {{Informative Conclusions}} for {{Argumentative Texts}}},
  author = {Syed, Shahbaz and {Al-Khatib}, Khalid and Alshomary, Milad and Wachsmuth, Henning and Potthast, Martin},
  year = {2021},
  month = jun,
  journal = {arXiv:2106.01064 [cs]},
  eprint = {2106.01064},
  primaryclass = {cs},
  urldate = {2021-06-09},
  abstract = {The purpose of an argumentative text is to support a certain conclusion. Yet, they are often omitted, expecting readers to infer them rather. While appropriate when reading an individual text, this rhetorical device limits accessibility when browsing many texts (e.g., on a search engine or on social media). In these scenarios, an explicit conclusion makes for a good candidate summary of an argumentative text. This is especially true if the conclusion is informative, emphasizing specific concepts from the text. With this paper we introduce the task of generating informative conclusions: First, Webis-ConcluGen-21 is compiled, a large-scale corpus of 136,996 samples of argumentative texts and their conclusions. Second, two paradigms for conclusion generation are investigated; one extractive, the other abstractive in nature. The latter exploits argumentative knowledge that augment the data via control codes and finetuning the BART model on several subsets of the corpus. Third, insights are provided into the suitability of our corpus for the task, the differences between the two generation paradigms, the trade-off between informativeness and conciseness, and the impact of encoding argumentative knowledge. The corpus, code, and the trained models are publicly available.},
  archiveprefix = {arXiv}
}

@article{Tai2015ImprovedSemanticRepresentations,
  title = {Improved {{Semantic Representations From Tree-Structured Long Short-Term Memory Networks}}},
  author = {Tai, Kai Sheng and Socher, Richard and Manning, Christopher D.},
  year = {2015},
  month = feb,
  journal = {arXiv:1503.00075 [cs]},
  eprint = {1503.00075},
  primaryclass = {cs},
  abstract = {Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).},
  archiveprefix = {arXiv}
}

@misc{Tay2022ScalingLawsVs,
  title = {Scaling {{Laws}} vs {{Model Architectures}}: {{How}} Does {{Inductive Bias Influence Scaling}}?},
  shorttitle = {Scaling {{Laws}} vs {{Model Architectures}}},
  author = {Tay, Yi and Dehghani, Mostafa and Abnar, Samira and Chung, Hyung Won and Fedus, William and Rao, Jinfeng and Narang, Sharan and Tran, Vinh Q. and Yogatama, Dani and Metzler, Donald},
  year = {2022},
  month = jul,
  number = {arXiv:2207.10551},
  eprint = {2207.10551},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2207.10551},
  urldate = {2024-04-25},
  abstract = {There have been a lot of interest in the scaling properties of Transformer models. However, not much has been done on the front of investigating the effect of scaling properties of different inductive biases and model architectures. Do model architectures scale differently? If so, how does inductive bias affect scaling behaviour? How does this influence upstream (pretraining) and downstream (transfer)? This paper conducts a systematic study of scaling behaviour of ten diverse model architectures such as Transformers, Switch Transformers, Universal Transformers, Dynamic convolutions, Performers, and recently proposed MLP-Mixers. Via extensive experiments, we show that (1) architecture is an indeed an important consideration when performing scaling and (2) the best performing model can fluctuate at different scales. We believe that the findings outlined in this work has significant implications to how model architectures are currently evaluated in the community.},
  archiveprefix = {arXiv}
}

@inproceedings{Thorburn2022OptimizingLanguageModels,
  title = {Optimizing {{Language Models}} for {{Argumentative Reasoning}}},
  booktitle = {{{ArgML}}@{{COMMA}}},
  author = {Thorburn, Luke and Kruger, Ariel},
  year = {2022},
  urldate = {2023-04-07},
  abstract = {Large transformer-based causal language models are capable of strong performance on many natural language processing tasks. Here, we systematically evaluate the performance of the 2.7 billion parameter GPT Neo pre-trained language model on 6 argumentative reasoning tasks under 5 different optimization strategies, including prompt programming, soft prompts, and parameter tuning. We report both intrinsic evaluation metrics (perplexity), and extrinsic measures of the coherence of model outputs, as judged by an expert human rater. With a few exceptions, the rate at which models produced coherent responses ranged from 15-50\%. In contrast, human performance (users of the Kialo argument mapping platform) ranged from 65-82\% coherent, depending on the task. These results suggest that larger, suitably optimized language models may be capable of supporting authors and auditors of natural language argument maps in human-in-the-loop settings. We share our finetuned models and code.}
}

@article{Ting2011ConfusionMatrix,
  title = {Confusion {{Matrix}}},
  author = {Ting, Kai Ming},
  year = {2011},
  journal = {Encyclopedia of Machine Learning},
  pages = {209--209},
  publisher = {Springer, Boston, MA},
  doi = {10.1007/978-0-387-30164-8_157},
  urldate = {2021-03-14},
  abstract = {A confusion matrix summarizes the classification performance of a classifier with respect to some test data. It is a two-dimensional matrix, indexed in one dimension by the true class of an object...},
  langid = {english}
}

@book{Toulmin2003UsesArgument,
  title = {The {{Uses}} of {{Argument}}},
  author = {Toulmin, Stephen E.},
  year = {2003},
  month = jul,
  publisher = {Cambridge University Press},
  abstract = {Traditionally, logic has been claimed to be 'the science of rational argument', but the relevance to our everyday disputes of the formal logician's results has remained unclear. The abstract character of traditional logic cuts the subject off from practical considerations; Mr Toulmin enquires why this is so, and shows how an alternative conception can be of more general value. Starting from an examination of the actual procedures in different fields of argument - the practice, as opposed to the theory, of logic - he discloses a richer variety than is allowed for by any available system. He argues that jurisprudence rather than mathematics should be the logician's model in analysing rational procedures, and that logic should be a comparative and not a purely formal study. These suggestions lead to conclusions which many will consider controversial; though they will also be widely recognized as interesting and illuminating. This book extends into general philosophy lines of enquiry already sketched by Mr Toulmin in his earlier books on ethics and the philosophy of science. The ordinary reader will find in it the same clarity and intelligibility; and the professional philosopher will acknowledge the same power to break new ground (and circumvent old difficulties) by posing fresh and stimulating questions.},
  googlebooks = {8UYgegaB1S0C},
  isbn = {978-0-521-53483-3},
  langid = {english}
}

@inproceedings{Toutanova2003FeatureRichPartofSpeechTagging,
  title = {Feature-{{Rich Part-of-Speech Tagging}} with a {{Cyclic Dependency Network}}},
  booktitle = {Proceedings of the 2003 {{Human Language Technology Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Toutanova, Kristina and Klein, Dan and Manning, Christopher D. and Singer, Yoram},
  year = {2003},
  pages = {252--259},
  urldate = {2021-02-09}
}

@misc{Touvron2023LlamaOpenFoundation,
  title = {Llama 2: {{Open Foundation}} and {{Fine-Tuned Chat Models}}},
  shorttitle = {Llama 2},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  year = {2023},
  month = jul,
  number = {arXiv:2307.09288},
  eprint = {2307.09288},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.09288},
  urldate = {2023-11-20},
  abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
  archiveprefix = {arXiv}
}

@inproceedings{Trautmann2020FineGrainedArgumentUnit,
  title = {Fine-{{Grained Argument Unit Recognition}} and {{Classification}}},
  booktitle = {Proceedings of the {{Thirty-Fourth AAAI Conference}} on {{Artificial Intelligence}} ({{AAAI}} 2020)},
  author = {Trautmann, Dietrich and Daxenberger, Johannes and Stab, Christian and Sch{\"u}tze, Hinrich and Gurevych, Iryna},
  year = {2020},
  month = feb,
  eprint = {1904.09688},
  address = {New York, NY, USA},
  urldate = {2020-05-23},
  abstract = {Prior work has commonly defined argument retrieval from heterogeneous document collections as a sentence-level classification task. Consequently, argument retrieval suffers both from low recall and from sentence segmentation errors making it difficult for humans and machines to consume the arguments. In this work, we argue that the task should be performed on a more fine-grained level of sequence labeling. For this, we define the task as Argument Unit Recognition and Classification (AURC). We present a dataset of arguments from heterogeneous sources annotated as spans of tokens within a sentence, as well as with a corresponding stance. We show that and how such difficult argument annotations can be effectively collected through crowdsourcing with high interannotator agreement. The new benchmark, AURC-8, contains up to 15\% more arguments per topic as compared to annotations on the sentence level. We identify a number of methods targeted at AURC sequence labeling, achieving close to human performance on known domains. Further analysis also reveals that, contrary to previous approaches, our methods are more robust against sentence segmentation errors. We publicly release our code and the AURC-8 dataset.},
  archiveprefix = {arXiv}
}

@article{Trautmann2020RelationalFineGrainedArgument,
  title = {Relational and {{Fine-Grained Argument Mining}}},
  author = {Trautmann, Dietrich and Fromm, Michael and Tresp, Volker and Seidl, Thomas and Sch{\"u}tze, Hinrich},
  year = {2020},
  month = jul,
  journal = {Datenbank-Spektrum},
  volume = {20},
  number = {2},
  pages = {99--105},
  issn = {1610-1995},
  doi = {10.1007/s13222-020-00341-z},
  urldate = {2020-09-12},
  abstract = {In our project ReMLAV, funded within the DFG Priority Program RATIO (http://www.spp-ratio.de/), we focus on relational and fine-grained argument mining. In this article, we first introduce the problems we address and then summarize related work. The main part of the article describes our research on argument mining, both coarse-grained and fine-grained methods, and on same-side stance classification, a~relational approach to the problem of stance classification. We conclude with an outlook.},
  langid = {english}
}

@article{Trinh2019SimpleMethodCommonsense,
  title = {A {{Simple Method}} for {{Commonsense Reasoning}}},
  author = {Trinh, Trieu H. and Le, Quoc V.},
  year = {2019},
  month = sep,
  journal = {arXiv:1806.02847 [cs]},
  eprint = {1806.02847},
  primaryclass = {cs},
  urldate = {2020-06-07},
  abstract = {Commonsense reasoning is a long-standing challenge for deep learning. For example, it is difficult to use neural networks to tackle the Winograd Schema dataset (Levesque et al., 2011). In this paper, we present a simple method for commonsense reasoning with neural networks, using unsupervised learning. Key to our method is the use of language models, trained on a massive amount of unlabled data, to score multiple choice questions posed by commonsense reasoning tests. On both Pronoun Disambiguation and Winograd Schema challenges, our models outperform previous state-of-the-art methods by a large margin, without using expensive annotated knowledge bases or hand-engineered features. We train an array of large RNN language models that operate at word or character level on LM-1-Billion, CommonCrawl, SQuAD, Gutenberg Books, and a customized corpus for this task and show that diversity of training data plays an important role in test performance. Further analysis also shows that our system successfully discovers important features of the context that decide the correct answer, indicating a good grasp of commonsense knowledge.},
  archiveprefix = {arXiv}
}

@article{Turing1950ComputingMachineryIntelligence,
  title = {Computing {{Machinery}} and {{Intelligence}}},
  author = {Turing, A. M.},
  year = {1950},
  month = oct,
  journal = {Mind},
  volume = {LIX},
  number = {236},
  pages = {433--460},
  issn = {0026-4423},
  doi = {10.1093/mind/LIX.236.433},
  urldate = {2021-02-06}
}

@inproceedings{Turpin2006UserPerformancePrecision,
  title = {User Performance versus Precision Measures for Simple Search Tasks},
  booktitle = {{{SIGIR}} 2006: {{Proceedings}} of the 29th {{Annual International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}, {{Seattle}}, {{Washington}}, {{USA}}, {{August}} 6-11, 2006},
  author = {Turpin, Andrew and Scholer, Falk},
  year = {2006},
  month = jan,
  pages = {11--18},
  doi = {10.1145/1148170.1148176}
}

@article{Twardy2004ArgumentMapsImprove,
  title = {Argument {{Maps Improve Critical Thinking}}},
  author = {Twardy, Charles},
  year = {2004},
  month = may,
  journal = {Teaching Philosophy},
  volume = {27},
  number = {2},
  pages = {95--116},
  doi = {10.5840/teachphil200427213},
  urldate = {2022-04-21},
  abstract = {This paper describes the Reason! method of argument mapping (along with the associated Reason!Able software) and measures its effect on the California Critical Thinking Skills Test. The result of the author's study is that students who use the Reason! method, rather than other methods of teaching critical thinking skills, perform better on the California test. What accounts for the effectiveness of Reason! method is its use of argument maps, a method of representing arguments using a two-dimensional diagram involving boxes and arrows. In addition to describing the method, and presenting empirical data that supports the Reason! approach, the author provides an assessment of the various strengths and weaknesses of the  method and details its use at the University of Melbourne.},
  langid = {english}
}

@book{VanEemeren1996FundamentalsArgumentationTheory,
  title = {Fundamentals of {{Argumentation Theory}}},
  shorttitle = {Fundamentals of {{Argumentation Theory}}},
  author = {{van Eemeren}, Frans H. and Grootendorst, Rob and Johnson, Ralph H. and Plantin, Christian and Willard, Charles A.},
  year = {1996},
  month = mar,
  edition = {1 edition},
  publisher = {Routledge},
  address = {Mahwah, N.J},
  abstract = {Argumentation theory is a distinctly multidisciplinary field of inquiry. It draws its data, assumptions, and methods from disciplines as disparate as formal logic and discourse analysis, linguistics and forensic science, philosophy and psychology, political science and education, sociology and law, and rhetoric and artificial intelligence. This presents the growing group of interested scholars and students with a problem of access, since it is even for those active in the field not common to have acquired a familiarity with relevant aspects of each discipline that enters into this multidisciplinary matrix. This book offers its readers a unique comprehensive survey of the various theoretical contributions which have been made to the study of argumentation. It discusses the historical works that provide the background to the field and all major approaches and trends in contemporary research.   Argument has been the subject of systematic inquiry for twenty-five hundred years. It has been graced with theories, such as formal logic or the legal theory of evidence, that have acquired a more or less settled provenance with regard to specific issues. But there has been nothing to date that qualifies as a unified general theory of argumentation, in all its richness and complexity. This being so, the argumentation theorist must have access to materials and methods that lie beyond his or her "home" subject. It is precisely on this account that this volume is offered to all the constituent research communities and their students. Apart from the historical sections, each chapter provides an economical introduction to the problems and methods that characterize a given part of the contemporary research program. Because the chapters are self-contained, they can be consulted in the order of a reader's interests or research requirements. But there is value in reading the work in its entirety. Jointly authored by the very people whose research has done much to define the current state of argumentation theory and to point the way toward more general and unified future treatments, this book is an impressively authoritative contribution to the field.},
  isbn = {978-0-8058-1862-8},
  langid = {english}
}

@book{VanEemeren2014HandbookArgumentationTheory,
  title = {Handbook of {{Argumentation Theory}}},
  author = {Van Eemeren, Frans H. and Garssen, Bart and Krabbe, Erik C. W. and Snoeck Henkemans, A. Francisca and Verheij, Bart and Wagemans, Jean H. M.},
  year = {2014},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-90-481-9473-5},
  urldate = {2023-07-26},
  isbn = {978-90-481-9472-8 978-90-481-9473-5},
  langid = {english}
}

@article{VanEemeren2017ArgumentationTheoryFormal,
  title = {Argumentation Theory in Formal and Computational Perspective},
  author = {{van Eemeren}, Frans H. and Verheij, Bart},
  year = {2017},
  journal = {IFCoLog Journal of Logics and Their Applications},
  volume = {4},
  number = {8},
  pages = {2099--2181}
}

@article{VanGelder2007RationaleRationale,
  title = {The Rationale for {{Rationale}}™},
  author = {{van Gelder}, Tim},
  year = {2007},
  month = mar,
  journal = {Law, Probability and Risk},
  volume = {6},
  number = {1-4},
  pages = {23--42},
  issn = {1470-8396},
  doi = {10.1093/lpr/mgm032},
  urldate = {2022-04-21},
  abstract = {Complex reasoning and argumentation are central to legal practice. Software-supported argument mapping may be able to help lawyers reason and argue more effectively. This article describes Rationale™, a generic argument mapping software package, and reviews some evidence that using it can help improve reasoning, i.e. make people smarter. It then explores three different explanations for this potential benefit: usability, complementation and semi-formality. First, argument mapping software can be more usable for reasoning activities than traditional methods because it can inherit the wisdom gained through decades of research and experience into usability, can exploit a wider range of representational resources, and is designed specifically to support reasoning activities. Second, such software works by complementing the strengths and weaknesses of our natural or inbuilt cognitive capacities. Third, it helps shift reasoning and argumentation into a semi-formal mode, a kind of `sweet spot' between the laxness of everyday reasoning and the straightjacket of formal logic.}
}

@inproceedings{Vaswani2017AttentionAllYou,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and ukasz Kaiser, {\L} and Polosukhin, Illia},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-04-25},
  abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.}
}

@mastersthesis{VelardeJara2024KnowledgeBasedFactVerification,
  title = {Knowledge-{{Based Fact Verification}}},
  author = {Velarde Jara, Juan Rodrigo},
  year = {2024},
  month = jun,
  address = {Trier, Germany},
  langid = {english},
  school = {Trier University}
}

@misc{Verga2024ReplacingJudgesJuries,
  title = {Replacing {{Judges}} with {{Juries}}: {{Evaluating LLM Generations}} with a {{Panel}} of {{Diverse Models}}},
  shorttitle = {Replacing {{Judges}} with {{Juries}}},
  author = {Verga, Pat and Hofstatter, Sebastian and Althammer, Sophia and Su, Yixuan and Piktus, Aleksandra and Arkhangorodsky, Arkady and Xu, Minjie and White, Naomi and Lewis, Patrick},
  year = {2024},
  month = apr,
  number = {arXiv:2404.18796},
  eprint = {2404.18796},
  primaryclass = {cs},
  doi = {10.48550/arXiv.2404.18796},
  urldate = {2024-05-01},
  abstract = {As Large Language Models (LLMs) have become more advanced, they have outpaced our abilities to accurately evaluate their quality. Not only is finding data to adequately probe particular model properties difficult, but evaluating the correctness of a model's freeform generation alone is a challenge. To address this, many evaluations now rely on using LLMs themselves as judges to score the quality of outputs from other LLMs. Evaluations most commonly use a single large model like GPT4. While this method has grown in popularity, it is costly, has been shown to introduce intramodel bias, and in this work, we find that very large models are often unnecessary. We propose instead to evaluate models using a Panel of LLm evaluators (PoLL). Across three distinct judge settings and spanning six different datasets, we find that using a PoLL composed of a larger number of smaller models outperforms a single large judge, exhibits less intra-model bias due to its composition of disjoint model families, and does so while being over seven times less expensive.},
  archiveprefix = {arXiv}
}

@article{Vilnis2014WordRepresentationsGaussian,
  title = {Word {{Representations}} via {{Gaussian Embedding}}},
  author = {Vilnis, Luke and McCallum, Andrew},
  year = {2014},
  month = dec,
  journal = {arXiv:1412.6623 [cs]},
  eprint = {1412.6623},
  primaryclass = {cs},
  abstract = {Current work in lexical distributed representations maps each word to a point vector in low-dimensional space. Mapping instead to a density provides many interesting advantages, including better capturing uncertainty about a representation and its relationships, expressing asymmetries more naturally than dot product or cosine similarity, and enabling more expressive parameterization of decision boundaries. This paper advocates for density-based distributed embeddings and presents a method for learning representations in the space of Gaussian distributions. We compare performance on various word embedding benchmarks, investigate the ability of these embeddings to model entailment and other asymmetric relationships, and explore novel properties of the representation.},
  archiveprefix = {arXiv}
}

@misc{Voigt2014Argdown,
  title = {Argdown},
  author = {Voigt, Christian},
  year = {2014},
  month = mar,
  urldate = {2022-04-21},
  abstract = {a simple syntax for complex argumentation}
}

@inproceedings{VonAhn2006VerbosityGameCollecting,
  title = {Verbosity: A Game for Collecting Common-Sense Facts},
  shorttitle = {Verbosity},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {{von Ahn}, Luis and Kedia, Mihir and Blum, Manuel},
  year = {2006},
  month = apr,
  series = {{{CHI}} '06},
  pages = {75--78},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1124772.1124784},
  urldate = {2021-02-12},
  abstract = {We address the problem of collecting a database of ""common-sense facts"" using a computer game. Informally, a common-sense fact is a true statement about the world that is known to most humans: ""milk is white,"" ""touching hot metal hurts,"" etc. Several efforts have been devoted to collecting common-sense knowledge for the purpose of making computer programs more intelligent. Such efforts, however, have not succeeded in amassing enough data because the manual process of entering these facts is tedious. We therefore introduce Verbosity, a novel interactive system in the form of an enjoyable game. People play Verbosity because it is fun, and as a side effect of them playing, we collect accurate common-sense knowledge. Verbosity is an example of a game that not only brings people together for leisure, but also collects useful data for computer science.},
  isbn = {978-1-59593-372-0}
}

@article{Voskoglou2014AnalogyBasedCaseBasedReasoning,
  title = {Analogy-{{Based}} and {{Case-Based Reasoning}}: {{Two}} Sides of the Same Coin},
  shorttitle = {Analogy-{{Based}} and {{Case-Based Reasoning}}},
  author = {Voskoglou, Michael Gr and Salem, Abdel-Badeeh M.},
  year = {2014},
  month = may,
  journal = {arXiv:1405.7567 [cs]},
  eprint = {1405.7567},
  primaryclass = {cs},
  urldate = {2020-05-26},
  abstract = {Analogy-Based (or Analogical) and Case-Based Reasoning (ABR and CBR) are two similar problem solving processes based on the adaptation of the solution of past problems for use with a new analogous problem. In this paper we review these two processes and we give some real world examples with emphasis to the field of Medicine, where one can find some of the most common and useful CBR applications. We also underline the differences between CBR and the classical rule-induction algorithms, we discuss the criticism for CBR methods and we focus on the future trends of research in the area of CBR.},
  archiveprefix = {arXiv}
}

@inproceedings{Wacholder2014AnnotatingMultipartyDiscourse,
  title = {Annotating {{Multiparty Discourse}}: {{Challenges}} for {{Agreement Metrics}}},
  shorttitle = {Annotating {{Multiparty Discourse}}},
  booktitle = {Proceedings of {{LAW VIII}} - {{The}} 8th {{Linguistic Annotation Workshop}}},
  author = {Wacholder, Nina and Muresan, Smaranda and Ghosh, Debanjan and Aakhus, Mark},
  year = {2014},
  month = aug,
  pages = {120--128},
  publisher = {{Association for Computational Linguistics and Dublin City University}},
  address = {Dublin, Ireland},
  doi = {10.3115/v1/W14-4918},
  urldate = {2021-02-22}
}

@inproceedings{Wachsmuth2016UsingArgumentMining,
  title = {Using {{Argument Mining}} to {{Assess}} the {{Argumentation Quality}} of {{Essays}}},
  booktitle = {Proceedings of {{COLING}} 2016, the 26th {{International Conference}} on {{Computational Linguistics}}: {{Technical Papers}}},
  author = {Wachsmuth, Henning and {Al-Khatib}, Khalid and Stein, Benno},
  year = {2016},
  month = dec,
  pages = {1680--1691},
  publisher = {The COLING 2016 Organizing Committee},
  address = {Osaka, Japan},
  urldate = {2019-09-03},
  abstract = {Argument mining aims to determine the argumentative structure of texts. Although it is said to be crucial for future applications such as writing support systems, the benefit of its output has rarely been evaluated. This paper puts the analysis of the output into the focus. In particular, we investigate to what extent the mined structure can be leveraged to assess the argumentation quality of persuasive essays. We find insightful statistical patterns in the structure of essays. From these, we derive novel features that we evaluate in four argumentation-related essay scoring tasks. Our results reveal the benefit of argument mining for assessing argumentation quality. Among others, we improve the state of the art in scoring an essay's organization and its argument strength.}
}

@inproceedings{Wachsmuth2017ArgumentationQualityAssessment,
  title = {Argumentation {{Quality Assessment}}: {{Theory}} vs. {{Practice}}},
  shorttitle = {Argumentation {{Quality Assessment}}},
  booktitle = {Proceedings of the 55th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 2: {{Short Papers}})},
  author = {Wachsmuth, Henning and Naderi, Nona and Habernal, Ivan and Hou, Yufang and Hirst, Graeme and Gurevych, Iryna and Stein, Benno},
  year = {2017},
  month = jul,
  pages = {250--255},
  publisher = {Association for Computational Linguistics},
  address = {Vancouver, Canada},
  doi = {10.18653/v1/P17-2039},
  urldate = {2019-09-04},
  abstract = {Argumentation quality is viewed differently in argumentation theory and in practical assessment approaches. This paper studies to what extent the views match empirically. We find that most observations on quality phrased spontaneously are in fact adequately represented by theory. Even more, relative comparisons of arguments in practice correlate with absolute quality ratings based on theory. Our results clarify how the two views can learn from each other.}
}

@inproceedings{Wachsmuth2017BuildingArgumentSearch,
  title = {Building an {{Argument Search Engine}} for the {{Web}}},
  booktitle = {Proceedings of the 4th {{Workshop}} on {{Argument Mining}}},
  author = {Wachsmuth, Henning and Potthast, Martin and Al Khatib, Khalid and Ajjour, Yamen and Puschmann, Jana and Qu, Jiani and Dorsch, Jonas and Morari, Viorel and Bevendorff, Janek and Stein, Benno},
  year = {2017},
  month = sep,
  pages = {49--59},
  publisher = {Association for Computational Linguistics},
  address = {Copenhagen, Denmark},
  urldate = {2018-10-17},
  abstract = {Computational argumentation is expected to play a critical role in the future of web search. To make this happen, many search-related questions must be revisited, such as how people query for arguments, how to mine arguments from the web, or how to rank them. In this paper, we develop an argument search framework for studying these and further questions. The framework allows for the composition of approaches to acquiring, mining, assessing, indexing, querying, retrieving, ranking, and presenting arguments while relying on standard infrastructure and interfaces. Based on the framework, we build a prototype search engine, called args, that relies on an initial, freely accessible index of nearly 300k arguments crawled from reliable web resources. The framework and the argument search engine are intended as an environment for collaborative research on computational argumentation and its practical evaluation.}
}

@inproceedings{Wachsmuth2017ComputationalArgumentationQuality,
  title = {Computational {{Argumentation Quality Assessment}} in {{Natural Language}}},
  booktitle = {Proceedings of the 15th {{Conference}} of the {{European Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Volume}} 1, {{Long Papers}}},
  author = {Wachsmuth, Henning and Naderi, Nona and Hou, Yufang and Bilu, Yonatan and Prabhakaran, Vinodkumar and Thijm, Tim Alberdingk and Hirst, Graeme and Stein, Benno},
  year = {2017},
  month = apr,
  pages = {176--187},
  publisher = {Association for Computational Linguistics},
  address = {Valencia, Spain},
  urldate = {2019-09-04},
  abstract = {Research on computational argumentation faces the problem of how to automatically assess the quality of an argument or argumentation. While different quality dimensions have been approached in natural language processing, a common understanding of argumentation quality is still missing. This paper presents the first holistic work on computational argumentation quality in natural language. We comprehensively survey the diverse existing theories and approaches to assess logical, rhetorical, and dialectical quality dimensions, and we derive a systematic taxonomy from these. In addition, we provide a corpus with 320 arguments, annotated for all 15 dimensions in the taxonomy. Our results establish a common ground for research on computational argumentation quality assessment.}
}

@inproceedings{Wachsmuth2017PageRankArgumentRelevance,
  title = {``{{PageRank}}'' for {{Argument Relevance}}},
  booktitle = {Proceedings of the 15th {{Conference}} of the {{European Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Volume}} 1, {{Long Papers}}},
  author = {Wachsmuth, Henning and Stein, Benno and Ajjour, Yamen},
  year = {2017},
  month = apr,
  pages = {1117--1127},
  publisher = {Association for Computational Linguistics},
  address = {Valencia, Spain},
  urldate = {2019-09-04},
  abstract = {Future search engines are expected to deliver pro and con arguments in response to queries on controversial topics. While argument mining is now in the focus of research, the question of how to retrieve the relevant arguments remains open. This paper proposes a radical model to assess relevance objectively at web scale: the relevance of an argument's conclusion is decided by what other arguments reuse it as a premise. We build an argument graph for this model that we analyze with a recursive weighting scheme, adapting key ideas of PageRank. In experiments on a large ground-truth argument graph, the resulting relevance scores correlate with human average judgments. We outline what natural language challenges must be faced at web scale in order to stepwise bring argument relevance to web search engines.}
}

@inproceedings{Wachsmuth2018ArgumentationSynthesisFollowing,
  title = {Argumentation {{Synthesis}} Following {{Rhetorical Strategies}}},
  booktitle = {Proceedings of the 27th {{International Conference}} on {{Computational Linguistics}}},
  author = {Wachsmuth, Henning and Stede, Manfred and El Baff, Roxanne and {Al-Khatib}, Khalid and Skeppstedt, Maria and Stein, Benno},
  year = {2018},
  month = aug,
  pages = {3753--3765},
  publisher = {Association for Computational Linguistics},
  address = {Santa Fe, New Mexico, USA},
  urldate = {2020-09-09},
  abstract = {Persuasion is rarely achieved through a loose set of arguments alone. Rather, an effective delivery of arguments follows a rhetorical strategy, combining logical reasoning with appeals to ethics and emotion. We argue that such a strategy means to select, arrange, and phrase a set of argumentative discourse units. In this paper, we model rhetorical strategies for the computational synthesis of effective argumentation. In a study, we let 26 experts synthesize argumentative texts with different strategies for 10 topics. We find that the experts agree in the selection significantly more when following the same strategy. While the texts notably vary for different strategies, especially their arrangement remains stable. The results suggest that our model enables a strategical synthesis.}
}

@misc{Wallace2024InstructionHierarchyTraining,
  title = {The {{Instruction Hierarchy}}: {{Training LLMs}} to {{Prioritize Privileged Instructions}}},
  shorttitle = {The {{Instruction Hierarchy}}},
  author = {Wallace, Eric and Xiao, Kai and Leike, Reimar and Weng, Lilian and Heidecke, Johannes and Beutel, Alex},
  year = {2024},
  month = apr,
  number = {arXiv:2404.13208},
  eprint = {2404.13208},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-04-25},
  abstract = {Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts. In this work, we argue that one of the primary vulnerabilities underlying these attacks is that LLMs often consider system prompts (e.g., text from an application developer) to be the same priority as text from untrusted users and third parties. To address this, we propose an instruction hierarchy that explicitly defines how models should behave when instructions of different priorities conflict. We then propose a data generation method to demonstrate this hierarchical instruction following behavior, which teaches LLMs to selectively ignore lower-privileged instructions. We apply this method to GPT-3.5, showing that it drastically increases robustness -- even for attack types not seen during training -- while imposing minimal degradations on standard capabilities.},
  archiveprefix = {arXiv}
}

@book{Walton2008ArgumentationSchemes,
  title = {Argumentation {{Schemes}}},
  author = {Walton, Douglas and Reed, Christopher and Macagno, Fabrizio},
  year = {2008},
  month = aug,
  publisher = {Cambridge University Press},
  abstract = {This book provides a systematic analysis of many common argumentation schemes and a compendium of 96 schemes. The study of these schemes, or forms of argument that capture stereotypical patterns of human reasoning, is at the core of argumentation research. Surveying all aspects of argumentation schemes from the ground up, the book takes the reader from the elementary exposition in the first chapter to the latest state of the art in the research efforts to formalize and classify the schemes, outlined in the last chapter. It provides a systematic and comprehensive account, with notation suitable for computational applications that increasingly make use of argumentation schemes.},
  isbn = {1-316-58313-9}
}

@book{Walton2013ArgumentationSchemesPresumptive,
  title = {Argumentation {{Schemes}} for {{Presumptive Reasoning}}},
  author = {Walton, Douglas},
  year = {2013},
  month = nov,
  publisher = {Routledge},
  doi = {10.4324/9780203811160},
  urldate = {2018-09-05},
  abstract = {Recent concerns with the evaluation of argumentation in informal logic and speech communication center around nondemonstrative arguments that lead to tentative},
  isbn = {978-1-136-68706-8},
  langid = {english}
}

@article{Walton2013TeleologicalJustificationArgumentation,
  title = {Teleological {{Justification}} of {{Argumentation Schemes}}},
  author = {Walton, Douglas and Sartor, Giovanni},
  year = {2013},
  month = may,
  journal = {Argumentation},
  volume = {27},
  number = {2},
  pages = {111--142},
  issn = {1572-8374},
  doi = {10.1007/s10503-012-9262-y},
  abstract = {Argumentation schemes are forms of reasoning that are fallible but correctable within a self-correcting framework. Their use provides a basis for taking rational action or for reasonably accepting a conclusion as a tentative hypothesis, but they are not deductively valid. We argue that teleological reasoning can provide the basis for justifying the use of argument schemes both in monological and dialogical reasoning. We consider how such a teleological justification, besides being inspired by the aim of directing a bounded cognizer to true belief and correct choices, needs to take into account the attitudes of dialogue partners as well as normative models of dialogue and communicative activity types, in particular social and cultural settings.},
  langid = {english}
}

@article{Walton2016ClassificationSystemArgumentation,
  title = {A Classification System for Argumentation Schemes},
  author = {Walton, Douglas and Macagno, Fabrizio},
  year = {2016},
  month = jun,
  journal = {Argument \& Computation},
  volume = {6},
  number = {3},
  pages = {219--245},
  doi = {10.1080/19462166.2015.1123772}
}

@article{Wambsganss2021ArgueBotConversationalAgent,
  title = {{{ArgueBot}}: {{A Conversational Agent}} for {{Adaptive Argumentation Feedback}}},
  shorttitle = {{{ArgueBot}}},
  author = {Wambsganss, Thiemo and Guggisberg, Sebastian and Soellner, Matthias},
  year = {2021},
  month = feb,
  journal = {Wirtschaftsinformatik 2021 Proceedings}
}

@misc{Wan2024TnTLLMTextMining,
  title = {{{TnT-LLM}}: {{Text Mining}} at {{Scale}} with {{Large Language Models}}},
  shorttitle = {{{TnT-LLM}}},
  author = {Wan, Mengting and Safavi, Tara and Jauhar, Sujay Kumar and Kim, Yujin and Counts, Scott and Neville, Jennifer and Suri, Siddharth and Shah, Chirag and White, Ryen W. and Yang, Longqi and Andersen, Reid and Buscher, Georg and Joshi, Dhruv and Rangan, Nagu},
  year = {2024},
  month = mar,
  number = {arXiv:2403.12173},
  eprint = {2403.12173},
  primaryclass = {cs},
  doi = {10.48550/arXiv.2403.12173},
  urldate = {2024-03-30},
  abstract = {Transforming unstructured text into structured and meaningful forms, organized by useful category labels, is a fundamental step in text mining for downstream analysis and application. However, most existing methods for producing label taxonomies and building text-based label classifiers still rely heavily on domain expertise and manual curation, making the process expensive and time-consuming. This is particularly challenging when the label space is under-specified and large-scale data annotations are unavailable. In this paper, we address these challenges with Large Language Models (LLMs), whose prompt-based interface facilitates the induction and use of large-scale pseudo labels. We propose TnT-LLM, a two-phase framework that employs LLMs to automate the process of end-to-end label generation and assignment with minimal human effort for any given use-case. In the first phase, we introduce a zero-shot, multi-stage reasoning approach which enables LLMs to produce and refine a label taxonomy iteratively. In the second phase, LLMs are used as data labelers that yield training samples so that lightweight supervised classifiers can be reliably built, deployed, and served at scale. We apply TnT-LLM to the analysis of user intent and conversational domain for Bing Copilot (formerly Bing Chat), an open-domain chat-based search engine. Extensive experiments using both human and automatic evaluation metrics demonstrate that TnT-LLM generates more accurate and relevant label taxonomies when compared against state-of-the-art baselines, and achieves a favorable balance between accuracy and efficiency for classification at scale. We also share our practical experiences and insights on the challenges and opportunities of using LLMs for large-scale text mining in real-world applications.},
  archiveprefix = {arXiv}
}

@article{Wang2020LanguageModelsAre,
  title = {Language {{Models}} Are {{Open Knowledge Graphs}}},
  author = {Wang, Chenguang and Liu, Xiao and Song, Dawn},
  year = {2020},
  month = oct,
  journal = {arXiv:2010.11967 [cs]},
  eprint = {2010.11967},
  primaryclass = {cs},
  urldate = {2021-09-06},
  abstract = {This paper shows how to construct knowledge graphs (KGs) from pre-trained language models (e.g., BERT, GPT-2/3), without human supervision. Popular KGs (e.g, Wikidata, NELL) are built in either a supervised or semi-supervised manner, requiring humans to create knowledge. Recent deep language models automatically acquire knowledge from large-scale corpora via pre-training. The stored knowledge has enabled the language models to improve downstream NLP tasks, e.g., answering questions, and writing code and articles. In this paper, we propose an unsupervised method to cast the knowledge contained within language models into KGs. We show that KGs are constructed with a single forward pass of the pre-trained language models (without fine-tuning) over the corpora. We demonstrate the quality of the constructed KGs by comparing to two KGs (Wikidata, TAC KBP) created by humans. Our KGs also provide open factual knowledge that is new in the existing KGs. Our code and KGs will be made publicly available.},
  archiveprefix = {arXiv}
}

@article{Wang2021EntailmentFewShotLearner,
  title = {Entailment as {{Few-Shot Learner}}},
  author = {Wang, Sinong and Fang, Han and Khabsa, Madian and Mao, Hanzi and Ma, Hao},
  year = {2021},
  month = apr,
  journal = {arXiv:2104.14690 [cs]},
  eprint = {2104.14690},
  primaryclass = {cs},
  urldate = {2022-04-20},
  abstract = {Large pre-trained language models (LMs) have demonstrated remarkable ability as few-shot learners. However, their success hinges largely on scaling model parameters to a degree that makes it challenging to train and serve. In this paper, we propose a new approach, named as EFL, that can turn small LMs into better few-shot learners. The key idea of this approach is to reformulate potential NLP task into an entailment one, and then fine-tune the model with as little as 8 examples. We further demonstrate our proposed method can be: (i) naturally combined with an unsupervised contrastive learning-based data augmentation method; (ii) easily extended to multilingual few-shot learning. A systematic evaluation on 18 standard NLP tasks demonstrates that this approach improves the various existing SOTA few-shot learning methods by 12{\textbackslash}\%, and yields competitive few-shot performance with 500 times larger models, such as GPT-3.},
  archiveprefix = {arXiv}
}

@inproceedings{Wang2023ChatGPTGoodNLG,
  title = {Is {{ChatGPT}} a {{Good NLG Evaluator}}? {{A Preliminary Study}}},
  shorttitle = {Is {{ChatGPT}} a {{Good NLG Evaluator}}?},
  booktitle = {Proceedings of the 4th {{New Frontiers}} in {{Summarization Workshop}}},
  author = {Wang, Jiaan and Liang, Yunlong and Meng, Fandong and Sun, Zengkui and Shi, Haoxiang and Li, Zhixu and Xu, Jinan and Qu, Jianfeng and Zhou, Jie},
  editor = {Dong, Yue and Xiao, Wen and Wang, Lu and Liu, Fei and Carenini, Giuseppe},
  year = {2023},
  month = dec,
  pages = {1--11},
  publisher = {Association for Computational Linguistics},
  address = {Singapore},
  doi = {10.18653/v1/2023.newsum-1.1},
  urldate = {2024-06-21},
  abstract = {Recently, the emergence of ChatGPT has attracted wide attention from the computational linguistics community. Many prior studies have shown that ChatGPT achieves remarkable performance on various NLP tasks in terms of automatic evaluation metrics. However, the ability of ChatGPT to serve as an evaluation metric is still underexplored. Considering assessing the quality of natural language generation (NLG) models is an arduous task and NLG metrics notoriously show their poor correlation with human judgments, we wonder whether ChatGPT is a good NLG evaluation metric. In this report, we provide a preliminary meta-evaluation on ChatGPT to show its reliability as an NLG metric. In detail, we regard ChatGPT as a human evaluator and give task-specific (e.g., summarization) and aspect-specific (e.g., relevance) instruction to prompt ChatGPT to evaluate the generated results of NLG models. We conduct experiments on five NLG meta-evaluation datasets (including summarization, story generation and data-to-text tasks). Experimental results show that compared with previous automatic metrics, ChatGPT achieves state-of-the-art or competitive correlation with human judgments in most cases. In addition, we find that the effectiveness of the ChatGPT evaluator might be influenced by the creation method of the meta-evaluation datasets. For the meta-evaluation datasets which are created greatly depending on the reference and thus are biased, the ChatGPT evaluator might lose its effectiveness. We hope our preliminary study could prompt the emergence of a general-purposed reliable NLG metric.}
}

@misc{Wang2024ChainofThoughtReasoningPrompting,
  title = {Chain-of-{{Thought Reasoning Without Prompting}}},
  author = {Wang, Xuezhi and Zhou, Denny},
  year = {2024},
  month = feb,
  number = {arXiv:2402.10200},
  eprint = {2402.10200},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.10200},
  urldate = {2024-02-19},
  abstract = {In enhancing the reasoning capabilities of large language models (LLMs), prior research primarily focuses on specific prompting techniques such as few-shot or zero-shot chain-of-thought (CoT) prompting. These methods, while effective, often involve manually intensive prompt engineering. Our study takes a novel approach by asking: Can LLMs reason effectively without prompting? Our findings reveal that, intriguingly, CoT reasoning paths can be elicited from pre-trained LLMs by simply altering the {\textbackslash}textit\{decoding\} process. Rather than conventional greedy decoding, we investigate the top-\$k\$ alternative tokens, uncovering that CoT paths are frequently inherent in these sequences. This approach not only bypasses the confounders of prompting but also allows us to assess the LLMs' {\textbackslash}textit\{intrinsic\} reasoning abilities. Moreover, we observe that the presence of a CoT in the decoding path correlates with a higher confidence in the model's decoded answer. This confidence metric effectively differentiates between CoT and non-CoT paths. Extensive empirical studies on various reasoning benchmarks show that the proposed CoT-decoding substantially outperforms the standard greedy decoding.},
  archiveprefix = {arXiv}
}

@inproceedings{Wang2024DAPRBenchmarkDocumentAware,
  title = {{{DAPR}}: {{A Benchmark}} on {{Document-Aware Passage Retrieval}}},
  shorttitle = {{{DAPR}}},
  booktitle = {{{ACL}} 2024},
  author = {Wang, Kexin and Reimers, Nils and Gurevych, Iryna},
  editor = {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
  year = {2024},
  month = aug,
  pages = {4313--4330},
  publisher = {Association for Computational Linguistics},
  address = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.acl-long.236},
  urldate = {2024-09-30},
  abstract = {The work of neural retrieval so far focuses on ranking short texts and is challenged with long documents. There are many cases where the users want to find a relevant passage within a long document from a huge corpus, e.g. Wikipedia articles, research papers, etc. We propose and name this task Document-Aware Passage Retrieval (DAPR). While analyzing the errors of the State-of-The-Art (SoTA) passage retrievers, we find the major errors (53.5\%) are due to missing document context. This drives us to build a benchmark for this task including multiple datasets from heterogeneous domains. In the experiments, we extend the SoTA passage retrievers with document context via (1) hybrid retrieval with BM25 and (2) contextualized passage representations, which inform the passage representation with document context. We find despite that hybrid retrieval performs the strongest on the mixture of the easy and the hard queries, it completely fails on the hard queries that require document-context understanding. On the other hand, contextualized passage representations (e.g. prepending document titles) achieve good improvement on these hard queries, but overall they also perform rather poorly. Our created benchmark enables future research on developing and comparing retrieval systems for the new task. The code and the data are available.}
}

@article{Wang2024SurveyLargeLanguage,
  title = {A Survey on Large Language Model Based Autonomous Agents},
  author = {Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and Zhao, Wayne Xin and Wei, Zhewei and Wen, Jirong},
  year = {2024},
  month = mar,
  journal = {Frontiers of Computer Science},
  volume = {18},
  number = {6},
  pages = {186345},
  issn = {2095-2236},
  doi = {10.1007/s11704-024-40231-1},
  urldate = {2024-09-17},
  abstract = {Autonomous agents have long been a research focus in academic and industry communities. Previous research often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of Web knowledge, large language models (LLMs) have shown potential in human-level intelligence, leading to a surge in research on LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of LLM-based autonomous agents from a holistic perspective. We first discuss the construction of LLM-based autonomous agents, proposing a unified framework that encompasses much of previous work. Then, we present a overview of the diverse applications of LLM-based autonomous agents in social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field.},
  langid = {english}
}

@misc{Warner2024SmarterBetterFaster,
  title = {Smarter, {{Better}}, {{Faster}}, {{Longer}}: {{A Modern Bidirectional Encoder}} for {{Fast}}, {{Memory Efficient}}, and {{Long Context Finetuning}} and {{Inference}}},
  shorttitle = {Smarter, {{Better}}, {{Faster}}, {{Longer}}},
  author = {Warner, Benjamin and Chaffin, Antoine and Clavi{\'e}, Benjamin and Weller, Orion and Hallstr{\"o}m, Oskar and Taghadouini, Said and Gallagher, Alexis and Biswas, Raja and Ladhak, Faisal and Aarsen, Tom and Cooper, Nathan and Adams, Griffin and Howard, Jeremy and Poli, Iacopo},
  year = {2024},
  month = dec,
  number = {arXiv:2412.13663},
  eprint = {2412.13663},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.13663},
  urldate = {2024-12-19},
  abstract = {Encoder-only transformer models such as BERT offer a great performance-size tradeoff for retrieval and classification tasks with respect to larger decoder-only models. Despite being the workhorse of numerous production pipelines, there have been limited Pareto improvements to BERT since its release. In this paper, we introduce ModernBERT, bringing modern model optimizations to encoder-only models and representing a major Pareto improvement over older encoders. Trained on 2 trillion tokens with a native 8192 sequence length, ModernBERT models exhibit state-of-the-art results on a large pool of evaluations encompassing diverse classification tasks and both single and multi-vector retrieval on different domains (including code). In addition to strong downstream performance, ModernBERT is also the most speed and memory efficient encoder and is designed for inference on common GPUs.},
  archiveprefix = {arXiv}
}

@misc{Watson2023CaseBasedPersistentMemory,
  title = {A {{Case-Based Persistent Memory}} for a {{Large Language Model}}},
  author = {Watson, Ian},
  year = {2023},
  month = oct,
  number = {arXiv:2310.08842},
  eprint = {2310.08842},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.08842},
  urldate = {2024-04-11},
  abstract = {Case-based reasoning (CBR) as a methodology for problem-solving can use any appropriate computational technique. This position paper argues that CBR researchers have somewhat overlooked recent developments in deep learning and large language models (LLMs). The underlying technical developments that have enabled the recent breakthroughs in AI have strong synergies with CBR and could be used to provide a persistent memory for LLMs to make progress towards Artificial General Intelligence.},
  archiveprefix = {arXiv}
}

@inproceedings{Weber2004CBRFlowEnablingAdaptive,
  title = {{{CBRFlow}}: {{Enabling Adaptive Workflow Management Through Conversational Case-Based Reasoning}}},
  shorttitle = {{{CBRFlow}}},
  booktitle = {Advances in {{Case-Based Reasoning}}},
  author = {Weber, Barbara and Wild, Werner and Breu, Ruth},
  editor = {Funk, Peter and Gonz{\'a}lez Calero, Pedro A.},
  year = {2004},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {434--448},
  publisher = {Springer Berlin Heidelberg},
  doi = {10.1007/978-3-540-28631-8_32},
  abstract = {In this paper we propose an architecture for an adaptive workflow management system (WFMS) and present the research prototype CBRFlow. CBRFlow extends workflow execution with conversational case-based reasoning (CCBR) to adapt the predefined workflow model to changing circumstances and to provide the WFMS with learning capabilities. Business rules within the predefined workflow model are annotated during run-time with context-specific information in the form of cases using the CCBR sub-system. When case reuse becomes frequent, the cases are manually refactored into rules to foster automatic execution. This feedback supports continuous process improvement, resulting in more manageable and more efficient business processes over time.},
  isbn = {978-3-540-28631-8},
  langid = {english}
}

@article{Weber2005TextualCasebasedReasoning,
  title = {Textual Case-Based Reasoning},
  author = {Weber, Rosina O. and Ashley, Kevin D. and Br{\"u}ninghaus, Stefanie},
  year = {2005},
  month = sep,
  journal = {The Knowledge Engineering Review},
  volume = {20},
  number = {3},
  pages = {255--260},
  issn = {0269-8889, 1469-8005},
  doi = {10.1017/S0269888906000713},
  urldate = {2019-08-20},
  abstract = {This commentary provides a definition of textual case-based reasoning (TCBR) and surveys research contributions according to four research questions. We also describe how TCBR can be distinguished from text mining and information retrieval. We conclude with potential directions for TCBR research.},
  langid = {english}
}

@inproceedings{Webster1992TokenizationInitialPhase,
  title = {Tokenization {{As}} the {{Initial Phase}} in {{NLP}}},
  booktitle = {Proceedings of the 14th {{Conference}} on {{Computational Linguistics}}},
  author = {Webster, Jonathan J. and Kit, Chunyu},
  year = {1992},
  series = {{{COLING}} '92},
  volume = {4},
  pages = {1106--1110},
  publisher = {Association for Computational Linguistics},
  address = {Nantes, France},
  doi = {10.3115/992424.992434},
  abstract = {In this paper, the authors address the significance and complexity of tokenization, the beginning step of NLP. Notions of word and token are discussed and defined from the viewpoints of lexicography and pragmatic implementation, respectively. Automatic segmentation of Chinese words is presented as an illustration of tokenization. Practical approaches to identification of compound tokens in English, such as idioms, phrasal verbs and fixed expressions, are developed.}
}

@inproceedings{Weidmann2023CLEARNESSCoreferenceResolution,
  title = {{{CLEARNESS}}: {{Coreference Resolution}} for {{Generating}} and {{Ranking Arguments Extracted}} from {{Debate Portals}} for {{Queries}}},
  shorttitle = {{{CLEARNESS}}},
  booktitle = {Lernen, {{Wissen}}, {{Daten}}, {{Analysen}} ({{LWDA}}) {{Conference Proceedings}}},
  author = {Weidmann, Johannes and Dumani, Lorik and Schenkel, Ralf},
  editor = {Leyer, Michael and Wichmann, Johannes},
  year = {2023},
  month = oct,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3630},
  pages = {161--174},
  publisher = {CEUR},
  address = {Marburg, Germany},
  issn = {1613-0073},
  urldate = {2024-02-09},
  langid = {english}
}

@inproceedings{Wells2020DatastoresArgumentationData,
  title = {Datastores for {{Argumentation Data}}},
  booktitle = {Proceedings of the 20th {{Workshop}} on {{Computational Models}} of {{Natural Argument}}},
  author = {Wells, Simon},
  editor = {Grasso, Floriana and Green, Nancy L. and Schneider, Jodi and Wells, Simon},
  year = {2020},
  series = {{{CEUR Workshop Proceedings}}},
  volume = {2669},
  pages = {31--40},
  publisher = {CEUR-WS.org},
  address = {Perugia, Italy},
  urldate = {2022-04-21}
}

@inproceedings{Wells2020OpenArgumentationPLatform,
  title = {The {{Open Argumentation PLatform}} ({{OAPL}})},
  booktitle = {Computational {{Models}} of {{Argument}}},
  author = {Wells, Simon},
  year = {2020},
  pages = {475--476},
  publisher = {IOS Press},
  doi = {10.3233/FAIA200541},
  urldate = {2021-03-28}
}

@inproceedings{Wijekoon2023CBRDrivenInteractive,
  title = {{{CBR Driven Interactive Explainable AI}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Wijekoon, Anjana and Wiratunga, Nirmalie and Martin, Kyle and Corsar, David and {Nkisi-Orji}, Ikechukwu and Palihawadana, Chamath and Bridge, Derek and Pradeep, Preeja and Agudo, Belen Diaz and {Caro-Mart{\'i}nez}, Marta},
  editor = {Massie, Stewart and Chakraborti, Sutanu},
  year = {2023},
  pages = {169--184},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-40177-0_11},
  abstract = {Explainable AI~(XAI) can greatly enhance user trust and satisfaction in AI-assisted decision-making processes. Numerous explanation techniques (explainers) exist in the literature, and recent findings suggest that addressing multiple user needs requires employing a combination of these explainers. We refer to such combinations as explanation strategies. This paper introduces iSee - Intelligent Sharing of Explanation Experience, an interactive platform that facilitates the reuse of explanation strategies and promotes best practices in XAI by employing the Case-based Reasoning~(CBR) paradigm. iSee uses an ontology-guided approach to effectively capture explanation requirements, while a behaviour tree-driven conversational chatbot captures user experiences of interacting with the explanations and provides feedback. In a case study, we illustrate the iSee CBR system capabilities by formalising a real-world radiograph fracture detection system and demonstrating how each interactive tools facilitate the CBR processes.},
  isbn = {978-3-031-40177-0},
  langid = {english}
}

@inproceedings{Wilkerson2024ImplementingCaseBasedReasoning,
  title = {On {{Implementing Case-Based Reasoning}} with~{{Large Language Models}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Wilkerson, Kaitlynne and Leake, David},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {404--417},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_26},
  abstract = {Systems based on Large Language Models (LLMs), such as ChatGPT, have impressive performance but also well-known issues with erroneous output. Retrieval Augmented Generation (RAG), which typically presents the LLM with text snippets of additional knowledge retrieved from an external knowledge base, is a popular method for increasing LLM accuracy. This paper presents initial studies exploring augmenting LLMs with cases rather than snippets and prompting LLMs towards performing case-based reasoning. The studies consider four possible scenarios, exploring the potential benefit of LLMs performing different subparts of the CBR process: (1) a scenario in which the LLM is prompted to adapt a presented case, (2) a scenario in which the LLM is first prompted to perform similarity assessment to select a case from a set of candidates, and then to adapt the selected case, (3) a scenario in which the LLM is prompted to select the two most similar cases to a problem and generate an adapted/combined solution in light of both, and (4) a scenario in which the LLM selects the nearest neighbor and nearest unlike neighbor and generates an adapted/combined solution based on both. Results of tests using Llama and ChatGPT are encouraging for the accuracy benefits of providing LLMs with cases and raise questions for future study.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@article{Winston1980LearningReasoningAnalogy,
  title = {Learning and Reasoning by Analogy},
  author = {Winston, Patrick H.},
  year = {1980},
  month = dec,
  journal = {Communications of the ACM},
  volume = {23},
  number = {12},
  pages = {689--703},
  issn = {0001-0782},
  doi = {10.1145/359038.359042},
  urldate = {2020-05-26},
  abstract = {We use analogy when we say something is a Cinderella story and when we learn about resistors by thinking about water pipes. We also use analogy when we learn subjects like economics, medicine, and law. This paper presents a theory of analogy and describes an implemented system that embodies the theory. The specific competence to be understood is that of using analogies to do certain kinds of learning and reasoning. Learning takes place when analogy is used to generate a constraint description in one domain, given a constraint description in another, as when we learn Ohm's law by way of knowledge about water pipes. Reasoning takes place when analogy is used to answer questions about one situation, given another situation that is supposed to be a precedent, as when we answer questions about Hamlet by way of knowledge about Macbeth.}
}

@inproceedings{Wiratunga2024CBRRAGCaseBasedReasoning,
  title = {{{CBR-RAG}}: {{Case-Based Reasoning}} for~{{Retrieval Augmented Generation}} in~{{LLMs}} for~{{Legal Question Answering}}},
  shorttitle = {{{CBR-RAG}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Wiratunga, Nirmalie and Abeyratne, Ramitha and Jayawardena, Lasal and Martin, Kyle and Massie, Stewart and {Nkisi-Orji}, Ikechukwu and Weerasinghe, Ruvan and Liret, Anne and Fleisch, Bruno},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {445--460},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_29},
  abstract = {Retrieval-Augmented Generation (RAG) enhances Large Language Model (LLM) output by providing prior knowledge as context to input. This is beneficial for knowledge-intensive and expert reliant tasks, including legal question-answering, which require evidence to validate generated text outputs. We highlight that Case-Based Reasoning (CBR) presents key opportunities to structure retrieval as part of the RAG process in an LLM. We introduce CBR-RAG, where CBR cycle's initial retrieval stage, its indexing vocabulary, and similarity knowledge containers are used to enhance LLM queries with contextually relevant cases. This integration augments the original LLM query, providing a richer prompt. We present an evaluation of CBR-RAG, and examine different representations (i.e. general and domain-specific embeddings) and methods of comparison (i.e. inter, intra and hybrid similarity) on the task of legal question-answering. Our results indicate that the context provided by CBR's case reuse enforces similarity between relevant components of the questions and the evidence base leading to significant improvements in the quality of generated answers.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@inproceedings{Witten1999KEAPracticalAutomatic,
  title = {{{KEA}}: Practical Automatic Keyphrase Extraction},
  shorttitle = {{{KEA}}},
  booktitle = {Proceedings of the Fourth {{ACM}} Conference on {{Digital}} Libraries},
  author = {Witten, Ian H. and Paynter, Gordon W. and Frank, Eibe and Gutwin, Carl and {Nevill-Manning}, Craig G.},
  year = {1999},
  month = aug,
  series = {{{DL}} '99},
  pages = {254--255},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/313238.313437},
  urldate = {2021-02-07},
  isbn = {978-1-58113-145-1}
}

@mastersthesis{Wong2022ImprovingQualityAutomated,
  title = {Improving {{Quality}} of {{Automated Constructed Argument Graphs}}: {{Towards}} a {{Pipeline}} for {{Argument Graph Reconstruction}}},
  author = {Wong, Wai Lun},
  year = {2022},
  month = mar,
  address = {Trier, Germany},
  langid = {english},
  school = {Trier University}
}

@inproceedings{Wu1994VerbsSemanticsLexical,
  title = {Verbs Semantics and Lexical Selection},
  booktitle = {Proceedings of the 32nd Annual Meeting on {{Association}} for {{Computational Linguistics}}},
  author = {Wu, Zhibiao and Palmer, Martha},
  year = {1994},
  month = jun,
  series = {{{ACL}} '94},
  pages = {133--138},
  publisher = {Association for Computational Linguistics},
  address = {USA},
  doi = {10.3115/981732.981751},
  urldate = {2021-02-17},
  abstract = {This paper will focus on the semantic representation of verbs in computer systems and its impact on lexical selection problems in machine translation (MT). Two groups of English and Chinese verbs are examined to show that lexical selection must be based on interpretation of the sentences as well as selection restrictions placed on the verb arguments. A novel representation scheme is suggested, and is compared to representations with selection restrictions used in transfer-based MT. We see our approach as closely aligned with knowledge-based MT approaches (KBMT), and as a separate component that could be incorporated into existing systems. Examples and experimental results will show that, using this scheme, inexact matches can achieve correct lexical selection.}
}

@inproceedings{Wu2021DeepLearningGraphs,
  title = {Deep {{Learning}} on {{Graphs}} for {{Natural Language Processing}}},
  booktitle = {Proceedings of the 2021 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}: {{Tutorials}}},
  author = {Wu, Lingfei and Chen, Yu and Ji, Heng and Li, Yunyao},
  year = {2021},
  month = jun,
  pages = {11--14},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  urldate = {2021-06-09},
  abstract = {Due to its great power in modeling non-Euclidean data like graphs or manifolds, deep learning on graph techniques (i.e., Graph Neural Networks (GNNs)) have opened a new door to solving challenging graph-related NLP problems. There has seen a surge of interests in applying deep learning on graph techniques to NLP, and has achieved considerable success in many NLP tasks, ranging from classification tasks like sentence classification, semantic role labeling and relation extraction, to generation tasks like machine translation, question generation and summarization. Despite these successes, deep learning on graphs for NLP still face many challenges, including automatically transforming original text sequence data into highly graph-structured data, and effectively modeling complex data that involves mapping between graph-based inputs and other highly structured output data such as sequences, trees, and graph data with multi-types in both nodes and edges. This tutorial will cover relevant and interesting topics on applying deep learning on graph techniques to NLP, including automatic graph construction for NLP, graph representation learning for NLP, advanced GNN based models (e.g., graph2seq, graph2tree, and graph2graph) for NLP, and the applications of GNNs in various NLP tasks (e.g., machine translation, natural language generation, information extraction and semantic parsing). In addition, hands-on demonstration sessions will be included to help the audience gain practical experience on applying GNNs to solve challenging NLP problems using our recently developed open source library -- Graph4NLP, the first library for researchers and practitioners for easy use of GNNs for various NLP tasks.}
}

@misc{Xiao2025FoundationsLargeLanguage,
  title = {Foundations of {{Large Language Models}}},
  author = {Xiao, Tong and Zhu, Jingbo},
  year = {2025},
  month = jan,
  number = {arXiv:2501.09223},
  eprint = {2501.09223},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.09223},
  urldate = {2025-01-23},
  abstract = {This is a book about large language models. As indicated by the title, it primarily focuses on foundational concepts rather than comprehensive coverage of all cutting-edge technologies. The book is structured into four main chapters, each exploring a key area: pre-training, generative models, prompting techniques, and alignment methods. It is intended for college students, professionals, and practitioners in natural language processing and related fields, and can serve as a reference for anyone interested in large language models.},
  archiveprefix = {arXiv}
}

@misc{Xu2024LargeLanguageModels,
  title = {Large {{Language Models}} for {{Generative Information Extraction}}: {{A Survey}}},
  shorttitle = {Large {{Language Models}} for {{Generative Information Extraction}}},
  author = {Xu, Derong and Chen, Wei and Peng, Wenjun and Zhang, Chao and Xu, Tong and Zhao, Xiangyu and Wu, Xian and Zheng, Yefeng and Wang, Yang and Chen, Enhong},
  year = {2024},
  month = jun,
  number = {arXiv:2312.17617},
  eprint = {2312.17617},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.17617},
  urldate = {2024-06-15},
  abstract = {Information extraction (IE) aims to extract structural knowledge (such as entities, relations, and events) from plain natural language texts. Recently, generative Large Language Models (LLMs) have demonstrated remarkable capabilities in text understanding and generation, allowing for generalization across various domains and tasks. As a result, numerous works have been proposed to harness abilities of LLMs and offer viable solutions for IE tasks based on a generative paradigm. To conduct a comprehensive systematic review and exploration of LLM efforts for IE tasks, in this study, we survey the most recent advancements in this field. We first present an extensive overview by categorizing these works in terms of various IE subtasks and learning paradigms, then we empirically analyze the most advanced methods and discover the emerging trend of IE tasks with LLMs. Based on thorough review conducted, we identify several insights in technique and promising research directions that deserve further exploration in future studies. We maintain a public repository and consistently update related resources at: {\textbackslash}url\{https://github.com/quqxui/Awesome-LLM4IE-Papers\}.},
  archiveprefix = {arXiv}
}

@inproceedings{Yang2019CasebasedReasoningFacilitation,
  title = {Toward {{Case-based Reasoning Facilitation}} for {{Online Discussion}} in {{Deliberation}}},
  booktitle = {2019 {{IEEE}} 23rd {{International Conference}} on {{Computer Supported Cooperative Work}} in {{Design}} ({{CSCWD}})},
  author = {Yang, Chunsheng and Gu, Wen and Ito, Takayuki},
  year = {2019},
  month = may,
  pages = {517--523},
  doi = {10.1109/CSCWD.2019.8791866},
  abstract = {This paper presents a novel case-based reasoning (CBR) application to crowd-scale deliberation. We propose a CBR approach to facilitating online discussion for crowd-scale deliberation. The objective is to smooth the discussion by avoiding flaming and to efficiently achieve a consensus. Accordingly, several challenging issues are addressed, including case definition and its structure, case creation, and implementation by incorporating with COLLAGREE, a crowd-scale deliberation platform supporting online discussion with the help of facilitators. After introducing an overview of the crowd-scale deliberation and the COLLAGREE, the paper presents the details of the proposed CBR approach for facilitation of online discussion along with some preliminary results. The feasibility of CBR-based facilitation support for crowd-scale deliberations is demonstrated.}
}

@misc{Yasunaga2023LargeLanguageModels,
  title = {Large {{Language Models}} as {{Analogical Reasoners}}},
  author = {Yasunaga, Michihiro and Chen, Xinyun and Li, Yujia and Pasupat, Panupong and Leskovec, Jure and Liang, Percy and Chi, Ed H. and Zhou, Denny},
  year = {2023},
  month = oct,
  number = {arXiv:2310.01714},
  eprint = {2310.01714},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.01714},
  urldate = {2023-10-09},
  abstract = {Chain-of-thought (CoT) prompting for language models demonstrates impressive performance across reasoning tasks, but typically needs labeled exemplars of the reasoning process. In this work, we introduce a new prompting approach, Analogical Prompting, designed to automatically guide the reasoning process of large language models. Inspired by analogical reasoning, a cognitive process in which humans draw from relevant past experiences to tackle new problems, our approach prompts language models to self-generate relevant exemplars or knowledge in the context, before proceeding to solve the given problem. This method presents several advantages: it obviates the need for labeling or retrieving exemplars, offering generality and convenience; it can also tailor the generated exemplars and knowledge to each problem, offering adaptability. Experimental results show that our approach outperforms 0-shot CoT and manual few-shot CoT in a variety of reasoning tasks, including math problem solving in GSM8K and MATH, code generation in Codeforces, and other reasoning tasks in BIG-Bench.},
  archiveprefix = {arXiv}
}

@inproceedings{Ye2024NetworkImplementationCBR,
  title = {Towards {{Network Implementation}} of~{{CBR}}: {{Case Study}} of~a~{{Neural Network K-NN Algorithm}}},
  shorttitle = {Towards {{Network Implementation}} of~{{CBR}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Ye, Xiaomeng and Leake, David and Wang, Yu and Zhao, Ziwei and Crandall, David},
  editor = {{Recio-Garcia}, Juan A. and {Orozco-del-Castillo}, Mauricio G. and Bridge, Derek},
  year = {2024},
  pages = {354--370},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63646-2_23},
  abstract = {Recent research brings the strengths of neural networks to bear on CBR tasks such as similarity assessment and case adaptation. This paper further advances this direction by implementing both retrieval and adaptation as a single neural network. Such an approach has multiple goals: From the perspective of CBR, it enables harmonizing the interaction between feature extraction, retrieval/similarity assessment, and case adaptation through end-to-end training. From the perspective of neural networks, a neural network implementing CBR processes ceases to be a black box and provides the natural interpretability of CBR. As a first step towards this goal, this paper presents neural network based k-nearest neighbor (NN-kNN), a network architecture that can be interpreted as a k-NN method. Unlike other network architectures, NN-kNN's decisions can be fully explained in terms of surface features, feature/case weights and nearest neighbors. It can be trained or fine-tuned using existing neural network methods. This study illustrates its feasibility and examines its strengths and limitations. The approach is evaluated for classification and regression tasks comparing NN-kNN, a standard neural network, and k-NN models using state-of-the-art distance metric learning algorithms. In these tests, NN-kNN achieves equal or less error when compared to the other models, while being fully interpretable as a k-NN method. The study also considered the limitations of NN-kNN and future directions to alleviate them.},
  isbn = {978-3-031-63646-2},
  langid = {english}
}

@article{Young2018NotesAbstractArgumentation,
  title = {Notes on {{Abstract Argumentation Theory}}},
  author = {Young, Anthony Peter},
  year = {2018},
  month = jun,
  journal = {arXiv:1806.07709 [cs]},
  eprint = {1806.07709},
  primaryclass = {cs},
  urldate = {2019-08-21},
  abstract = {This note reviews Section 2 of Dung's seminal 1995 paper on abstract argumentation theory. In particular, we clarify and make explicit all of the proofs mentioned therein, and provide many more examples to the definitions, in a way that should be helpful to readers approaching abstract argumentation theory for the first time. However, we provide minimal commentary and will refer the reader to Dung's paper for the intuitions behind various concepts. The appropriate mathematical prerequisites are provided in the appendices.},
  archiveprefix = {arXiv}
}

@article{Young2022ModellingOnlineDebates,
  title = {Modelling Online Debates with Argumentation Theory},
  author = {Young, Anthony P. and Joglekar, Sagar and Agarwal, Vibhor and Sastry, Nishanth},
  year = {2022},
  month = may,
  journal = {ACM SIGWEB Newsletter},
  volume = {2022},
  number = {Spring},
  pages = {4:1--4:9},
  issn = {1931-1745},
  doi = {10.1145/3533274.3533278},
  urldate = {2023-10-20},
  abstract = {It is important to study and understand Internet debates because they often have consequences in the offline world, for better or worse. We show that argumentation theory, a branch of AI concerned with the resolution of disagreements, provides a powerful toolbox with which we can represent and reason about such debates. After summarising the relevant ideas of argumentation theory, we overview three recent contributions from the authors and their collaborators: (1) on how to automatically identify reply polarity (agreement or disagreement) between arguments submitted in online debates, (2) on locating where the justified arguments are likely to be and how that depends on the "degree of antagonism" of the debate, and (3) on how to present the arguments made in debates such that a reader would get as many of the justified arguments as possible without having to read the entire debate. We hope that this will lead to further work that applies argumentation theory to model and analyse online debates.}
}

@article{Zapf2016MeasuringInterraterReliability,
  title = {Measuring Inter-Rater Reliability for Nominal Data -- Which Coefficients and Confidence Intervals Are Appropriate?},
  author = {Zapf, Antonia and Castell, Stefanie and Morawietz, Lars and Karch, Andr{\'e}},
  year = {2016},
  month = aug,
  journal = {BMC Medical Research Methodology},
  volume = {16},
  number = {1},
  pages = {93},
  issn = {1471-2288},
  doi = {10.1186/s12874-016-0200-9},
  urldate = {2021-02-23},
  abstract = {Reliability of measurements is a prerequisite of medical research. For nominal data, Fleiss' kappa (in the following labelled as Fleiss' K) and Krippendorff's alpha provide the highest flexibility of the available reliability measures with respect to number of raters and categories. Our aim was to investigate which measures and which confidence intervals provide the best statistical properties for the assessment of inter-rater reliability in different situations.}
}

@inproceedings{Zeyen2019AdaptationScientificWorkflows,
  title = {Adaptation of {{Scientific Workflows}} by {{Means}} of {{Process-Oriented Case-Based Reasoning}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Zeyen, Christian and Malburg, Lukas and Bergmann, Ralph},
  editor = {Bach, Kerstin and Marling, Cindy},
  year = {2019},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {388--403},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-29249-2_26},
  abstract = {This paper investigates automatic adaptation of scientific workflows in process-oriented case-based reasoning with the goal of providing modeling assistance. With regard to our previous work on the adaptation of business workflows, we discuss the differences between the workflow types and the implications for transferring the approaches to scientific workflows. An experimental evaluation with RapidMiner workflows demonstrates that the approaches can significantly improve workflows towards a given query while mostly maintaining their executability and semantic correctness.},
  isbn = {978-3-030-29249-2},
  langid = {english}
}

@inproceedings{Zeyen2020ABasedSimilarityAssessment,
  title = {A*-{{Based Similarity Assessment}} of {{Semantic Graphs}}},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  author = {Zeyen, Christian and Bergmann, Ralph},
  editor = {Watson, Ian and Weber, Rosina},
  year = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {17--32},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-58342-2_2},
  abstract = {The similarity assessment of graphs is a fundamental problem that is particularly challenging if efficiency is of core importance. In this paper, we focus on a similarity measure for semantically labeled graphs whose labels are composed in an object-oriented manner. The measure is based on A* search and is particularly suited for case-based reasoning as it can be combined with knowledge-intensive local similarity measures and outputs similarities and corresponding mappings usable for explanation and adaptation. However, particularly for large graphs, the search space must be pruned to improve efficiency of A* search at the cost of sacrificing global optimality. We address this issue and present complementary improvements of the measure, which we systematically evaluate for the similarity assessment of semantic workflow graphs. The experimental results demonstrate that the new measure considerably reduces the computation time and memory consumption while increasing the accuracy.},
  isbn = {978-3-030-58342-2},
  langid = {english}
}

@article{Zhang2020BERTScoreEvaluatingText,
  title = {{{BERTScore}}: {{Evaluating Text Generation}} with {{BERT}}},
  shorttitle = {{{BERTScore}}},
  author = {Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q. and Artzi, Yoav},
  year = {2020},
  month = feb,
  journal = {arXiv:1904.09675 [cs]},
  eprint = {1904.09675},
  primaryclass = {cs},
  urldate = {2021-03-09},
  abstract = {We propose BERTScore, an automatic evaluation metric for text generation. Analogously to common metrics, BERTScore computes a similarity score for each token in the candidate sentence with each token in the reference sentence. However, instead of exact matches, we compute token similarity using contextual embeddings. We evaluate using the outputs of 363 machine translation and image captioning systems. BERTScore correlates better with human judgments and provides stronger model selection performance than existing metrics. Finally, we use an adversarial paraphrase detection task to show that BERTScore is more robust to challenging examples when compared to existing metrics.},
  archiveprefix = {arXiv}
}

@article{Zhang2021StudyBugResolution,
  title = {A {{Study}} of {{Bug Resolution Characteristics}} in {{Popular Programming Languages}}},
  author = {Zhang, Jie M. and Li, Feng and Hao, Dan and Wang, Meng and Tang, Hao and Zhang, Lu and Harman, Mark},
  year = {2021},
  month = dec,
  journal = {IEEE Transactions on Software Engineering},
  volume = {47},
  number = {12},
  pages = {2684--2697},
  issn = {1939-3520},
  doi = {10.1109/TSE.2019.2961897},
  abstract = {This paper presents a large-scale study that investigates the bug resolution characteristics among popular Github projects written in different programming languages. We explore correlations but, of course, we cannot infer causation. Specifically, we analyse bug resolution data from approximately 70 million Source Line of Code, drawn from 3 million commits to 600 GitHub projects, primarily written in 10 programming languages. We find notable variations in apparent bug resolution time and patch (fix) size. While interpretation of results from such large-scale empirical studies is inherently difficult, we believe that the differences in medians are sufficiently large to warrant further investigation, replication, re-analysis and follow up research. For example, in our corpus, the median apparent bug resolution time (elapsed time from raise to resolve) for Ruby was 4X that for Go and 2.5X for Java. We also found that patches tend to touch more files for the corpus of strongly typed and for statically typed programs. However, we also found evidence for a lower elapsed resolution time for bug resolution committed to projects constructed from statically typed languages. These findings, if replicated in subsequent follow on studies, may shed further empirical light on the debate about the importance of static typing.}
}

@inproceedings{Zhang2023ImprovingSentenceEmbedding,
  title = {Improving {{Sentence Embedding With Sentence Relationships From Word Analogies}}},
  booktitle = {Proceedings of the {{Workshops}} at the 31st {{International Conference}} on {{Case-Based Reasoning}} ({{ICCBR-WS}} 2023)},
  author = {Zhang, Qixuan and Lepage, Yves},
  editor = {Malburg, Lukas and Verma, Deepika},
  year = {2023},
  month = jul,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3438},
  pages = {43--53},
  publisher = {CEUR},
  address = {Aberdeen, Scotland},
  issn = {1613-0073},
  urldate = {2023-07-31},
  langid = {english}
}

@article{Zhao2021EvaluationIndicatorsOpensource,
  title = {Evaluation Indicators for Open-Source Software: A Review},
  shorttitle = {Evaluation Indicators for Open-Source Software},
  author = {Zhao, Yuhang and Liang, Ruigang and Chen, Xiang and Zou, Jing},
  year = {2021},
  month = jun,
  journal = {Cybersecurity},
  volume = {4},
  number = {1},
  pages = {20},
  issn = {2523-3246},
  doi = {10.1186/s42400-021-00084-8},
  urldate = {2023-10-05},
  abstract = {In recent years, the widespread applications of open-source software (OSS) have brought great convenience for software developers. However, it is always facing unavoidable security risks, such as open-source code defects and security vulnerabilities. To find out the OSS risks in time, we carry out an empirical study to identify the indicators for evaluating the OSS. To achieve a comprehensive understanding of the OSS assessment, we collect 56 papers from prestigious academic venues (such as IEEE Xplore, ACM Digital Library, DBLP, and Google Scholar) in the past 21 years. During the process of the investigation, we first identify the main concerns for selecting OSS and distill five types of commonly used indicators to assess OSS. We then conduct a comparative analysis to discuss how these indicators are used in each surveyed study and their differences. Moreover, we further undertake a correlation analysis between these indicators and uncover 13 confirmed conclusions and four cases with controversy occurring in these studies. Finally, we discuss several possible applications of these conclusions, which are insightful for the research on OSS and software supply chain.}
}

@inproceedings{Zhao2023RetrievingMultimodalInformation,
  title = {Retrieving {{Multimodal Information}} for {{Augmented Generation}}: {{A Survey}}},
  shorttitle = {Retrieving {{Multimodal Information}} for {{Augmented Generation}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2023},
  author = {Zhao, Ruochen and Chen, Hailin and Wang, Weishi and Jiao, Fangkai and Do, Xuan Long and Qin, Chengwei and Ding, Bosheng and Guo, Xiaobao and Li, Minzhi and Li, Xingxuan and Joty, Shafiq},
  editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
  year = {2023},
  month = dec,
  pages = {4736--4756},
  publisher = {Association for Computational Linguistics},
  address = {Singapore},
  doi = {10.18653/v1/2023.findings-emnlp.314},
  urldate = {2024-09-30},
  abstract = {As Large Language Models (LLMs) become popular, there emerged an important trend of using multimodality to augment the LLMs' generation ability, which enables LLMs to better interact with the world. However, there lacks a unified perception of at which stage and how to incorporate different modalities. In this survey, we review methods that assist and augment generative models by retrieving multimodal knowledge, whose formats range from images, codes, tables, graphs, to audio. Such methods offer a promising solution to important concerns such as factuality, reasoning, interpretability, and robustness. By providing an in-depth review, this survey is expected to provide scholars with a deeper understanding of the methods' applications and encourage them to adapt existing techniques to the fast-growing field of LLMs.}
}

@article{Zhelezniak2019DonSettleAverage,
  title = {Don't {{Settle}} for {{Average}}, {{Go}} for the {{Max}}: {{Fuzzy Sets}} and {{Max-Pooled Word Vectors}}},
  shorttitle = {Don't {{Settle}} for {{Average}}, {{Go}} for the {{Max}}},
  author = {Zhelezniak, Vitalii and Savkov, Aleksandar and Shen, April and Moramarco, Francesco and Flann, Jack and Hammerla, Nils Y.},
  year = {2019},
  month = apr,
  journal = {arXiv:1904.13264 [cs]},
  eprint = {1904.13264},
  primaryclass = {cs},
  urldate = {2019-09-12},
  abstract = {Recent literature suggests that averaged word vectors followed by simple post-processing outperform many deep learning methods on semantic textual similarity tasks. Furthermore, when averaged word vectors are trained supervised on large corpora of paraphrases, they achieve state-of-the-art results on standard STS benchmarks. Inspired by these insights, we push the limits of word embeddings even further. We propose a novel fuzzy bag-of-words (FBoW) representation for text that contains all the words in the vocabulary simultaneously but with different degrees of membership, which are derived from similarities between word vectors. We show that max-pooled word vectors are only a special case of fuzzy BoW and should be compared via fuzzy Jaccard index rather than cosine similarity. Finally, we propose DynaMax, a completely unsupervised and non-parametric similarity measure that dynamically extracts and max-pools good features depending on the sentence pair. This method is both efficient and easy to implement, yet outperforms current baselines on STS tasks by a large margin and is even competitive with supervised word vectors trained to directly optimise cosine similarity.},
  archiveprefix = {arXiv}
}

@article{Zhou2019PredictingConceptNetPath,
  title = {Predicting {{ConceptNet Path Quality Using Crowdsourced Assessments}} of {{Naturalness}}},
  author = {Zhou, Yilun and Schockaert, Steven and Shah, Julie A.},
  year = {2019},
  journal = {The World Wide Web Conference on   - WWW '19},
  eprint = {1902.07831},
  pages = {2460--2471},
  doi = {10.1145/3308558.3313486},
  urldate = {2020-05-30},
  abstract = {In many applications, it is important to characterize the way in which two concepts are semantically related. Knowledge graphs such as ConceptNet provide a rich source of information for such characterizations by encoding relations between concepts as edges in a graph. When two concepts are not directly connected by an edge, their relationship can still be described in terms of the paths that connect them. Unfortunately, many of these paths are uninformative and noisy, which means that the success of applications that use such path features crucially relies on their ability to select high-quality paths. In existing applications, this path selection process is based on relatively simple heuristics. In this paper we instead propose to learn to predict path quality from crowdsourced human assessments. Since we are interested in a generic task-independent notion of quality, we simply ask human participants to rank paths according to their subjective assessment of the paths' naturalness, without attempting to define naturalness or steering the participants towards particular indicators of quality. We show that a neural network model trained on these assessments is able to predict human judgments on unseen paths with near optimal performance. Most notably, we find that the resulting path selection method is substantially better than the current heuristic approaches at identifying meaningful paths.},
  archiveprefix = {arXiv}
}

@article{Zhu2017ComputingSemanticSimilarity,
  title = {Computing {{Semantic Similarity}} of {{Concepts}} in {{Knowledge Graphs}}},
  author = {Zhu, Ganggao and Iglesias, Carlos A.},
  year = {2017},
  month = jan,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {29},
  number = {1},
  pages = {72--85},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2016.2610428},
  abstract = {This paper presents a method for measuring the semantic similarity between concepts in Knowledge Graphs (KGs) such as WordNet and DBpedia. Previous work on semantic similarity methods have focused on either the structure of the semantic network between concepts (e.g., path length and depth), or only on the Information Content (IC) of concepts. We propose a semantic similarity method, namely wpath, to combine these two approaches, using IC to weight the shortest path length between concepts. Conventional corpus-based IC is computed from the distributions of concepts over textual corpus, which is required to prepare a domain corpus containing annotated concepts and has high computational cost. As instances are already extracted from textual corpus and annotated by concepts in KGs, graph-based IC is proposed to compute IC based on the distributions of concepts over instances. Through experiments performed on well known word similarity datasets, we show that the wpath semantic similarity method has produced a statistically significant improvement over other semantic similarity methods. Moreover, in a real category classification evaluation, the wpath method has shown the best performance in terms of accuracy and F score.}
}

@misc{Zhu2023CanChatGPTReproduce,
  title = {Can {{ChatGPT Reproduce Human-Generated Labels}}? {{A Study}} of {{Social Computing Tasks}}},
  shorttitle = {Can {{ChatGPT Reproduce Human-Generated Labels}}?},
  author = {Zhu, Yiming and Zhang, Peixian and Haq, Ehsan-Ul and Hui, Pan and Tyson, Gareth},
  year = {2023},
  month = apr,
  number = {arXiv:2304.10145},
  eprint = {2304.10145},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.10145},
  urldate = {2024-02-10},
  abstract = {The release of ChatGPT has uncovered a range of possibilities whereby large language models (LLMs) can substitute human intelligence. In this paper, we seek to understand whether ChatGPT has the potential to reproduce human-generated label annotations in social computing tasks. Such an achievement could significantly reduce the cost and complexity of social computing research. As such, we use ChatGPT to relabel five seminal datasets covering stance detection (2x), sentiment analysis, hate speech, and bot detection. Our results highlight that ChatGPT does have the potential to handle these data annotation tasks, although a number of challenges remain. ChatGPT obtains an average accuracy 0.609. Performance is highest for the sentiment analysis dataset, with ChatGPT correctly annotating 64.9\% of tweets. Yet, we show that performance varies substantially across individual labels. We believe this work can open up new lines of analysis and act as a basis for future research into the exploitation of ChatGPT for human annotation tasks.},
  archiveprefix = {arXiv}
}

@inproceedings{Ziegenbein2024ObjectiveArgumentSummarization,
  title = {Objective {{Argument Summarization}} in~{{Search}}},
  booktitle = {Robust {{Argumentation Machines}}},
  author = {Ziegenbein, Timon and Syed, Shahbaz and Potthast, Martin and Wachsmuth, Henning},
  editor = {Cimiano, Philipp and Frank, Anette and Kohlhase, Michael and Stein, Benno},
  year = {2024},
  pages = {335--351},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-63536-6_20},
  abstract = {Decision-making and opinion formation are influenced by arguments from various online sources, including social media, web publishers, and, not least, the search engines used to retrieve them. However, many, if not most, arguments on the web are informal, especially in online discussions or on personal pages. They can be long and unstructured, subjective and emotional, and contain inappropriate language. This makes it difficult to find relevant arguments efficiently. We hypothesize that, on search engine results pages, ``objective snippets'' of arguments are better suited than the commonly used extractive snippets and develop corresponding methods for two important tasks: snippet generation and neutralization. For each of these tasks, we investigate two approaches based on (1)~prompt engineering for large language models~(LLMs), and (2)~supervised models trained on existing datasets. We find that a supervised summarization model outperforms zero-shot summarization with LLMs for snippet generation. For neutralization, using reinforcement learning to align an LLM with human preferences for suitable arguments leads to the best results. Both tasks are complementary, and their combination leads to the best snippets of arguments according to automatic and human evaluation.},
  isbn = {978-3-031-63536-6},
  langid = {english}
}

@article{Zwick1988AnotherLookInterrater,
  title = {Another Look at Interrater Agreement.},
  author = {Zwick, Rebecca},
  year = {1988},
  journal = {Psychological Bulletin},
  volume = {103},
  number = {3},
  pages = {374--378},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/0033-2909.103.3.374},
  urldate = {2021-03-07},
  langid = {english}
}
